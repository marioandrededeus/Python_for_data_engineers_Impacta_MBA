{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -n pysparkpi plenv ipykernel --update-deps --force-reinstall\n",
    "#!pip install bibtexparser\n",
    "#!pip install pyyaml\n",
    "#!pip install pyspark findspark\n",
    "#!pip install PyArrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "#import pandas as pd\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "from functions import read_bib\n",
    "from functions import load_bib\n",
    "from functions import write_yaml\n",
    "from functions import write_json\n",
    "from functions import write_csv\n",
    "from functions import read_yaml\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating SparkSession and sparkcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName('Firstprogram')\\\n",
    "                    .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading, loading and concatenating all bibtex files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../01_Datasets/bibtex\\acm\n",
      "../01_Datasets/bibtex\\ieee\n",
      "../01_Datasets/bibtex\\sciencedirect\n",
      "\n",
      " ../01_Datasets/bibtex\\acm\n",
      "1 de 15: ../01_Datasets/bibtex\\acm\\acm (1).bib\n",
      "2 de 15: ../01_Datasets/bibtex\\acm\\acm (10).bib\n",
      "3 de 15: ../01_Datasets/bibtex\\acm\\acm (11).bib\n",
      "4 de 15: ../01_Datasets/bibtex\\acm\\acm (12).bib\n",
      "5 de 15: ../01_Datasets/bibtex\\acm\\acm (13).bib\n",
      "6 de 15: ../01_Datasets/bibtex\\acm\\acm (14).bib\n",
      "7 de 15: ../01_Datasets/bibtex\\acm\\acm (2).bib\n",
      "8 de 15: ../01_Datasets/bibtex\\acm\\acm (3).bib\n",
      "9 de 15: ../01_Datasets/bibtex\\acm\\acm (4).bib\n",
      "10 de 15: ../01_Datasets/bibtex\\acm\\acm (5).bib\n",
      "11 de 15: ../01_Datasets/bibtex\\acm\\acm (6).bib\n",
      "12 de 15: ../01_Datasets/bibtex\\acm\\acm (7).bib\n",
      "13 de 15: ../01_Datasets/bibtex\\acm\\acm (8).bib\n",
      "14 de 15: ../01_Datasets/bibtex\\acm\\acm (9).bib\n",
      "15 de 15: ../01_Datasets/bibtex\\acm\\acm.bib\n",
      "Shape df_bibtex\\acm:  (1451, 27)\n",
      "\n",
      " ../01_Datasets/bibtex\\ieee\n",
      "1 de 5: ../01_Datasets/bibtex\\ieee\\ieee01.bib\n",
      "2 de 5: ../01_Datasets/bibtex\\ieee\\ieee02.bib\n",
      "3 de 5: ../01_Datasets/bibtex\\ieee\\ieee03.bib\n",
      "4 de 5: ../01_Datasets/bibtex\\ieee\\ieee04.bib\n",
      "5 de 5: ../01_Datasets/bibtex\\ieee\\ieee05.bib\n",
      "Shape df_bibtex\\ieee:  (466, 18)\n",
      "\n",
      " ../01_Datasets/bibtex\\sciencedirect\n",
      "1 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664900981798.bib\n",
      "2 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664900996606.bib\n",
      "3 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901008566.bib\n",
      "4 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901022672.bib\n",
      "5 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901034634.bib\n",
      "6 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901049390.bib\n",
      "7 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901062597.bib\n",
      "8 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901076219.bib\n",
      "9 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901313104.bib\n",
      "10 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901325707.bib\n",
      "11 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901341946.bib\n",
      "12 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901354705.bib\n",
      "13 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901373091.bib\n",
      "14 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901384565.bib\n",
      "15 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901396061.bib\n",
      "16 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901407156.bib\n",
      "17 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901423447.bib\n",
      "18 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901473402.bib\n",
      "19 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901483538.bib\n",
      "20 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901493338.bib\n",
      "21 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901516463.bib\n",
      "22 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901530660.bib\n",
      "23 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901545863.bib\n",
      "24 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901569366.bib\n",
      "25 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901582313.bib\n",
      "26 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901593466.bib\n",
      "27 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901604197.bib\n",
      "28 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901618620.bib\n",
      "29 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901629453.bib\n",
      "30 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901642131.bib\n",
      "31 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901653154.bib\n",
      "32 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901714428.bib\n",
      "33 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901727203.bib\n",
      "34 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901739254.bib\n",
      "35 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901753759.bib\n",
      "36 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901771138.bib\n",
      "37 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901780783.bib\n",
      "38 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901790793.bib\n",
      "39 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901802926.bib\n",
      "40 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901814134.bib\n",
      "41 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901904068.bib\n",
      "42 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901914229.bib\n",
      "43 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901925196.bib\n",
      "44 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901936569.bib\n",
      "45 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901948081.bib\n",
      "46 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901957848.bib\n",
      "47 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901969577.bib\n",
      "48 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901979356.bib\n",
      "49 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664901990073.bib\n",
      "50 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664902039403.bib\n",
      "51 de 51: ../01_Datasets/bibtex\\sciencedirect\\ScienceDirect_citations_1664902053739.bib\n",
      "Shape df_bibtex\\sciencedirect:  (4858, 22)\n",
      "\n",
      "Shape df_all_raw:  (6775, 27)\n"
     ]
    }
   ],
   "source": [
    "#pd\n",
    "list_folders = []\n",
    "for folder in glob.glob(f'../01_Datasets/bibtex/*'):\n",
    "  print(folder)\n",
    "  list_folders.append(folder)\n",
    "\n",
    "list_df = []\n",
    "for f in list_folders:\n",
    "  print('\\n',f)\n",
    "  df_temp = load_bib(f) #def load_bib\n",
    "  list_df.append(df_temp)\n",
    "df_all_raw = pd.concat(list_df)\n",
    "df_all_raw.to_csv('../01_Datasets/output/df_all_raw.csv', index = False)\n",
    "print('\\nShape df_all_raw: ',df_all_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features renaming / selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\n",
      "author              object\n",
      "title               object\n",
      "keywords            object\n",
      "abstract            object\n",
      "year                object\n",
      "type_publication    object\n",
      "doi                 object\n",
      "issn                object\n",
      "isbn                object\n",
      "publisher           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#pyspark.pandas (ps)\n",
    "df_all_raw = ps.read_csv('../01_Datasets/output/df_all_raw.csv')\n",
    "df_all = df_all_raw.copy()\n",
    "df_all.rename(columns={'ENTRYTYPE': 'type_publication'}, inplace = True)\n",
    "cols_to_keep = ['author', 'title', 'keywords', 'abstract', 'year', 'type_publication', 'doi', 'issn', 'isbn','publisher']\n",
    "df_all = df_all[cols_to_keep]\n",
    "df_all.head()\n",
    "print(type(df_all))\n",
    "print(df_all.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\pysparkenv\\lib\\site-packages\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: `to_pandas` loads all data into the driver's memory. It should only be used if the resulting pandas DataFrame is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.pandas.frame.DataFrame'>\n",
      "author               object\n",
      "title                object\n",
      "keywords             object\n",
      "abstract             object\n",
      "year                float64\n",
      "type_publication     object\n",
      "doi                  object\n",
      "issn                 object\n",
      "isbn                 object\n",
      "publisher            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Converting from ps to pd\n",
    "df_all = df_all.to_pandas()\n",
    "print(type(df_all))\n",
    "\n",
    "#Adjusting \"year\" feature dtype\n",
    "df_all['year'] = pd.to_numeric(df_all['year'], errors = 'coerce')\n",
    "df_all['year'] = df_all['year'].fillna(0).astype('int64', errors = 'raise')\n",
    "df_all['year'] = df_all['year'].map(lambda x: np.nan if x > 2022 else np.nan if x < 1900 else x)\n",
    "\n",
    "# #Adjusting \"doi\" feature\n",
    "df_all['doi'] = df_all['doi'].apply(lambda x: np.nan if x != x else x.split('doi.org/')[-1] if x is not None else x)\n",
    "\n",
    "#Sorting values by \"year\"\n",
    "df_all = df_all.sort_values('title')\n",
    "\n",
    "#Converting from pd to ps\n",
    "df_all = ps.from_pandas(df_all)\n",
    "print(type(df_all))\n",
    "print(df_all.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropna:  (8904, 10)\n",
      "Shape after dropna:  (6769, 10)\n"
     ]
    }
   ],
   "source": [
    "#ps\n",
    "#Dropna\n",
    "print('Shape before dropna: ', df_all.shape)\n",
    "df_all.dropna(subset = ['doi'], axis = 0, inplace = True)\n",
    "print('Shape after dropna: ', df_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting to SQlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\pysparkenv\\lib\\site-packages\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: `to_pandas` loads all data into the driver's memory. It should only be used if the resulting pandas DataFrame is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dbfile = '../03_OutputFiles/doi.db'\n",
    "tabela = 'bib'\n",
    "db = sqlite3.connect(dbfile)\n",
    "sqlDataTypes={}\n",
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype.kind == 'i':  \n",
    "        sqlDataTypes[c]='INTEGER'\n",
    "    elif df_all[c].dtype.kind == 'f':\n",
    "        sqlDataTypes[c]='REAL'\n",
    "    else:\n",
    "        sqlDataTypes[c]='TEXT'\n",
    "\n",
    "#Converting from ps to pd\n",
    "df_all = df_all.to_pandas()\n",
    "print(type(df_all))\n",
    "\n",
    "df_all.to_sql(tabela, index=False, if_exists='replace', dtype=sqlDataTypes, con=db)   \n",
    "db.commit()\n",
    "db.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)\n",
       "0      6769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>type_publication</th>\n",
       "      <th>doi</th>\n",
       "      <th>issn</th>\n",
       "      <th>isbn</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendors</td>\n",
       "      <td>\"\"intelligent\"\" curriculum). In spite of the ...</td>\n",
       "      <td>data integration, collaboration, learning anal...</td>\n",
       "      <td>\"Learning analytics are rapidly being implemen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and practitioners</td>\n",
       "      <td>in contrast</td>\n",
       "      <td>https://doi.org/10.1145/2330601.2330605</td>\n",
       "      <td>predictive models</td>\n",
       "      <td>sentiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607; 95% CI</td>\n",
       "      <td>$30</td>\n",
       "      <td>971 cases and 3</td>\n",
       "      <td>respectively. Sepsis conferred the greatest e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$28</td>\n",
       "      <td>$38</td>\n",
       "      <td>$28</td>\n",
       "      <td>508)</td>\n",
       "      <td>597 to $43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhargav, Samarth and Sidiropoulos, Georgios an...</td>\n",
       "      <td>'It's on the Tip of My Tongue': A New Dataset...</td>\n",
       "      <td>known item retrieval, tip of the tongue known ...</td>\n",
       "      <td>The tip of the tongue known-item retrieval (TO...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3488560.3498421</td>\n",
       "      <td>None</td>\n",
       "      <td>9781450391320</td>\n",
       "      <td>Association for Computing Machinery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feger, Sebastian S. and Wozniak, Pawe\\l{} W. a...</td>\n",
       "      <td>'Yes, I Comply!': Motivations and Practices a...</td>\n",
       "      <td>reuse, research data management, human data in...</td>\n",
       "      <td>As science becomes increasingly data-intensive...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1145/3415212</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Association for Computing Machinery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feger, Sebastian S. and Wozniak, Pawe\\l{} W. a...</td>\n",
       "      <td>'Yes, I Comply!': Motivations and Practices a...</td>\n",
       "      <td>reuse, research data management, human data in...</td>\n",
       "      <td>As science becomes increasingly data-intensive...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1145/3415212</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Association for Computing Machinery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              author                                              title                                           keywords                                           abstract    year    type_publication                      doi  \\\n",
       "0                                            vendors   \"\"intelligent\"\" curriculum). In spite of the ...  data integration, collaboration, learning anal...  \"Learning analytics are rapidly being implemen...     NaN   and practitioners              in contrast   \n",
       "1                                        607; 95% CI                                                $30                                    971 cases and 3   respectively. Sepsis conferred the greatest e...     NaN                 $28                      $38   \n",
       "2  Bhargav, Samarth and Sidiropoulos, Georgios an...   'It's on the Tip of My Tongue': A New Dataset...  known item retrieval, tip of the tongue known ...  The tip of the tongue known-item retrieval (TO...  2022.0       inproceedings  10.1145/3488560.3498421   \n",
       "3  Feger, Sebastian S. and Wozniak, Pawe\\l{} W. a...   'Yes, I Comply!': Motivations and Practices a...  reuse, research data management, human data in...  As science becomes increasingly data-intensive...  2020.0             article          10.1145/3415212   \n",
       "4  Feger, Sebastian S. and Wozniak, Pawe\\l{} W. a...   'Yes, I Comply!': Motivations and Practices a...  reuse, research data management, human data in...  As science becomes increasingly data-intensive...  2020.0             article          10.1145/3415212   \n",
       "\n",
       "                                      issn                isbn                            publisher  \n",
       "0  https://doi.org/10.1145/2330601.2330605   predictive models                           sentiments  \n",
       "1                                      $28                508)                           597 to $43  \n",
       "2                                     None       9781450391320  Association for Computing Machinery  \n",
       "3                                     None                None  Association for Computing Machinery  \n",
       "4                                     None                None  Association for Computing Machinery  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd\n",
    "#Check db content\n",
    "db = sqlite3.connect(dbfile)\n",
    "\n",
    "tabela = 'bib'\n",
    "#imoveisCaros = pd.read_sql_query(f'select * from \"{tabela}\" where preco>1000000', db)\n",
    "query_bib = pd.read_sql_query(f'select * from {tabela} LIMIT 10', db)\n",
    "display(pd.read_sql_query(f'select count(*) from {tabela}', db))\n",
    "query_bib.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 03_OutputFiles if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../03_OutputFiles/'):\n",
    "  os.makedirs('../03_OutputFiles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating yaml file if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../05_Config/configuration.yaml read successfully\n",
      "Output extensions options:  ['json', 'csv']\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"../05_Config/configuration.yaml\"):\n",
    "  configuration_dict = {\n",
    "        'output_extensions': ['csv', 'json', 'yaml']\n",
    "    }\n",
    "  with open('05_Config/configuration.yaml', 'w') as yamlfile:\n",
    "    data = yaml.dump(configuration_dict, yamlfile)\n",
    "\n",
    "configuration_file = read_yaml(\"../05_Config/configuration.yaml\")\n",
    "\n",
    "\n",
    "print(\"Output extensions options: \", configuration_file['output_extensions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading yaml file and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all.csv successfully written\n",
      "df_all.json successfully written\n",
      "df_all.yaml successfully written\n"
     ]
    }
   ],
   "source": [
    "for extension_name in configuration_file['output_extensions']:\n",
    "  if extension_name == 'csv':\n",
    "    write_csv(df_all, 'df_all')\n",
    "  elif extension_name == 'json':\n",
    "    write_json(df_all, 'df_all')\n",
    "  elif extension_name == 'yaml':\n",
    "    write_yaml(df_all, 'df_all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pysparkenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d72600fe25ea01fed8a8bd5b701f41dfab9fe768d304343d1f083959fb332c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
