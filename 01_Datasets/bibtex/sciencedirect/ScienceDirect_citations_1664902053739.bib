@incollection{ZHANG20221075,
title = {How Digital Twins are Propelling Metals Industry to Next Generation Decision-Making: A Practitioner’s View},
editor = {Yoshiyuki Yamashita and Manabu Kano},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {49},
pages = {1075-1080},
year = {2022},
booktitle = {14th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-323-85159-6.50179-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323851596501792},
author = {Yale Zhang and Mitren Sukhram and Ian Cameron},
keywords = {Digital Twin, Analytics, Decision-making, Mining and Metals, Blast Furnace},
abstract = {The digital twin is a technology to digitally transform asset lifecycle in the metals industry, from improving project delivery to empowering operational intelligence toward next-generation decision-making. In this paper, Hatch’s digital twin framework is presented and demonstrated using a real-world blast furnace twin example, followed by development practice and lessons learned from our practice experience.}
}
@article{LUO2022100072,
title = {2022 BenchCouncil International Symposium on benchmarking, measuring and optimizing (Bench 2022) call for papers},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {2},
number = {3},
pages = {100072},
year = {2022},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2022.100072},
url = {https://www.sciencedirect.com/science/article/pii/S277248592200059X},
author = {Chunjie Luo and Wanling Gao},
keywords = {Bench 2022, Bench22, Call for papers},
abstract = {Sponsored and organized by the International Open Benchmark Council (BenchCouncil), the Bench conference encompasses a wide range of topics in benchmarking, measurement, evaluation methods, and tools. Bench’s multi-disciplinary emphasis provides an ideal environment for developers and researchers from the architecture, data management, algorithm, system, network, dataset, and application communities to discuss practical and theoretical work covering workload characterization, benchmarks and tools, evaluation, measurement and optimization, and dataset generation. The Bench conferences have been successfully held for four series from 2018 to 2021 and attracted plenty of paper submissions and participants. Bench 2022 will be held virtually on Nov. 7–9, 2022, and invites manuscripts describing original work in benchmarking, measuring, and optimizing. The conference website is https://www.benchcouncil.org/bench2022/index.html.}
}
@incollection{MACCARTHY20223,
title = {Chapter 1 - The Digital Supply Chain—emergence, concepts, definitions, and technologies},
editor = {Bart L. MacCarthy and Dmitry Ivanov},
booktitle = {The Digital Supply Chain},
publisher = {Elsevier},
pages = {3-24},
year = {2022},
isbn = {978-0-323-91614-1},
doi = {https://doi.org/10.1016/B978-0-323-91614-1.00001-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323916141000010},
author = {Bart L. MacCarthy and Dmitry Ivanov},
keywords = {Blockchain, Digital supply chain, Digital twins, Internet of things, Smart factory, Supply chain analytics, Cloud computing},
abstract = {Advances in technology, rapid globalization, trade liberalization, and increased regulation have shaped supply chains in the last four decades. We examine the impact of digitalization on contemporary and future supply chains. Digitalization potentially enables a strong digital thread connecting and mirroring an entire physical supply chain. We provide an overview of the principal technologies and systems enabling the Digital Supply Chain, including Smart Factories, Smart Warehouses, Smart Logistics, Cloud-based systems, and digital platforms. We discuss the computational engines enabled by Analytics, Data Science, and Artificial Intelligence and the emerging technologies likely to influence future supply chains—Blockchain, Digital Twins, Internet of Things, 5G, Edge, and Fog computing. The technologies offering the most promise in linking the virtual and physical worlds to improve supply chain performance are noted. We describe an evolving spectrum from digitally immature to digitally enabled and digitally transformed supply chains. We provide both narrow and broad definitions for future Digital Supply Chains. The transformative effects of the digitalization of supply chains will affect supply systems in diverse ways. Data-rich supply chain ecosystems will provide many new opportunities but will also give rise to many challenges that require continued analysis and evaluation by researchers and practitioners.}
}
@incollection{MIERONKOSKI202225,
title = {CHAPTER 2 - Smart home technology for geriatric rehabilitation and the Internet of Things},
editor = {Mohamed-Amine Choukou and Shabbir Syed-Abdul},
booktitle = {Smart Home Technologies and Services for Geriatric Rehabilitation},
publisher = {Academic Press},
pages = {25-42},
year = {2022},
isbn = {978-0-323-85173-2},
doi = {https://doi.org/10.1016/B978-0-323-85173-2.00006-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323851732000060},
author = {Riitta Mieronkoski and Iman Azimi and Lydia Sequeira and Laura-Maria Peltonen},
keywords = {Smart home technology, geriatric rehabilitation, Internet of Things},
abstract = {Geriatric rehabilitation is an interactive process between a patient and health professional aiming to maintain or restore the best possible function in various areas of life. The Internet of Things (IoT)-based systems offer new means to support geriatric rehabilitation. IoT-based systems consist of multiple technologies embedded with sensors and software to gather and exchange information with systems over the Internet. In addition to offering means for measuring and monitoring health conditions, these technologies may enable real-time and smooth data exchange between professionals to support care provision. IoT-based systems may have a major role in ensuring effective and equally accessible rehabilitation to the geriatric population. However, many issues warrant attention for the safe and efficient development and implementation of these IoT-based systems. This chapter explores contemporary IoT-based technologies available for geriatric rehabilitation, the geriatric rehabilitation service user as IoT user, and potential and challenges with the use of these technologies in geriatric rehabilitation.}
}
@incollection{FABBECOSTES2022289,
title = {Chapter 17 - Automotive supply chain digitalization: lessons and perspectives},
editor = {Bart L. MacCarthy and Dmitry Ivanov},
booktitle = {The Digital Supply Chain},
publisher = {Elsevier},
pages = {289-308},
year = {2022},
isbn = {978-0-323-91614-1},
doi = {https://doi.org/10.1016/B978-0-323-91614-1.00017-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323916141000174},
author = {Nathalie Fabbe-Costes and Lucie Lechaptois},
keywords = {Automotive industry, Car manufacturer, Digital technologies, Digitalization process, Supply chain digitalization},
abstract = {Supply chain (SC) digitalization in the automotive industry is an old story but one that raises many contemporary strategic issues. The objective of this chapter is to better understand the complexity of SC digitalization and gain greater insights into its dynamics. We combine a historical overview of the evolving process of SC digitalization in the industry with the analysis of a specific case: one car manufacturer's ongoing SC digitalization journey. The evolution of automotive SCs and their digitalization falls into five main historical eras. Digitalization has an impact on all SC management processes from the design of cars to their end-of-life. It is a complex, multifactor, multilayer, and multiactor coevolving process. Digital technologies are a major factor of change but are also combining with other macro trends in the sector. Today's automotive sector has become a complex ecosystem with new players and stakeholders. External factors interact with SC digitalization strategies, resulting in multiple projects involving heterogeneous stakeholders. We highlight the complexity of the decision-making processes on whether to adopt specific technologies, and the strategic, organizational, and operational challenges they bring. We note the changes affecting the future of mobility solutions, which in turn will affect SC digitalization in the sector.}
}
@article{CHEN2022494,
title = {Application of deep learning to auto-delineation of target volumes and organs at risk in radiotherapy},
journal = {Cancer/Radiothérapie},
volume = {26},
number = {3},
pages = {494-501},
year = {2022},
issn = {1278-3218},
doi = {https://doi.org/10.1016/j.canrad.2021.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S1278321821002547},
author = {M. Chen and S. Wu and W. Zhao and Y. Zhou and Y. Zhou and G. Wang},
keywords = {Radiotherapy, Target volumes, Organs at risk, Artificial intelligence, Deep learning, Radiothérapie, Volumes cibles, Organes à risque, Intelligence artificielle, Apprentissage profond},
abstract = {The technological advancement heralded the arrival of precision radiotherapy (RT), thereby increasing the therapeutic ratio and decreasing the side effects from treatment. Contour of target volumes (TV) and organs at risk (OARs) in RT is a complicated process. In recent years, automatic contouring of TV and OARs has rapidly developed due to the advances in deep learning (DL). This technology has the potential to save time and to reduce intra- or inter-observer variability. In this paper, the authors provide an overview of RT, introduce the concept of DL, summarize the data characteristics of the included literature, summarize the possible challenges for DL in the future, and discuss the possible research directions.
Résumé
Le contour des volumes-cibles et des organes à risque en radiothérapie est un processus compliqué. Ces dernières années, la délinéation automatique des volumes-cibles et des organes à risque s’est rapidement développée en raison des progrès du deep learning. Cette technologie a le potentiel de gagner du temps et de réduire la variabilité pour un même – ou entre les – observateurs. Dans cet article, les auteurs donnent un aperçu de la radiothérapie, introduisent le concept de deep learning, résument les caractéristiques des données de la littérature incluse, résument les défis possibles pour le deep learning à l’avenir et discutent des directions de recherche possibles.}
}
@article{2022238,
title = {Abstracts},
journal = {Fuel and Energy Abstracts},
volume = {63},
number = {3},
pages = {238-332},
year = {2022},
issn = {0140-6701},
doi = {https://doi.org/10.1016/j.fueleneab.2022.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0140670122000224}
}
@incollection{FUENTES2022125,
title = {Chapter 7 - Modern approaches to precision and digital viticulture},
editor = {J. Miguel Costa and Sofia Catarino and José M. Escalona and Piergiorgio Comuzzo},
booktitle = {Improving Sustainable Viticulture and Winemaking Practices},
publisher = {Academic Press},
pages = {125-145},
year = {2022},
isbn = {978-0-323-85150-3},
doi = {https://doi.org/10.1016/B978-0-323-85150-3.00015-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323851503000153},
author = {Sigfredo Fuentes and Jorge Gago},
keywords = {Artificial Intelligence, Computer vision, Integrated viticulture, Machine and deep learning, Robotics, Satellite imagery, Unmanned aerial vehicles},
abstract = {New and emerging technologies could play a critical role in the viticulture and winemaking of the future. Climate change has threatened the status quo within the viticultural and wine industry due to increased ambient temperatures, the variability of precipitation, and the increase of climatic risks. These main threats are specifically related to the compression of phenological stages, earlier harvests, many of these within the hottest months producing a dual warming effect. Furthermore, the increase of climatic anomalies, such as floods, frosts, and bushfires, in number, intensity, and window of opportunity within the growing season directly impacts yield and grape and wine quality. The viticulture and winemaking of the future need to have a transformational process to be more predictive rather than only reactive by implementing disruptive technology supported by artificial intelligence.}
}
@incollection{ALSHORBAJI2022375,
title = {Chapter 16 - Health informatics in the Middle East and North Africa},
editor = {Evelyn Hovenga and Heather Grain},
booktitle = {Roadmap to Successful Digital Health Ecosystems},
publisher = {Academic Press},
pages = {375-397},
year = {2022},
isbn = {978-0-12-823413-6},
doi = {https://doi.org/10.1016/B978-0-12-823413-6.00029-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823413600029X},
author = {Najeeb Al-Shorbaji and Dari Alhuwail},
keywords = {Digital health, eHealth, Health systems, ICT, MENA, Middle East & North Africa},
abstract = {This chapter provides a background on the Middle East and North Africa as a diverse region from economic, social, political, and infrastructure points of view. This diversity has resulted into adoption of digital health in the countries of the Region based on health system’s structure and resources available. It provides highlights of the application of digital health in MENA countries ranging from the very simple appointment taking, to fully operational electronic health records systems, telemedicine services, and artificial intelligence. It provides an 8-point ‘Digital Health Innovations and Future Directions’ for a country, including commitment to develop and implement a national strategy and plan of digital health, ICT infrastructure, human resources development, funding, interoperability, priority setting, legal framework, and partnerships.}
}
@article{TAO2022271,
title = {Groundwater level prediction using machine learning models: A comprehensive review},
journal = {Neurocomputing},
volume = {489},
pages = {271-308},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S092523122200282X},
author = {Hai Tao and Mohammed Majeed Hameed and Haydar Abdulameer Marhoon and Mohammad Zounemat-Kermani and Salim Heddam and Sungwon Kim and Sadeq Oleiwi Sulaiman and Mou Leong Tan and Zulfaqar Sa’adi and Ali Danandeh Mehr and Mohammed Falah Allawi and S.I. Abba and Jasni Mohamad Zain and Mayadah W. Falah and Mehdi Jamei and Neeraj Dhanraj Bokde and Maryam Bayatvarkeshi and Mustafa Al-Mukhtar and Suraj Kumar Bhagat and Tiyasha Tiyasha and Khaled Mohamed Khedher and Nadhir Al-Ansari and Shamsuddin Shahid and Zaher Mundher Yaseen},
keywords = {State-of-the-art, Machine learning, Groundwater level, Input parameters, Prediction performance, Catchment sustainability},
abstract = {Developing accurate soft computing methods for groundwater level (GWL) forecasting is essential for enhancing the planning and management of water resources. Over the past two decades, significant progress has been made in GWL prediction using machine learning (ML) models. Several review articles have been published, reporting the advances in this field up to 2018. However, the existing review articles do not cover several aspects of GWL simulations using ML, which are significant for scientists and practitioners working in hydrology and water resource management. The current review article aims to provide a clear understanding of the state-of-the-art ML models implemented for GWL modeling and the milestones achieved in this domain. The review includes all of the types of ML models employed for GWL modeling from 2008 to 2020 (138 articles) and summarizes the details of the reviewed papers, including the types of models, data span, time scale, input and output parameters, performance criteria used, and the best models identified. Furthermore, recommendations for possible future research directions to improve the accuracy of GWL prediction models and enhance the related knowledge are outlined.}
}
@article{DARMONT2022101936,
title = {Data processing in modern distributed architectures},
journal = {Information Systems},
volume = {104},
pages = {101936},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101936},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921001368},
author = {Jérôme Darmont and Boris Novikov and Robert Wrembel and Ladjel Bellatreche}
}
@article{LIMA2022156,
title = {The Benefits of Culture Change in Nursing Homes—Obtaining Nationally Representative Evidence},
journal = {Journal of the American Medical Directors Association},
volume = {23},
number = {1},
pages = {156-160.e9},
year = {2022},
issn = {1525-8610},
doi = {https://doi.org/10.1016/j.jamda.2021.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S1525861021006769},
author = {Julie C. Lima and Pedro Gozalo and Melissa A. Clark and Margot L. Schwartz and Susan C. Miller},
keywords = {Culture change, nursing homes, person-centered care, staff empowerment, Minimum Data Set, secondary data},
abstract = {Objective
Despite face validity and regulatory support, empirical evidence of the benefit of culture change practices in nursing homes (NHs) has been inconclusive. We used rigorous methods and large resident-level cohorts to determine whether NH increases in culture change practice adoption in the domains of environment, staff empowerment, and resident-centered care are associated with improved resident-level quality outcomes.
Design
We linked national panel 2009-2011 and 2016-2017 survey data to Minimum Data Set assessment data to test the impact of increases in each of the culture change domains on resident quality outcomes.
Setting and Participants
The sample included 1584 nationally representative US NHs that responded to both surveys, and more than 188,000 long-stay residents cared for in the pre- and/or postsurvey periods.
Methods
We used multivariable logistic regression with robust standard errors and a difference-in-differences methodology. Controlling for the endogeneity between increases in culture change adoption and NH characteristics that are also related to quality outcomes, we tested whether pre-post quality outcome differences (ie, improvements in outcomes) were greater for residents in NHs with culture change increases vs in those without such increases.
Results
NH performance on most quality indicators improved, but improvement was not significantly different by whether NHs increased or did not increase their culture change domain practices.
Conclusions and Implications
This study found that increases in an NH’s culture change domain practices were not significantly associated with improved resident-level quality. It describes a number of potential limitations that may have contributed to the null findings.}
}
@incollection{WEVILL202231,
title = {Chapter 2 - Relative performance of support vector machine, decision trees, and random forest classifiers for predicting production success in US unconventional shale plays},
editor = {Shuvajit Bhattacharya and Haibin Di},
booktitle = {Advances in Subsurface Data Analytics},
publisher = {Elsevier},
pages = {31-62},
year = {2022},
isbn = {978-0-12-822295-9},
doi = {https://doi.org/10.1016/B978-0-12-822295-9.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222959000078},
author = {Jessica Wevill and Alex Bromhead and Kate Evans and Jeffrey Yarus and Cédric M. John},
keywords = {Decision tree, Machine learning, Random forest, SGD-SVM, Shale plays},
abstract = {Unconventional shale reservoirs have revolutionized the energy industry. However, the prediction of production based on reservoir geology characterization has largely focused on sweet spot definition rather than on over-arching production trends across multiple plays. This study uses machine learning (ML) techniques to analyze the relationships between well log data and production success within seven North American shale plays. Three ML algorithms were evaluated: stochastic gradient descent kernel trained support-vector machine (SGD-SVM), decision tree (DT), and random forest (RF) classifier. Accuracy of predictions using the SGD-SVM and DT classifiers did not exceed 55%. A fine-tuned RF classifier is the most successful method at predicting well success based on normalized initial production, with an accuracy of 97%. To achieve this result, the RF is trained on the following input features: average play thickness, pore pressure, TVD, and resource concentration. The main factors impacting performance of our algorithm when trying to predict success in unconventional plays are previous understanding of heterogeneities in individual formations, and consistency of data availability across multiple wells. Despite challenges, ML and the RF method in particular show promising applications in the unconventional petroleum industry as a means to streamline production and data collection.}
}
@article{RAMKUMAR2022100490,
title = {Data science, human intelligence, and therapeutics discovery: An interview with Sean Escola, Saul Kato, and Pavan Ramkumar},
journal = {Patterns},
volume = {3},
number = {4},
pages = {100490},
year = {2022},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2022.100490},
url = {https://www.sciencedirect.com/science/article/pii/S2666389922000757},
author = {Pavan Ramkumar and Saul Kato and G. Sean Escola},
abstract = {Sean Escola, Saul Kato, and Pavan Ramkumar explain the importance of data science in their research. They have developed a simple non-parametric statistical method called the Rank-to-Group (RTG) score that identifies hierarchical confounder effects in raw data and machine learning-derived data embeddings. This approach should be generally useful in experiment-analysis cycles and to ensure confounder robustness in machine learning models.}
}
@incollection{GUO2022551,
title = {Chapter 22 - Sensing and monitoring of urban roadway traffic state with large-scale ride-sourcing vehicles},
editor = {Amir H. Alavi and Maria Q. Feng and Pengcheng Jiao and Zahra Sharif-Khodaei},
booktitle = {The Rise of Smart Cities},
publisher = {Butterworth-Heinemann},
pages = {551-582},
year = {2022},
isbn = {978-0-12-817784-6},
doi = {https://doi.org/10.1016/B978-0-12-817784-6.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128177846000035},
author = {Shuocheng Guo and Xinwu Qian and Sagar Dasgupta and Mizanur Rahman and Steven Jones},
keywords = {Traffic sensing, Ride-sourcing vehicle, Sensor observability},
abstract = {The monitoring of urban roadway traffic state is an essential task for the efficient operation of urban transportation system and mobility of urban population at scale. Current practices of sensing urban traffic are primarily based on embedded sensors (e.g., loop detector) on a roadway or roadside sensors (e.g., roadside camera) and the crowdsourcing data from massive urban travelers through mobile application such as Google traffic data, which are associated with high costs or high degree of uncertainty due to lack of sufficient data from users. This chapter investigates an innovative approach for monitoring urban roadway traffic state with large-scale ride-sourcing vehicles (RVs). An example can be monitoring roadway traffic state through sensing the state of entire fleet of for-hire vehicles such as Uber and Lyft. The RVs serve as a connected mobile sensor network, which ensures sufficient coverage in high demand areas and can be routed to supply additional observations in other areas when off duty. Moreover, the RV fleet can sense, monitor, and predict overall roadway traffic condition that is beyond traditional traffic sensing techniques, such as future travel demand and shortage of mobility supply. This chapter reviews current traffic sensing and monitoring techniques and their comparison with RV-based approach. We present a real-time RV-based roadway traffic sensing and monitoring framework along with a computational architecture integrating edge and cloud computing concept. Finally, we present a case study on the reliability of the monitoring and prediction of roadway network travel time using real-world RV trajectory data. We report that while only 65% of road segments are explicitly traversed by RVs, over 80% of total network information can be inferred from the actual observations, and only less than 10% of additional links need to be visited in order to reach the 100% network coverage rate.}
}
@incollection{KAMBOURIS202275,
title = {Chapter 6 - Nonmicrobial biothreats: DNA, prions, and (bio)regulators/(bio)toxins},
editor = {Manousos E. Kambouris},
booktitle = {Genomics in Biosecurity},
publisher = {Academic Press},
pages = {75-91},
year = {2022},
series = {Translational and Applied Genomics},
isbn = {978-0-323-85236-4},
doi = {https://doi.org/10.1016/B978-0-323-85236-4.00011-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385236400011X},
author = {Manousos E. Kambouris and Georgios Skiniotis},
keywords = {Prions, Bioregulators, Toxins, Antitoxins, Antidotes, Naked DNA, Biochemical agents, Structural studies, Electron microscopy, Spectrometry},
abstract = {Biochemical agents, originally comprising toxins and bioregulators but belatedly enriched by prions and naked DNAs, comprise a highly heterogeneous category of biorisk factors minimally apprehensible by standard genomic approaches, even the most elaborate ones. Capable of serious detrimental effects, with their disruptive potential multiplied by the terror they cause after millennia of illicit use and due to the prospect of highly lethal bioengineered spinoffs, they are of quintessential importance in every biosecurity-oriented approach. Detecting and tackling these threats requires cutting-edge approaches able to prognose functional specifics and structure-function correlations so as to predict activity, characteristics, and vulnerabilities of such agents, in a process reminiscent of standard pharmacological research, so as to device proper response strategies in an integrated biosecurity context.}
}
@incollection{ALEMANY202297,
title = {5 - Data management and processing of 3D body scans},
editor = {Norsaadah Zakaria},
booktitle = {Digital Manufacturing Technology for Sustainable Anthropometric Apparel},
publisher = {Woodhead Publishing},
pages = {97-116},
year = {2022},
series = {The Textile Institute Book Series},
isbn = {978-0-12-823969-8},
doi = {https://doi.org/10.1016/B978-0-12-823969-8.00007-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239698000071},
author = {Sandra Alemany and Alfredo Remon and Alfredo Ballester and Juan {Vicente Durá} and Beatriz Nácher and Eduardo Parrilla and Juan {Carlos González}},
keywords = {Anthropometry, 3D body scanning, 3D body avatar, 3D body model, anthropometry standardization, 3D body template, 3D body processing, rigging, data-driven models, shape analysis, fitting, sizing tables, mannequins},
abstract = {Since the appearance of 3D body scanning technology until today, the progress of research has delivered several solutions to be offered to the customers’ clothing needs as to what fits better the body sizes and shapes. These solutions range from sizing tables and 3D body mannequins that may improve the garment development process to new mobile apps that scan the body using a smartphone and provide to the user new services of size selection or customization. All this progress is underpinned by databases of body measurements or 3D body scans and reveals the importance of the access to this data. This chapter includes a review of the value chain of 3D body data: processing, 3D body model creation, standardization, and anonymization described as key elements to build a future sustainable ecosystem used to grow and update 3D body databases.}
}
@article{ZHANG2022171,
title = {Information fusion for edge intelligence: A survey},
journal = {Information Fusion},
volume = {81},
pages = {171-186},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521002438},
author = {Yin Zhang and Chi Jiang and Binglei Yue and Jiafu Wan and Mohsen Guizani},
keywords = {Information fusion, Multisource, Real-time, Event-driven, Context-aware},
abstract = {Edge intelligence capability is expected to enable the development of a new paradigm integrated with edge computing and artificial intelligence. However, due to the multisource nature, heterogeneity, and a large scale of the sensory data, it is necessary to improve the data processing and decision-making capacity for the edges. Hence, this paper asserts that information fusion is an important technique to power the capacity of edge intelligence in terms of collection, communication, computing, caching, control and collaboration. Specifically, it provides a comprehensive investigation of four representative scenarios assisted by information fusion at the edge, i.e., multisource information fusion, real-time information fusion, event-driven information fusion, and context-aware information fusion. Moreover, it discusses the future directions and open issues in this field.}
}
@article{MACAS2022109032,
title = {A survey on deep learning for cybersecurity: Progress, challenges, and opportunities},
journal = {Computer Networks},
volume = {212},
pages = {109032},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109032},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622001864},
author = {Mayra Macas and Chunming Wu and Walter Fuertes},
keywords = {Cybersecurity, Artificial intelligence, Machine learning, Deep learning, Cyber-threat, Botnets, Intrusion detection, Spam filtering, Encrypted traffic analysis},
abstract = {As the number of Internet-connected systems rises, cyber analysts find it increasingly difficult to effectively monitor the produced volume of data, its velocity and diversity. Signature-based cybersecurity strategies are unlikely to achieve the required performance for detecting new attack vectors. Moreover, technological advances enable attackers to develop sophisticated attack strategies that can avoid detection by current security systems. As the cyber-threat landscape worsens, we need advanced tools and technologies to detect, investigate, and make quick decisions regarding emerging attacks and threats. Applications of artificial intelligence (AI) have the potential to analyze and automatically classify vast amounts of Internet traffic. AI-based solutions that automate the detection of attacks and tackle complex cybersecurity problems are gaining increasing attention. This paper comprehensively presents the promising applications of deep learning, a subfield of AI based on multiple layers of artificial neural networks, in a wide variety of security tasks. Before critically and comparatively surveying state-of-the-art solutions from the literature, we discuss the key characteristics of representative deep learning architectures employed in cybersecurity applications, we introduce the emerging trends in deep learning, and we provide an overview of necessary resources like a generic framework and suitable datasets. We identify the limitations of the reviewed works, and we bring forth a vision of the current challenges of the area, providing valuable insights and good practices for researchers and developers working on related problems. Finally, we uncover current pain points and outline directions for future research to address them.}
}
@incollection{BEJA202267,
title = {Chapter Two - Data services in ocean science with a focus on the biology∗},
editor = {Giuseppe Manzella and Antonio Novellino},
booktitle = {Ocean Science Data},
publisher = {Elsevier},
pages = {67-129},
year = {2022},
isbn = {978-0-12-823427-3},
doi = {https://doi.org/10.1016/B978-0-12-823427-3.00006-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234273000062},
author = {Joana Beja and Leen Vandepitte and Abigail Benson and Anton {Van de Putte} and Dan Lear and Daphnis {De Pooter} and Gwenaëlle Moncoiffé and John Nicholls and Nina Wambiji and Patricia Miloslavich and Vasilis Gerovasileiou},
keywords = {Data challenges, Data services, Essential variables, Historical data, Indigenous knowledge, Marine biodiversity, Marine data management, Research data life cycle},
abstract = {Biological ocean science has a long history; it goes back millennia, whereas the related data services have emerged in the recent digital era of the past decades. To understand where we come from—and why data services are so important—we will start by taking you back to the rise in the study of marine biology—marine biodiversity—and its key players, before immersing ourselves in the data life cycle, past and present joint global initiatives, and systems that allow(ed) scientists to more easily access biological data, online services through some simple keyboard strokes, and the many challenges we still encounter on a daily basis when dealing with these types of data.}
}
@incollection{FREMIN2022673,
title = {Chapter 19 - Technical (engineering) advancements enabling deepwater exploration and production},
editor = {Jon R. Rotzien and Cindy A. Yeilding and Richard A. Sears and F. Javier Hernández-Molina and Octavian Catuneanu},
booktitle = {Deepwater Sedimentary Systems},
publisher = {Elsevier},
pages = {673-692},
year = {2022},
isbn = {978-0-323-91918-0},
doi = {https://doi.org/10.1016/B978-0-323-91918-0.00019-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323919180000190},
author = {Lori Fremin and Richard A. Sears and Charlie Williams},
keywords = {Deepwater, Well engineering, Production engineering, Offshore structure, Development planning, Pipelines, Flow assurance, Surveillance, Remote monitoring, Emerging technology},
abstract = {The oil and gas industry has a long history of developing the technologies necessary to exploit discovered resources. In this regard, deepwater is no exception. Since first stepping offshore in the early 20th century, the industry has had to solve a variety of technical challenges to drill in deeper water depths and economically develop and produce the discovered resources. This chapter looks at some of these important engineering advancements, describing them in the context of the deepwater reservoirs and fluids that are characterized in the other chapters of this book. Without these technology advancements, deepwater oil and gas resources could not have been successfully exploited and much of the detailed geological understanding of deepwater reservoirs and petroleum systems would never have been developed. This chapter is dedicated to the engineering pioneers in the oil and gas industry who were willing to step off the beach into the sea in the early 1900s, move over the horizon and out of sight of land in the 1940s, and 50years later, explore for and develop oil and gas resources in nearly 10,000ft of water.}
}
@incollection{KIDO2022161,
title = {Chapter 10 - Explore the RNA-sequencing and the next-generation sequencing in crops responding to abiotic stress},
editor = {Pradeep Sharma and Dinesh Yadav and Rajarshi Kumar Gaur},
booktitle = {Bioinformatics in Agriculture},
publisher = {Academic Press},
pages = {161-175},
year = {2022},
isbn = {978-0-323-89778-5},
doi = {https://doi.org/10.1016/B978-0-323-89778-5.00005-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323897785000052},
author = {Éderson Akio Kido and José Ribamar Costa Ferreira-Neto and Eliseu Binneck and Manassés {da Silva} and Wilson {da Silva} and Ana Maria Benko-Iseppon},
keywords = {Transcriptomic, bioinformatic, RNA-Seq, SuperSAGE, crop, breeding, abiotic stress, drought, salinity, environmental stress, gene expression, RT-qPCR, plant biotechnology},
abstract = {Most of the environmental stresses damage crops provoking economic losses. Molecular characterization of genotypes identifying suitable genes helps breeders to develop abiotic stress-tolerant crops. Among the omics technologies, transcriptomics represents the most informative techniques for global gene expression profiling of an organism, organ/tissue, or even cell at a given snapshot in time. In this context the next-generation sequencing technologies revolutionized plant transcriptomics, particularly nonmodel plants of economic interest, enhancing the high-throughput data generated from biological samples. This chapter shows an updated RNA-Seq (sequencing of RNA) overview covering scientific reports published in the last 5 years. The assortment of the data-mined RNA-Seq studies concerning relevant issues identified the most studied crops, abiotic stresses, plant organs/tissues, stress-treatment exposition time, global or specific gene expression profiling, noncoding RNA approach, extra omics data, supplementary physiological data, studied accession(s), transcriptome assembly approach, gene expression validation process, relative quantification method, and reference gene(s) in the qPCR assays. Besides, an overall RNA-Seq analysis workflow, covering data generation, raw data processing, and data analysis, was provided, together with some information involving transcriptome assembly, quality of the transcriptome assembly, transcript quantification, differential expression analysis, and annotation/functional analysis. Finally, in the functional genomics topic, the integration of multiomic data stands out, improving our understanding of genetic networks, which helps us to envision machine learning strategies and genome editing applications involving agronomic characteristics. These approaches may help plant breeders identify new genes and related metabolic subpathways associated with relevant agronomic traits.}
}
@incollection{LAMARCA20223,
title = {Chapter 1 - User vs. machine-based seismic attribute selection for unsupervised machine learning techniques: Does human insight provide better results than statistically chosen attributes?},
editor = {Shuvajit Bhattacharya and Haibin Di},
booktitle = {Advances in Subsurface Data Analytics},
publisher = {Elsevier},
pages = {3-30},
year = {2022},
isbn = {978-0-12-822295-9},
doi = {https://doi.org/10.1016/B978-0-12-822295-9.00002-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222959000029},
author = {Karelia {La Marca} and Heather Bedle},
keywords = {Machine learning techniques, Principal component analysis, Self-organized maps},
abstract = {In geosciences, a variety of machine learning (ML) algorithms are currently being employed for multiple purposes, for example, facies classification, fault prediction, and reservoir characterization. Among these are two clustering methods: principal component analysis (PCA) and self-organized maps (SOMs), which provide a fast organization of data into groups or clusters (with no geologic supervision) that aid in preliminary geological interpretation. With increasingly common usage of these techniques, the motivation of this chapter is to investigate the impact of a user-controlled selection of attributes to perform SOM for deepwater seismic facies classification versus a machine-selected result through PCA. Results reveal that whereas an appropriate combination of attributes with a clear interpretation objective enhances the SOM’s results and facilitates the interpreter understanding of the output classes, PCA provides insightful information regarding the contribution of seismic attributes that may not have been initially considered. While machine learning techniques are a powerful “tool” for geological interpretation, user control on initial input attributes and validation of output using an “in-context” interpretation is necessary for an optimal elucidation, at least in unsupervised machine learning methods.}
}
@article{CHARLES2022101742,
title = {Artificial Intelligence for data-driven decision-making and governance in public affairs},
journal = {Government Information Quarterly},
volume = {39},
number = {4},
pages = {101742},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2022.101742},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X22000788},
author = {Vincent Charles and Nripendra P. Rana and Lemuria Carter},
keywords = {Artificial intelligence, Data-driven decision-making, Public governance, Public sector, Research agenda},
abstract = {Literature shows there is a growing interest in studies involving Artificial Intelligence (AI) in the public sector; and while there is evidence of many governmental initiatives that have been established to harness the power of AI, empirical research on the topic and evidence-based insights are rather lacking. The aim of this Special Issue on Artificial Intelligence for Data-Driven Decision-Making and Governance in Public Affairs is to extend both the theoretical and practical boundaries of AI research in the public sector in order to improve governmental decision-making and governance, thus enhancing public value creation. The papers in this special issue focus on AI risks and guidelines, AI governance, the risks of governmental implementation of AI to citizens' privacy, increasing citizen satisfaction through AI-enabled government services, the enablers and challenges of AI implementation in specific public sectors, and using AI to study political opinion. These papers not only advance our knowledge and understanding of the use of AI in government and public governance, but they also help to set out a renewed research agenda. Future research should, among other things, focus on inter- and multi-disciplinary empirical studies that call for the collaboration of a variety of stakeholders; on the longitudinal dynamics of creating public value through the breadth and depth of AI assimilation; and on the investigation of the ethical challenges (particularly data privacy) in AI implementation.}
}
@incollection{2022435,
title = {Index},
editor = {Bart L. MacCarthy and Dmitry Ivanov},
booktitle = {The Digital Supply Chain},
publisher = {Elsevier},
pages = {435-446},
year = {2022},
isbn = {978-0-323-91614-1},
doi = {https://doi.org/10.1016/B978-0-323-91614-1.20001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323916141200014}
}
@incollection{WARREN2022151,
title = {Chapter 8 - Operational aspects of deep learning solutions for Alzheimer’s disease},
editor = {Ahmed A. Moustafa},
booktitle = {Alzheimer's Disease},
publisher = {Academic Press},
pages = {151-173},
year = {2022},
isbn = {978-0-12-821334-6},
doi = {https://doi.org/10.1016/B978-0-12-821334-6.00002-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128213346000028},
author = {Samuel L. Warren and Ahmed A. Moustafa and Dustin {van der Haar}},
keywords = {Alzheimer’s disease, machine learning, deep learning, operational aspects},
abstract = {In this article, we discuss operational aspects of deep learning solutions for Alzheimer’s disease. First, we introduce clinical and neural aspects of Alzheimer’s disease. After that, we discuss traditional computer-aided diagnosis methods, such as support vector machines, random forests, and logistic regressions, which use statistical and machine learning techniques to identify and predict Alzheimer’s disease. We then describe basic operational aspects of the use of deep learning, and how they provide some benefits over traditional computer-aided diagnosis methods. Finally, we describe the advantages and limitations of using deep learning, and future directions on the applications of deep learning to Alzheimer’s disease.}
}
@incollection{HUSSAIN2022179,
title = {Chapter 8 - Application of artificial intelligence and information and communication technology in the grid agricultural industry: business motivation, analytical tools, and challenges},
editor = {B.D. Deebak and Fadi Al-Turjman},
booktitle = {Sustainable Networks in Smart Grid},
publisher = {Academic Press},
pages = {179-205},
year = {2022},
isbn = {978-0-323-85626-3},
doi = {https://doi.org/10.1016/B978-0-323-85626-3.00002-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856263000028},
author = {Adedoyin A. Hussain and Barakat A. Dawood and Chadi Altrjman and Sinem Alturjman and Fadi Al-Turjman},
keywords = {Agriculture industry, information and communication technology, AI, big data, HetNet},
abstract = {Recently, the use of Artificial Intelligence (AI) and Information and Communication Technology (ICT) has been clear in farming applications. A few examinations address the subject of ICT appropriation in flooded agribusiness. The principle idea of AI in agribusiness is its adaptability, precision, and cost-adequacy. This area faces various difficulties for yield growth including inappropriate soil treatment, sickness and irritation pervasion, large information necessities, low yield, and information gaps among ranchers and innovation. This paper tackles these issues by presenting a survey of the uses of AI and ICT in the agricultural business. We summarize and arrange different territories and procedures in which AI and ICT can be applied in rural areas. A unique spotlight is laid on the strength and constraints of the application and the path in using scalable frameworks for higher efficiency. Also, the usage of AI and computer networks in the agricultural industry is presented and discussed. The overview put forward will provide understudies and specialists with up to 90% effectiveness at whatever point considered.}
}
@incollection{FRANCHAK202261,
title = {Chapter Three - Beyond screen time: Using head-mounted eye tracking to study natural behavior},
editor = {Rick O. Gilmore and Jeffrey J. Lockman},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {62},
pages = {61-91},
year = {2022},
booktitle = {New Methods and Approaches for Studying Child Development},
issn = {0065-2407},
doi = {https://doi.org/10.1016/bs.acdb.2021.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065240721000409},
author = {John M. Franchak and Chen Yu},
keywords = {Eye movements, Head-mounted eye tracking, Mobile eye tracking, Ecological validity, Perceptual-motor development, Joint attention, Language development, Computer vision, Social attention},
abstract = {Head-mounted eye tracking is a new method that allows researchers to catch a glimpse of what infants and children see during naturalistic activities. In this chapter, we review how mobile, wearable eye trackers improve the construct validity of important developmental constructs, such as visual object experiences and social attention, in ways that would be impossible using screen-based eye tracking. Head-mounted eye tracking improves ecological validity by allowing researchers to present more realistic and complex visual scenes, create more interactive experimental situations, and examine how the body influences what infants and children see. As with any new method, there are difficulties to overcome. Accordingly, we identify what aspects of head-mounted eye-tracking study design affect the measurement quality, interpretability of the results, and efficiency of gathering data. Moreover, we provide a summary of best practices aimed at allowing researchers to make well-informed decisions about whether and how to apply head-mounted eye tracking to their own research questions.}
}
@incollection{YADAV2022367,
title = {Chapter 22 - Topological parameters, patterns, and motifs in biological networks},
editor = {Dev Bukhsh Singh and Rajesh Kumar Pathak},
booktitle = {Bioinformatics},
publisher = {Academic Press},
pages = {367-380},
year = {2022},
isbn = {978-0-323-89775-4},
doi = {https://doi.org/10.1016/B978-0-323-89775-4.00012-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323897754000122},
author = {Arvind Kumar Yadav and Rohit Shukla and Tiratha Raj Singh},
keywords = {Topological parameters, motif, biological network, graph theory, systems biology, biological pathways, protein–protein interaction, patterns, system biology},
abstract = {Systems biology is an emerging field to study the complex interactions in biological systems. The enormous amount of data generated through high-throughput technologies allows the reconstruction of the biological pathways in a structured and dynamic way at the systems level. Hence, for understating the dynamics of these biological pathways, it is necessary to convert the molecular data in the form of biological pathways. Graph theory is utilized for the modeling of complex biological data. Graphs are used to analyze, simulate, and visualize the biological pathways, such as protein–protein interaction and protein metabolite interaction. Motifs are used for the analysis of complex biological networks. The network motifs describe the local properties of a network and are represented as a small connected subgraph, which is frequently appearing in a network. In this chapter, we have described the structure of biological networks, graph theory including its statistical parameters, network motifs, different types of algorithms, and its role in the biological application.}
}
@incollection{CHIRBA2022265,
title = {Chapter 14 - FDA regulation of adipose cell use in clinical trials and clinical translation},
editor = {Lauren Kokai and Kacey Marra and J. Peter Rubin},
booktitle = {Scientific Principles of Adipose Stem Cells},
publisher = {Academic Press},
pages = {265-310},
year = {2022},
isbn = {978-0-12-819376-1},
doi = {https://doi.org/10.1016/B978-0-12-819376-1.00003-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128193761000032},
author = {Mary Ann Chirba and Veronica Morgan Jones and Patsy Simon and Adam J. Katz},
keywords = {Food and Drug Administration (FDA), Regulation, Adipose tissue, Adipose function, Cell therapy, Real-world evidence, Trial design},
abstract = {This chapter discusses United States Food and Drug Administration (FDA) regulation of adipose-derived stem cell therapies. It begins with the basic facts of what adipose is and what it does (while leaving more detailed discussions to other parts of this publication). It then summarizes the basics of law and regulation as applied to regenerative medicine and describes the FDA's overall risk-based framework for regulating cell therapies. This is followed by a closer examination of the FDA's specific regulation of adipose-derived cell and tissue products. The agency's missteps are identified, and their repercussions for the regulated as well as the regulator are considered. The chapter closes with a brief overview of recent developments in methods and mechanisms for obtaining approval of regenerative products and biologics in general, particularly with regard to real-world evidence and innovative trial design. While not limited to adipose products, this material is potentially relevant to those working in this area.}
}
@incollection{KIRAN2022153,
title = {Chapter 11 - Internet of things and wearables-enabled Alzheimer detection and classification model using stacked sparse autoencoder},
editor = {Hemanth {D. Jude} and Deepak Gupta and Ashish Khanna and Aditya Khamparia},
booktitle = {Wearable Telemedicine Technology for the Healthcare Industry},
publisher = {Academic Press},
pages = {153-168},
year = {2022},
isbn = {978-0-323-85854-0},
doi = {https://doi.org/10.1016/B978-0-323-85854-0.00012-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323858540000125},
author = {Siripuri Kiran and S. Neelakandan and A. Pratapa Reddy and Sonali Goyal and Balajee Maram and V. Chandra Shekhar Rao},
keywords = {Deep learning, IoT, wearables, Alzheimer disease, Classification, Feature extraction},
abstract = {Presently, Internet of Things (IoT) and wearables have become advanced technologies that intend to ease life and aid people in every aspect of life. They find use in smart healthcare where several wearables and IoT devices are used to monitor the health status of the patients. At the same time, Alzheimer’s disease (AD) is a dynamic, permanent, and neuro-degenerative illness that mainly affects elder people and it progressively degrades the efficiency of the brain, thereby affects memories, learning, and behaviors. The advent of machine learning algorithms has led to the design of IoT and wearables-enabled automated AD diagnosis and classification model. In this view, this chapter introduces an effective IoT and wearables-enabled AD detection and classification model using stacked sparse autoencoder (ADC-SSAE). The proposed ADC-SSAE model enables the wearables to collect patient data and medical examination takes place on the captured data. In addition, the region of interest extraction and bilateral filtering based preprocessing take place to raise the image quality. Besides, local texton XOR patterns (LTxXORP) model is applied as a feature extractor to derive a useful set of features from the preprocessed data. At last, SSAE model is utilized as a classification model to determine the proper class labels of the applied input data. An extensive range of simulations was performed to highlight the better outcome of the ADC-SSAE model. The experimental values obtained by the ADC-SSAE model have ensured the efficacy of the ADC-SSAE model over the compared methods.}
}
@incollection{RANI2022143,
title = {Chapter 6 - Machine learning for soil moisture assessment},
editor = {Ramesh Chandra Poonia and Vijander Singh and Soumya Ranjan Nayak},
booktitle = {Deep Learning for Sustainable Agriculture},
publisher = {Academic Press},
pages = {143-168},
year = {2022},
series = {Cognitive Data Science in Sustainable Computing},
isbn = {978-0-323-85214-2},
doi = {https://doi.org/10.1016/B978-0-323-85214-2.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385214200001X},
author = {Alka Rani and Nirmal Kumar and Jitendra Kumar and Jitendra Kumar and Nishant K. Sinha},
keywords = {Soil moisture, Machine learning, Remote sensing, Pedotransfer functions, Downscaling},
abstract = {Soil moisture plays a key role in the Earth’s hydrological cycle and meteorological and climatic processes. The information on soil moisture content is required for irrigation scheduling, crop yield prediction, studies on weather and climate change, monitoring and forecasting extreme weather events like floods and drought, and estimation of runoff and soil erosion. The accurate and timely estimation and forecasting of soil moisture are necessary for these applications. Machine learning (ML) algorithms, like artificial neural networks, support vector machines, decision trees, random forest, and so on, are widely used for soil moisture assessment due to their ability to model nonlinear and complex relationships between variables. These algorithms are used to develop pedotransfer functions that can predict soil hydraulic properties, like available water capacity, hydraulic conductivity, soil water retention curve, and more. These algorithms are also used for the retrieval of soil moisture through remote sensing. By providing meteorological, vegetation, topographic, and historical input data about soil moisture variation, these ML algorithms can accurately forecast soil moisture after a few days. This information can be used for scheduling irrigation in the automated smart irrigation system. These algorithms are also extensively used for downscaling coarse resolution satellite-derived soil moisture products to finer spatial resolutions so that these products can be applied at the regional or watershed level. ML algorithms are contributing significantly to the progress of soil moisture research. In this chapter, an overview of the applicability of ML algorithms for soil moisture assessment in the various domains of soil moisture research is presented.}
}
@incollection{2022721,
title = {Index},
editor = {Shiew-Mei Huang and Juan J.L. Lertora and Paolo Vicini and Arthur J. Atkinson},
booktitle = {Atkinson's Principles of Clinical Pharmacology (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Boston},
pages = {721-739},
year = {2022},
isbn = {978-0-12-819869-8},
doi = {https://doi.org/10.1016/B978-0-12-819869-8.09991-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198698099912}
}
@article{TIAN2022203,
title = {Meta-learning approaches for learning-to-learn in deep learning: A survey},
journal = {Neurocomputing},
volume = {494},
pages = {203-223},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.04.078},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222004684},
author = {Yingjie Tian and Xiaoxi Zhao and Wei Huang},
keywords = {Meta-learning, Learning to learn, Application},
abstract = {Compared to traditional machine learning, deep learning can learn deeper abstract data representation and understand scattered data properties. It has gained considerable attention for its extraordinary performances. However, existing deep learning algorithms perform poorly on new tasks. Meta-learning, known as learning to learn, is one of the effective techniques to overcome this issue. Meta-learning’s generalization ability to unknown tasks is improved by employing prior knowledge to assist the learning of new tasks. There are mainly three types of meta-learning methods: metric-based, model-based, and optimization-based meta-learning. We investigate classical algorithms and recent meta-learning advances. Second, we survey meta-learning application in real world scenarios. Finally, we discuss present challenges and future research directions of meta-learning.}
}
@incollection{MUFTUOGLU202261,
title = {4 - Data sharing and privacy issues arising with COVID-19 data and applications},
editor = {Utku Kose and Deepak Gupta and Victor Hugo C. {de Albuquerque} and Ashish Khanna},
booktitle = {Data Science for COVID-19},
publisher = {Academic Press},
pages = {61-75},
year = {2022},
isbn = {978-0-323-90769-9},
doi = {https://doi.org/10.1016/B978-0-323-90769-9.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323907699000037},
author = {Z. Müftüoğlu and M.A. Kızrak and T. Yıldırım},
keywords = {COVID-19, Data privacy, Medical records sharing, Privacy metrics, Secure data sharing},
abstract = {The coronavirus disease 2019 (COVID-19) (2019-nCov), which was first detected in Wuhan/China in December 2019 and spread to the whole world in a short time, was explained as a new coronavirus by the World Health Organization on February 11, 2020. Countries are developing various strategies against the spread of epidemic threat. The main ones are to develop web-based or mobile applications to reduce the spread and economic damage of the epidemic by making use of COVID-19 datasets. It is seen that the existing applications developed within the framework of these expectations contain absolute location information (direct), relative location information (indirect), and characteristic data defining people. Even if these data mean a lot to the world's struggle with COVID-19, it is necessary to foresee the risks that may occur after the epidemic when the relations of the information are considered. In order to measure the privacy risk of this kind of applications containing personal data, privacy metrics have been defined in the literature. In this chapter, we give a perspective about the sharing and privacy of medical data within the scope of COVID-19. Within this context, privacy models, metrics, and approaches for selecting the appropriate model are described, in particular for COVID-19 applications, and we also propose a new metric with the entropy approach to metrics defined in the literature and effective in determining the privacy score.}
}
@incollection{2022491,
title = {Appendix},
editor = {Deepak Yadav and Pradeep Kumar and Pardeep Singh and Daniel A. Vallero},
booktitle = {Hazardous Waste Management},
publisher = {Elsevier},
pages = {491-589},
year = {2022},
isbn = {978-0-12-824344-2},
doi = {https://doi.org/10.1016/B978-0-12-824344-2.00010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128243442000100}
}
@incollection{MOHAGHEGH2022281,
title = {Chapter 11 - Application of artificial intelligence to computational fluid dynamics},
editor = {Shuvajit Bhattacharya and Haibin Di},
booktitle = {Advances in Subsurface Data Analytics},
publisher = {Elsevier},
pages = {281-352},
year = {2022},
isbn = {978-0-12-822295-9},
doi = {https://doi.org/10.1016/B978-0-12-822295-9.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222959000017},
author = {Shahab D. Mohaghegh and Ayodeji Aboaba and Yvon Martinez and Mehrdad Shahnam and Chris Guenther and Yong Liu},
keywords = {Artificial intelligence, CFD, Machine learning, Smart proxy},
abstract = {Smart proxy technology leverages the art and science of artificial intelligence and machine learning in order to build accurate and very fast proxy models for highly complex numerical simulation models. The main characteristics of the smart proxy modeling are (a) physics of the numerical simulation is not reduced or modified, (b) resolution of the numerical simulation is not reduced or modified, (c) detail cell results of the numerical simulation is replicated with high accuracy, and (d) deployment of the smart proxy to provide numerical simulation results for every cell will take few minutes using a laptop or desktop workstation. In this project, smart proxy technology is used to simulate the combustion of natural gas under various conditions such as varying natural gas composition and flow rate, inlet air flow rate and temperature, and outlet pressure in a high-pressure combustion facility (B6 combustor) with more than four million simulation cells.}
}
@incollection{DUBOIS2022335,
title = {Chapter Eleven - Use of GC×GC for the characterization of odours in forensic applications},
editor = {Chiara Emilia Irma Cordero},
series = {Comprehensive Analytical Chemistry},
publisher = {Elsevier},
volume = {96},
pages = {335-365},
year = {2022},
booktitle = {Characterization of Odorant Patterns by Comprehensive Two-Dimensional Gas Chromatography},
issn = {0166-526X},
doi = {https://doi.org/10.1016/bs.coac.2021.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166526X2100101X},
author = {Lena M. Dubois and Gwen O'Sullivan and Pierre-Hugues Stefanuto and Court D. Sandau and Jean-François Focant},
keywords = {Forensic science, Odour analysis, Ignitable liquids, Fire debris investigation, VOCs, Volatolomics, Volatile organic compounds, GC×GC, Comprehensive two-dimensional gas chromatography},
abstract = {In forensic science, the emission of odours from objects or biological matrices is exploited for different purposes. For example, the monitoring of odours via biological or analytical detectors is used in thanatochemistry, the chemistry of death. The analysis of decomposition odour can be explored to support the localization of a missing body, a scenario encountered in urban search and rescue operations. A better understanding of the formation and evolution of decomposition odour is also of high interest to human remains detection canine handlers to improve training practices and chose appropriate training aids. Next to thanatochemistry, many other types of evidence evaluation benefit from the characterization of the volatile profile including the analysis of fire debris, chemical threat agents, explosives, and drugs. From a chemical point of view, an odour represents a complex mixture of gaseous molecules and its characterization demands for a powerful analytical technique. Especailly, in non-targeted analysis, the separation power provided by one-dimensional (1D) gas chromatography (GC) can be surpassed. Thus, a better insight is usually achieved using a multidimensional technique, such as comprehensive two-dimensional gas chromatography (GC×GC). This chapter focuses on scientific articles published between 2015 and 2020 reporting on the use of GC×GC for odour characterization in the context of forensic science. The main points are decomposition odour, volatolomic applications for profiling of human scent and illegal trade goods such as wildlife parts. Furthermore, the investigation of volatile traces of drugs and ignitable liquids in the context of arson investigations is addressed in detail. For each section, the length is proportional to the number of publications from the literature review.}
}
@incollection{EMETERE202253,
title = {Chapter 4 - Generating environmental data: Progress and shortcoming},
editor = {Moses Eterigho Emetere},
booktitle = {Numerical Methods in Environmental Data Analysis},
publisher = {Elsevier},
pages = {53-77},
year = {2022},
isbn = {978-0-12-818971-9},
doi = {https://doi.org/10.1016/B978-0-12-818971-9.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128189719000107},
author = {Moses Eterigho Emetere},
keywords = {Data, Environment data, Inset, Remote},
abstract = {Environmental data is that which is based on the measurement of environmental parameters, and its impacts on the ecosystems. Environmental data is a set of quantitative, qualitative, or geographically referenced facts about the state of the environment and how it is changing. There are progress made that needs more improvement and shortcomings that requires urgent action. This chapter is an overview of the progress and shortcoming made in data curation in environmental research.}
}
@incollection{CORTES2022219,
title = {Chapter 11 - Societal and ethical impact of technologies for health and biomedicine},
editor = {Davide Cirillo and Silvina Catuara-Solarz and Emre Guney},
booktitle = {Sex and Gender Bias in Technology and Artificial Intelligence},
publisher = {Academic Press},
pages = {219-238},
year = {2022},
isbn = {978-0-12-821392-6},
doi = {https://doi.org/10.1016/B978-0-12-821392-6.00002-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128213926000029},
author = {Atia Cortés and Nataly Buslón and Liliana Arroyo},
keywords = {Artificial intelligence, Ethics, AI ethics, Social impact AI, Health AI, Responsible AI},
abstract = {The healthcare sector has been an early adopter of new technologies such as artificial intelligence, nanotechnology, or genome sequencing. They are expected to improve healthcare systems and augment practitioners’ skills. The deployment of wearable sensors and healthcare trackers are empowering individuals, making them self-aware of their wellbeing but also turning them into data donors. Personal data are essential to train machine learning models used to support healthcare professionals in decision making. However, it is extremely relevant to consider the power of the (mis-)represented population in the data analyzed. Artificial intelligent systems used in precision medicine need to be robust, not only technically but also socially by tackling gender imbalance, technology access, or other issues that may affect vulnerable groups in healthcare. This chapter offers an overview on the opportunities of digital health ecosystems while highlighting some social, ethical, and technical challenges. It also provides a review of the relation of the traditional ethical principles used in health and biomedicine and those defined for the design, deployment, and use of a trustworthy AI in Europe.}
}
@article{2022100051,
title = {Full Issue PDF},
journal = {JACC: Advances},
volume = {1},
number = {2},
pages = {100051},
year = {2022},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2022.100051},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X22000552}
}
@incollection{KURNI2022297,
title = {Chapter 11 - A forefront insight into the integration of AI and blockchain technologies},
editor = {SK Hafizul Islam and Arup Kumar Pal and Debabrata Samanta and Siddhartha Bhattacharyya},
booktitle = {Blockchain Technology for Emerging Applications},
publisher = {Academic Press},
pages = {297-320},
year = {2022},
series = {Hybrid Computational Intelligence for Pattern Analysis},
isbn = {978-0-323-90193-2},
doi = {https://doi.org/10.1016/B978-0-323-90193-2.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323901932000053},
author = {Muralidhar Kurni and K. Saritha and D. Nagadevi and K. {Somasena Reddy}},
keywords = {AI and blockchain fusion, App development industry, Artificial intelligence (AI), Blockchain, Industry 4.0, Integration of AI and blockchain, Shared records, Smart contracts},
abstract = {Artificial intelligence (AI) and blockchain: these two technologies have recently been the trendiest and most revolutionary, progressive technologies. Blockchain technology can automate payments in cryptocurrency and provide admittance in a decentralized, safe, and trustworthy way to shared records, transactions, and log ledgers. Also, with smart contracts, blockchain can handle interactions between participants without an interceder. Furthermore, AI provides intelligence and smart decision-making for human-like machines. This chapter presents a thorough analysis of AI and blockchain integration ability, possibilities, and applications. The incorporation of AI was evaluated as well as how blockchain will influence industry 4.0. We also recognize and address the open issues of AI and blockchain fusion.}
}
@incollection{BHAT20221,
title = {Chapter 1 - Emerging trends and sustainability challenges in the global agri-food sector},
editor = {Rajeev Bhat},
booktitle = {Future Foods},
publisher = {Academic Press},
pages = {1-21},
year = {2022},
isbn = {978-0-323-91001-9},
doi = {https://doi.org/10.1016/B978-0-323-91001-9.00041-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323910019000414},
author = {Rajeev Bhat},
keywords = {Sustainability challenges, Technological innovations, Digitalization, Green technologies, Circular economy, Designer foods, Underutilized resources, Climate change impacts, Food frauds, Gastronomy},
abstract = {The global agri-food system has progressively evolved and is experiencing precipitous transformations. Of late, technological innovations have substantially revolutionized the entire agri-food production and supply chain systems. And, this is irrespective of a regions socio-economic stature. In spite of this, still there are several recurring global sustainability challenges that requires to be tackled. In this chapter, some of the currently encountered sustainability challenges and coherent practical solutions/innovations offered in the agri-food sector are deliberated. In the future, major focus will revolve around designing appropriate models/frameworks to overcome the challenges, understanding the requirements of a resilient food system, sharing of evidence-based research/new knowledge with the consumers, educating local population, realigning and introducing new agri-food policies, and implementation of realistic solutions. In the coming decades, the prospects of the entire agri-food sector are affirmative, however, all the key players (farming community, unions, government and non-governmental organizations, environmental groups, suppliers and manufacturers, agri-food scientists/technologists, policy makers, risk managers, consumers, and the public) need to drive together to contribute for a successful sustainable future.}
}
@incollection{WU20221,
title = {Chapter 1 - Chronotopologic data analysis},
editor = {Jiaping Wu and Junyu He and George Christakos},
booktitle = {Quantitative Analysis and Modeling of Earth and Environmental Data},
publisher = {Elsevier},
pages = {1-32},
year = {2022},
isbn = {978-0-12-816341-2},
doi = {https://doi.org/10.1016/B978-0-12-816341-2.00005-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128163412000058},
author = {Jiaping Wu and Junyu He and George Christakos},
keywords = {Topos, Chronos, Chronotopos, Scientific inquiry, Chronotopologic data analysis, Application, Software},
abstract = {The concepts of topos, chronos, and chronotopos are introduced in the broad scientific inquiry context; the notions of chronotopologic variability, dependency, uncertainty, estimation, and mapping are introduced; chronotopologic data analysis techniques and visualization technology are reviewed; last, the chronotopologic applications are outlined and a list of public domain software libraries is provided.}
}
@incollection{DING2022129,
title = {6 - Blockchain for future renewable energy},
editor = {Mohsen Parsa Moghaddam and Reza Zamani and Hassan Haes Alhelou and Pierluigi Siano},
booktitle = {Decentralized Frameworks for Future Power Systems},
publisher = {Academic Press},
pages = {129-146},
year = {2022},
isbn = {978-0-323-91698-1},
doi = {https://doi.org/10.1016/B978-0-323-91698-1.00011-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032391698100011X},
author = {Jianguo Ding and Vahid Naserinia},
keywords = {Renewable energy, Decentralized framework, Decentralized management, Blockchain},
abstract = {To better optimize and control the renewable energy system and its integration with traditional grid systems and other energy systems, corresponding technologies are needed to meet its growing practical application requirements: decentralized management and control, support for decentralized decision-making, fine-grained and timely data sharing, maintain data and business privacy, support fast and low-cost electricity market transactions, maintain the security and reliability of system operation data, and prevent malicious cyberattacks. Blockchain is based on core technologies such as distributed ledgers, asymmetric encryption, consensus mechanisms, and smart contracts and has some excellent features such as decentralization, openness, independence, security, and anonymity. These characteristics seem to meet the technical requirements of future renewable energy systems partially. This chapter will systematically review how blockchain technology can potentially solve the challenges with decentralized solutions for future renewable energy systems and show a guideline to implement blockchain-based corresponding applications for future renewable energy.}
}
@incollection{COSTA20221,
title = {Chapter 1 - Achieving a more sustainable wine supply chain—Environmental and socioeconomic issues of the industry},
editor = {J. Miguel Costa and Sofia Catarino and José M. Escalona and Piergiorgio Comuzzo},
booktitle = {Improving Sustainable Viticulture and Winemaking Practices},
publisher = {Academic Press},
pages = {1-24},
year = {2022},
isbn = {978-0-323-85150-3},
doi = {https://doi.org/10.1016/B978-0-323-85150-3.00009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323851503000098},
author = {J. Miguel Costa and Sofia Catarino and José M. Escalona and Piergiorgio Comuzzo},
keywords = {Innovation and competitiveness, Oenology, Supply chain, Sustainability issues, Viticulture},
abstract = {Sustainable development involves three basic pillars: environmental, economic, and social. In the case of the wine sector, sustainability needs to integrate the concept defined by economics, ecology, and community dimensions for both grape and wine production. The wine industry is a large, globalized, and diversified sector encompassing multiple production systems and cultures, diverse management choices and a wide range of monitoring tools and solutions. This chapter presents and discusses the most relevant risks and concerns of modern wine industry and major sustainability issues related to wine production and related supply chain. The wine sector must implement more sustainable practices to mitigate climate change impacts and to decrease its environmental impact while ensuring its important economic and social function. Metrics and standards are required to support audits, efficient management, and regulatory parameters. Social issues must be addressed by the sector, especially because it strongly relies on human resources and manual labor. Research and development activities and related innovation (e.g., digitalization, sensors, mechanization, and recycling) can result in improved sustainability and resilience while the lack of transparency of the sector will harm confidence of consumers and competiveness.}
}
@incollection{LEMUSALARCON2022159,
title = {Chapter 6 - Cloud-based data pipeline orchestration platform for COVID-19 evidence-based analytics},
editor = {Victor Chang and Mohamed Abdel-Basset and Muthu Ramachandran and Nicolas G. Green and Gary Wills},
booktitle = {Novel AI and Data Science Advancements for Sustainability in the Era of COVID-19},
publisher = {Academic Press},
pages = {159-180},
year = {2022},
isbn = {978-0-323-90054-6},
doi = {https://doi.org/10.1016/B978-0-323-90054-6.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900546000039},
author = {Mauro {Lemus Alarcon} and Roland Oruche and Ashish Pandey and Prasad Calyam},
keywords = {Research data sharing, Cloud-hosted health-care data, Data access control, Data science tools interface},
abstract = {Identifying high-quality publications remains a critical challenge for health-care data consumers (e.g., immunologists, clinical researchers) who seek to make timely decisions related to the COVID-19 pandemic response. Currently, researchers perform a manual literature review process to compile and analyze publications from disparate medical journal databases. Such a process is cumbersome, inefficient, and increases the time to complete research tasks. In this book chapter, we describe a cloud-based, intelligent data pipeline orchestration platform, viz., “OnTimeEvidence” that provides health-care consumers with easy access to publication archives and analytics tools for rapid pandemic-related knowledge discovery tasks. This platform aims to reduce the burden and expensive time to find, sort, and analyze publications in terms of their level of evidence. We also present a case study of how OnTimeEvidence platform can be configured to help health-care data consumers to combine and analyze multiple data sources using interactive interfaces featuring workspaces equipped with analytics tools.}
}
@article{LIN2022101587,
title = {Protocol to estimate cell type proportions from bulk RNA-seq using DAISM-DNNXMBD},
journal = {STAR Protocols},
volume = {3},
number = {3},
pages = {101587},
year = {2022},
issn = {2666-1667},
doi = {https://doi.org/10.1016/j.xpro.2022.101587},
url = {https://www.sciencedirect.com/science/article/pii/S2666166722004671},
author = {Yating Lin and Shangze Wu and Xu Xiao and Jingbo Zhao and Minshu Wang and Haojun Li and Kejia Wang and Minwei Zhang and Frank Zheng and Wenxian Yang and Lei Zhang and Jiahuai Han and Rongshan Yu},
keywords = {Bioinformatics, Sequence analysis, Cell Biology, Flow Cytometry/Mass Cytometry, RNAseq, Immunology, Gene Expression},
abstract = {Summary
Computational protocols for cell type deconvolution from bulk RNA-seq data have been used to understand cellular heterogeneity in disease-related samples, but their performance can be impacted by batch effect among datasets. Here, we present a DAISM-DNN protocol to achieve robust cell type proportion estimation on the target dataset. We describe the preparation of calibrated samples from human blood samples. We then detail steps to train a dataset-specific deep neural network (DNN) model and cell type proportion estimation using the trained model. For complete details on the use and execution of this protocol, please refer to Lin et al. (2022).}
}
@incollection{HOVENGA20221,
title = {Chapter 1 - Transforming health care},
editor = {Evelyn Hovenga and Heather Grain},
booktitle = {Roadmap to Successful Digital Health Ecosystems},
publisher = {Academic Press},
pages = {1-16},
year = {2022},
isbn = {978-0-12-823413-6},
doi = {https://doi.org/10.1016/B978-0-12-823413-6.00020-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234136000203},
author = {Evelyn Hovenga},
keywords = {Value proposition, Ecosystem, Government leadership, Innovation, Roadmap, Infrastructure},
abstract = {Revolutionary changes are needed to reform healthcare delivery systems globally to realise the vision of healthcare access for everyone, no matter their location, facilitated and enabled by effective national digital health ecosystems. This chapter introduces the reader to widely recognised drivers and desired future outcomes. Foundational principles adopted as the focus for this text are identified. This includes the need for sustained leadership, committed investments, effective governance, a national technical framework, and a description of the digital health ecosystem characteristics. Innovation blind spots that have the potential to undermine digital health transformation need to be identified, considered, and included as roadmap components. Principles to be adopted, some examples of existing foundations, and value proposition drivers are introduced, followed by a description of a digitally enabling health environment. The chapter concludes with the identification of key requirements for global and national action to be incorporated in a digital health roadmap which needs to consider numerous fragmented influencing factors. Six foundational concepts representing desired outcomes are introduced.}
}
@incollection{HOVENGA2022169,
title = {Chapter 8 - Health data standards’ limitations},
editor = {Evelyn Hovenga and Heather Grain},
booktitle = {Roadmap to Successful Digital Health Ecosystems},
publisher = {Academic Press},
pages = {169-207},
year = {2022},
isbn = {978-0-12-823413-6},
doi = {https://doi.org/10.1016/B978-0-12-823413-6.00015-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823413600015X},
author = {Evelyn Hovenga and Heather Grain},
keywords = {Ontology, Terminology, Data set, Electronic data processing, Big data, Data management, Linguistics},
abstract = {Data represent foundational assets of any healthcare delivery system. Clinical data form the basis of electronic communications from point of data collection to storage and archiving. Computers cannot handle ambivalence, hence the need for the widespread adoption of technical and terminology standards. Many domain ontologies and terminologies, developed to suit a variety of different purposes well before this digital era, are reviewed and examined to determine their usability within a digital ecosystem. The ontological data modelling approach was found to result in the highest degrees of expressivity and formalism available today. Resulting artefacts linked to standard value sets were found to be most comprehensive with their ability to best represent data for a lifetime support, patient safety, and electronic communication. Many issues and limitations, such as variations regarding design principles used, overlaps, and shortcomings, are identified and discussed. There is a need for a major globally led transformation.}
}
@article{GUTIERREZ2022102,
title = {On the use of information fusion techniques to improve information quality: Taxonomy, opportunities and challenges},
journal = {Information Fusion},
volume = {78},
pages = {102-137},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521001925},
author = {Raúl Gutiérrez and Víctor Rampérez and Horacio Paggi and Juan A. Lara and Javier Soriano},
keywords = {Information fusion, Information quality, Information imperfections, Sustainability},
abstract = {The information fusion field has recently been attracting a lot of interest within the scientific community, as it provides, through the combination of different sources of heterogeneous information, a fuller and/or more precise understanding of the real world than can be gained considering the above sources separately. One of the fundamental aims of computer systems, and especially decision support systems, is to assure that the quality of the information they process is high. There are many different approaches for this purpose, including information fusion. Information fusion is currently one of the most promising methods. It is particularly useful under circumstances where quality might be compromised, for example, either intrinsically due to imperfect information (vagueness, uncertainty, …) or because of limited resources (energy, time, …). In response to this goal, a wide range of research has been undertaken over recent years. To date, the literature reviews in this field have focused on problem-specific issues and have been circumscribed to certain system types. Therefore, there is no holistic and systematic knowledge of the state of the art to help establish the steps to be taken in the future. In particular, aspects like what impact different information fusion methods have on information quality, how information quality is characterised, measured and evaluated in different application domains depending on the problem data type or whether fusion is designed as a flexible process capable of adapting to changing system circumstances and their intrinsically limited resources have not been addressed. This paper aims precisely to review the literature on research into the use of information fusion techniques specifically to improve information quality, analysing the above issues in order to identify a series of challenges and research directions, which are presented in this paper.}
}
@incollection{KIMM202261,
title = {Chapter 4 - Classes of AI tools, techniques, and methods},
editor = {Imdat As and Prithwish Basu and Pratap Talwar},
booktitle = {Artificial Intelligence in Urban Planning and Design},
publisher = {Elsevier},
pages = {61-83},
year = {2022},
isbn = {978-0-12-823941-4},
doi = {https://doi.org/10.1016/B978-0-12-823941-4.00012-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239414000123},
author = {Geoff Kimm},
keywords = {Artificial intelligence, AI tools, AI survey, Urban planning, Intelligent agents},
abstract = {In urban design and planning, there is no canonical classification of uses and approaches of artificial intelligence (AI), nor even a definitive framework for developing such. The increasing capabilities of AI continually change its scope and possible roles. In its urban application, there are multiple perspectives—from that of the practitioner, the citizen, and even notionally the machine—that are all equally valid. This chapter therefore looks at classifying AI in urban design and planning in three ways. Initially, algorithms are discussed as the essential AI tool. Subsequently, in a reductionist approach, techniques are considered via Russell and Norvig's schema of intelligent agents with respect to the objectives of the practitioner. Finally, methods are considered in a teleological approach by considering the purposes AI tools and techniques serve for the practitioner rather than the underlying mechanisms themselves. The discussion is founded on a working definition of AI that is predicated on the fact that synthetic reasoning and outcomes may be fundamentally nonhuman.}
}
@incollection{KOLTAY202277,
title = {Chapter 4 - Research data management},
editor = {Tibor Koltay},
booktitle = {Research Data Management and Data Literacies},
publisher = {Chandos Publishing},
pages = {77-108},
year = {2022},
series = {Chandos Information Professional Series},
isbn = {978-0-12-824475-3},
doi = {https://doi.org/10.1016/B978-0-12-824475-3.00002-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128244753000023},
author = {Tibor Koltay},
keywords = {Research data management, Readiness, Skills and competencies, Planning, Research data life cycle, Data management plans, Data reference, Data citation, Data retrieval, Data curation},
abstract = {Research data management (RDM) should be central for both researchers and academic libraries. The latter provide related services that are described in this chapter. RDM embraces the entire research cycle, aiming at making the research process as efficient as possible and facilitating cooperation with other players involved in it. To get a clear picture of the nature of RDM services, a short history of the academic library’s readiness and involvement is described. Skills and competencies necessary for serving research and researchers are enumerated, followed by a portrayal of the planning and building of services, giving particular attention to the research data life cycle and to the importance of data management plans. The tasks related to data reference, data citation, and data retrieval are presented. The relationship between RDM and data curation, as well as between RDM and research support services, is characterized.}
}
@incollection{KALPANA2022225,
title = {13 - Data-driven machine learning: A new approach to process and utilize biomedical data},
editor = {Sudipta Roy and Lalit Mohan Goyal and Valentina E. Balas and Basant Agarwal and Mamta Mittal},
booktitle = {Predictive Modeling in Biomedical Data Mining and Analysis},
publisher = {Academic Press},
pages = {225-252},
year = {2022},
series = {Advanced Studies in Complex Systems: Theory and Applications},
isbn = {978-0-323-99864-2},
doi = {https://doi.org/10.1016/B978-0-323-99864-2.00017-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323998642000172},
author = { Kalpana and Aditya Srivastava and Shashank Jha},
keywords = {Data, Disease, Drug, Artificial intelligence, Machine learning, Cognitive computing, Vaccine, Bioinformatics, Artificial neural network},
abstract = {With new diseases like Covid-19 and preexisting challenges like the shortage of skilled personnel, the need for new advancements in healthcare is acutely felt. This also includes the development of precise and accurate diagnostic tools to ease the pressure on the medical personnel, simultaneously enhancing efficiency. Machine Learning (ML) and Artificial Intelligence (AI) have emerged as promising solutions, and are being explored extensively. Their core concept, Artificial Neural Networking (ANN), is a banal yet faithful replica of the natural brain, making complex computing and “learning” possible. Being a gold mine of biomedical data, the healthcare sector serves as an invaluable resource for the development of such tools. However, there are numerous hurdles along the path to the realization of the same. This chapter explores the development of ANN-based diagnostic tools, focusing more on the aforementioned challenges. A brief overview of the current scenarios and future prospects of Machine Learning in Biomedicine has also been discussed.}
}
@incollection{MISTRY202219,
title = {Chapter 2 - The role of climate datasets in understanding climate extremes},
editor = {Victor Ongoma and Hossein Tabari},
booktitle = {Climate Impacts on Extreme Weather},
publisher = {Elsevier},
pages = {19-48},
year = {2022},
isbn = {978-0-323-88456-3},
doi = {https://doi.org/10.1016/B978-0-323-88456-3.00005-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323884563000058},
author = {Malcolm N. Mistry},
keywords = {Climate extremes, Climate datasets, ETCCDI, Expert team on sector-specific climate indices (ET-SCI)},
abstract = {A rapidly growing body of literature routinely employs historical observations to study extremes in past and current climate. The inconsistencies in observations often lead to erroneous results and drawing incorrect inferences when undertaking analyses of climate extremes at regional or global scales. Understanding the potential inhomogeneity in climate datasets is therefore central to the study of climate extremes, especially when attributing any shifts in extremes to a changing climate. Despite the best efforts in assembling quality-controlled input data sources, inconsistencies in data are inherently embedded within long-term records of observations. Knowing the strengths and limitations of climate datasets can potentially facilitate better analyses of climate extremes. This chapter begins with an overview of climate extremes and Climate Extreme Indices (CEIs). The importance of quality control input meteorological variables, tools for assembling the CEIs, and a detailed list of recommended CEIs suitable for examining a broad array of temperature- and precipitation-based extremes are described next. Different sources of global and regional input climate data along with their strengths and limitations for assembling the CEIs form the crux of the next section. Existing datasets of CEIs and recommendations for future research conclude the chapter as the final two sections.}
}
@article{2022,
title = {Poster abstracts (P)},
journal = {Human Immunology},
year = {2022},
issn = {0198-8859},
doi = {https://doi.org/10.1016/j.humimm.2022.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S019888592200163X}
}
@incollection{CHANDRA2022177,
title = {Chapter 10 - Data visualization: existing tools and techniques},
editor = {Sourav De and Sandip Dey and Siddhartha Bhattacharyya and Surbhi Bhatia},
booktitle = {Advanced Data Mining Tools and Methods for Social Computing},
publisher = {Academic Press},
pages = {177-217},
year = {2022},
series = {Hybrid Computational Intelligence for Pattern Analysis},
isbn = {978-0-323-85708-6},
doi = {https://doi.org/10.1016/B978-0-32-385708-6.00017-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323857086000175},
author = {Tej Bahadur Chandra and Anuj Kumar Dwivedi},
keywords = {Dataset, Data model, Data source, Data visualization, Tools, Techniques, Visualization},
abstract = {Over time, data have become the essential competitive factor for businesses/enterprises to grow and develop. Selected businesses/enterprises such as information industrial businesses will put more focus on product innovation or technology for solving the challenges of gigantic data, i.e., capture, storage, analysis, and presentation/application. Enterprises/businesses like banking, manufacturing, and other enterprises will also benefit from analysis and management of huge data and provide more prospects for management/strategy/marketing innovations. For centuries, persons/societies have depended on visual illustrations such as maps and charts to grasp information quickly. Due to the way the human brain processes information, it is faster for people to grasp the meaning of many data points when they are displayed in charts and graphs rather than in piles of spreadsheets or long reports. Data visualization is the presentation of data in a graphical or pictorial format. Over time, as data are collected, stored, and analyzed, decision makers at all stages rely on data visualization/presentation software that enables them to see and visually present fruitful analytical results, find significance among the heaps/millions of variables, communicate established concepts and hypotheses to others, and even forecast/predict the future. By exploring each aspect of existing tools and techniques related to data visualization, the major objective of this chapter is to present essential theoretical aspects in an analytical way with a profound focus on challenges to represent data in visual form and limits in terms of pros and cons of existing tools and techniques.}
}
@incollection{BRIGHTPONTE2022265,
title = {Chapter 15 - Postmarket surveillance and regulatory considerations in reproductive and developmental toxicology: a Food and Drug Administration perspective},
editor = {Ramesh C. Gupta},
booktitle = {Reproductive and Developmental Toxicology (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {265-282},
year = {2022},
isbn = {978-0-323-89773-0},
doi = {https://doi.org/10.1016/B978-0-323-89773-0.00015-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323897730000151},
author = {Susan Bright-Ponte},
keywords = {Drugs, FDA, Pharmacovigilance, Safety, Surveillance, Vaccines},
abstract = {Pharmaceutical products for humans and animals may have toxic effects on human or animal reproductive and developmental processes. Various governmental agencies are charged with monitoring the safety of pharmaceuticals and biologics used to treat or prevent disease in humans and animals. Adverse event reporting systems and pharmacovigilance are important for monitoring the safety of medical products and in protecting public health. The US Food and Drug Administration (US FDA) is a regulatory, science-based federal agency responsible for protecting and promoting the public health through the monitoring and regulation of a number of items necessary for the health and well-being of consumers. This chapter will focus on the FDA's pharmacovigilance and surveillance activities as related to the regulation of marketed drugs and vaccines intended for use in humans, and drugs intended for use in animals. Examples of regulatory programs and issues specifically regarding potential reproductive and developmental toxicity of pharmaceutical products will be presented.}
}
@incollection{SCHNEIDER2022149,
title = {Chapter 8 - Machine learning: ML for eHealth systems},
editor = {Patrick Schneider and Fatos Xhafa},
booktitle = {Anomaly Detection and Complex Event Processing over IoT Data Streams},
publisher = {Academic Press},
pages = {149-191},
year = {2022},
isbn = {978-0-12-823818-9},
doi = {https://doi.org/10.1016/B978-0-12-823818-9.00019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128238189000195},
author = {Patrick Schneider and Fatos Xhafa},
keywords = {Algorithms, Diagnostic systems, Ethics, safety, and equity, Learning problems, Learning techniques, Ethics, safety, privacy, accountability, and transparency, ML frameworks, Federated learning},
abstract = {Healthcare is at the dawn of a new era of intelligent systems and improved human relationships. The potential of artificial intelligence (AI) and machine learning (ML) technologies to support decision-making, optimize workflows, and free up quality human time is revolutionizing how people deliver and receive care. The success and performance of AI-based expert-level diagnostic systems have inspired unprecedented optimism. However, there are growing concerns about ethics, safety, and equity in the delivery of care. The lack of clarity about how it works and the resulting mistrust has negatively affected the relationship between AI and caregivers and recipients, preventing adoption. This chapter provides a general overview of the various AI learning areas and a detailed introduction to the area of federated learning, a key to the application of machine learning in the future vision of healthcare.}
}
@incollection{TREIBLMAIER2022127,
title = {Chapter 8 - Blockchain technologies in the digital supply chain},
editor = {Bart L. MacCarthy and Dmitry Ivanov},
booktitle = {The Digital Supply Chain},
publisher = {Elsevier},
pages = {127-144},
year = {2022},
isbn = {978-0-323-91614-1},
doi = {https://doi.org/10.1016/B978-0-323-91614-1.00008-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323916141000083},
author = {Horst Treiblmaier and Abderahman Rejeb and Wafaa A.H. Ahmed},
keywords = {Blockchain adoption barriers, Blockchain adoption drivers, Blockchain technology, Distributed ledger technology, Literature review, Supply chain management},
abstract = {The application of blockchain or, more generally, distributed ledger technology in logistics and supply chain management has created a huge amount of interest among academics and practitioners. Blockchain's inherent characteristics include immutable data, seamless information flows, and shared access to data. Also, the potential to deploy smart contracts (program code executed automatically) with blockchain has raised high hopes for improving the effectiveness, efficiency, and sustainability of supply chains. In this chapter, we clarify the meaning of terms used in the blockchain ecosystem and present the results from an extensive literature review from which we summarize current findings. We highlight the principal drivers influencing blockchain adoption—traceability, trust and transparency, supply chain integration, data security, privacy, and sustainability. We note technical, organizational, and regulatory barriers that may inhibit adoption of blockchain in supply chain applications, including scalability, investment costs versus perceived benefits, data sharing and interoperability challenges, and lack of standards or regulations. Although blockchain adoption is still in its early stages, an increasing number of applications are being reported. We identify reported supply chain applications classified by industry sector. This chapter equips scholars and practitioners with an understanding of how blockchain can provide value in contemporary supply chains.}
}
@article{ONETO2022300,
title = {Advances in artificial neural networks, machine learning and computational intelligence},
journal = {Neurocomputing},
volume = {470},
pages = {300-303},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.07.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221011036},
author = {Luca Oneto and Kerstin Bunte and Nicoló Navarin}
}
@incollection{JEYAKUMAR2022347,
title = {Chapter 30 - A smart virtual vision system for health monitoring},
editor = {Valentina Emilia Balas and Oana Geman},
booktitle = {Biomedical Engineering Applications for People with Disabilities and the Elderly in the COVID-19 Pandemic and Beyond},
publisher = {Academic Press},
pages = {347-360},
year = {2022},
isbn = {978-0-323-85174-9},
doi = {https://doi.org/10.1016/B978-0-323-85174-9.00021-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323851749000212},
author = {Vijay Jeyakumar and K. Nirmala and R. Nithya},
keywords = {Assistive device, COVID-19, Health monitoring, Home monitoring, Intelligent system, Virtual vision system},
abstract = {One of the greatest challenges in regard to the elderly is the autonomous and healthy availability of appropriate beneficial and social functionalities to achieve the primary goal of prolonging independent living at home. In 2050, the forecast population of elderly people in India is about 300 million. The traditional kind of joint family in Indian culture has come under pressure due to family planning awareness, migration to cities, a lack of sustainability, and inadequate guidance from the elders. A virtual vision system (VVS) is a home-based monitoring device that captures the scene continuously to aid the user. The system helps the individual to navigate in a closed environment. The user can provide the system with commands, queries, and/or demands using free form natural language input to receive help. A wearable sensor that can track physiological parameters such as oxygen saturation, temperature, and pulse rate also can be integrated into the system. The risk of falling and potential injury is one reason for the elderly being placed in care facilities. The system also supports users by tracking their mobility, and helps to identify falls. The system autonomously patrols the user's environment without any user activity and checks if the user is well and has not suffered a fall. The VVS emphasis is on an application platform that incorporates distinct technical solutions such as biometric tools, remote doctor visits, emergency call and tracking systems, drug dispensers, and online shopping. In elderly care, continuous monitoring helps not only to focus on improving the senior's safety when a caregiver is not present, but also provides peace of mind to adult children who may be concerned about the welfare of their loved one. Such systems would be helpful for those in self-quarantine/isolation during this COVID-19 pandemic situation.}
}
@incollection{PALMA20225085,
title = {Chapter 91 - Neuroeconomics: An overview and applications to agricultural and food economics},
editor = {Christopher B. Barrett and David R. Just},
series = {Handbook of Agricultural Economics},
publisher = {Elsevier},
volume = {6},
pages = {5085-5116},
year = {2022},
issn = {1574-0072},
doi = {https://doi.org/10.1016/bs.hesagr.2022.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S157400722200007X},
author = {Marco A. Palma},
keywords = {Biometrics, Choice process data, Emotions, Eye-tracking, Neuroeconomics},
abstract = {This chapter provides an overview of the neuroeconomics field, with particular emphasis and applications to the agricultural and applied economics profession. First, I provide a brief overview of the brain. Next, I highlight the priority areas in the applied economics agenda, including developing, testing, and refining theory; the value of using neurophysiological data to enrich the underlying motivations of the choice process preference formation; evaluating treatment compliance and effort (internal validity); generalizability of behavior from the lab to the real world (external validity); and recent neuroeconomic advances in the prediction power of choice models. Next, I provide an overview of a wide range of available neuro-physiological tools varying in cost, obtrusiveness, and complexity. I highlight some basic, low-cost measures that can be incorporated using existing resources for most researchers. Throughout the chapter, I discuss opportunities for the neuroeconomics agenda to address relevant questions in the food and agriculture domain. Finally, I raise potential ethical concerns about the use of the neuroeconomics paradigm to induce changes that could harm individuals and result in suboptimal and costly behavior.}
}
@article{2022I,
title = {Full issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {15},
number = {4},
pages = {I-CLXVIII},
year = {2022},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(22)00139-5},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X22001395}
}
@article{2022iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {200},
pages = {iii-xiii},
year = {2022},
note = {3rd International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(22)00407-0},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922004070}
}
@incollection{YANG2022245,
title = {Chapter 9 - MaaS system visualization},
editor = {Haoran Zhang and Xuan Song and Ryosuke Shibasaki},
booktitle = {Big Data and Mobility as a Service},
publisher = {Elsevier},
pages = {245-263},
year = {2022},
isbn = {978-0-323-90169-7},
doi = {https://doi.org/10.1016/B978-0-323-90169-7.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323901697000105},
author = {Chuang Yang and Renhe Jiang and Ryosuke Shibasaki},
keywords = {Mobility as a Service, Data visualization, Visual analytics, Intelligence transportation system, Spatial information science},
abstract = {With the MaaS system running, massive amounts of data are generated (such as GPS trajectory data of moving objects, daily delay data of metros, and ridership data). These data contain a considerable amount of information, knowledge, and insights, giving rise to the demand to perceive, understand, and utilize them, which visualization technology has native potential for such scenarios. In this paper, we summarize the existing visualization technologies of the current transportation system into a multi-view frame, covering the perspective of the three MaaS's leading actors, i.e., demanders of mobility, suppliers of transport services, and city managers. Three real-world application cases from different actor perspectives are introduced. Moreover, we recommend some practical open-source tools and libraries for MaaS system visualization and discuss some future challenges and directions of MaaS visualization.}
}
@incollection{LI2022349,
title = {Chapter 12 - Blockchain-enabled product lifecycle management},
editor = {Dimitris Mourtzis},
booktitle = {Design and Operation of Production Networks for Mass Personalization in the Era of Cloud Technology},
publisher = {Elsevier},
pages = {349-379},
year = {2022},
isbn = {978-0-12-823657-4},
doi = {https://doi.org/10.1016/B978-0-12-823657-4.00013-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128236574000130},
author = {Zhi Li and Zonggui Tian and Lihui Wang and Ray Y. Zhong},
keywords = {Industry 4.0, Fourth industrial revolution, Product lifecycle management, Industrial blockchain, Mass customization},
abstract = {The rapid advances of information technology have pushed society into the fourth industrial revolution (I4.0). It requires an integration of value chain organization and management across the product lifecycle driven by the Internet industrialization, industrial digitalization and intellectualization, and industrial integration. PLM is the business activity of managing a company’s products from the idea of product development to the end of product life. It aims to seamlessly manage all products, information, and knowledge generated throughout the product’s lifecycle in order to achieve business competitiveness. Blockchain is an emerging technology that brings transparency to opaque systems, verifiability, and immutability to transactions and processes, which gives it the potential to drive I4.0 revolution. This chapter will demonstrate the real-world applicability of blockchain potential using existing industrial case studies. Besides, an industrial blockchain-based PLM framework is introduced to facilitate data exchange and service sharing in the product lifecycle.}
}
@article{HBAIEB2022108558,
title = {A survey of trust management in the Internet of Vehicles},
journal = {Computer Networks},
volume = {203},
pages = {108558},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108558},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004758},
author = {Amal Hbaieb and Samiha Ayed and Lamia Chaari},
keywords = {Vehicular networks, VANET, IoV, V2X, Trust management, Security, Blockchain},
abstract = {In recent years, the emergence of the Internet of Vehicles (IoV) aims to enhance the users’ quality of experience through proposing more sophisticated services ranging from guaranteeing the user safety to improving his comfort. The IoV ecosystem is complex, heterogeneous, and evolving. Many entities participate to compose its architecture (such as vehicles, humans, roadside units, ITS). Moreover, different communication types co-exist to ensure the IoV connectivity and continuity. This diversity leads to new security requirements that seem more complex to take into account and enlarge the attack surface of such ecosystem. Many security mechanisms should be considered to enforce the security of IoV environment at many levels: data, entities, communications, storage, etc.. Trust management is one of the potential security mechanisms that aims to increase the reliability within the IoV environment. The topic has been widely explored within the vehicular ad hoc networks (VANETs). However, the VANET represents only one component of the IoV ecosystem. Thus, the approaches proposed for the VANET should be adapted to be applied for the IoV. Moreover, the advent of the emerging technologies like blockchain, cloud, SDN as well as artificial intelligence bring new opportunities to propose more relevant approaches within the trust management mechanisms within the IoV context. Accordingly, this survey deals with the literature about the trust management topic in vehicular environments. The scope considers the IoV environment as well as the relevant approaches proposed for the VANET context since it is one of the important component of the IoV ecosystem. We start by quickly reviewing the existing surveys about security of the vehicular environments. Then, we give a general overview about trust concepts. Afterwards, we present the security and trust challenges and attacks in the vehicular context. Later, we classify and compare the most relevant approaches related to the trust management for the IoV proposing a new taxonomy. We complete this survey by highlighting the open future directions and perspectives for research.}
}
@incollection{2022485,
title = {Index},
editor = {Jiaping Wu and Junyu He and George Christakos},
booktitle = {Quantitative Analysis and Modeling of Earth and Environmental Data},
publisher = {Elsevier},
pages = {485-492},
year = {2022},
isbn = {978-0-12-816341-2},
doi = {https://doi.org/10.1016/B978-0-12-816341-2.00016-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128163412000162}
}
@article{OCHELLA2022104552,
title = {Artificial intelligence in prognostics and health management of engineering systems},
journal = {Engineering Applications of Artificial Intelligence},
volume = {108},
pages = {104552},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104552},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621003961},
author = {Sunday Ochella and Mahmood Shafiee and Fateme Dinmohammadi},
keywords = {Prognostics and health management (PHM), Artificial intelligence (AI), Machine learning (ML), Predictive maintenance, Algorithm, Remaining useful life (RUL), Engineering systems},
abstract = {Prognostics and health management (PHM) has become a crucial aspect of the management of engineering systems and structures, where sensor hardware and decision support tools are deployed to detect anomalies, diagnose faults and predict remaining useful lifetime (RUL). Methodologies for PHM are either model-driven, data-driven or a fusion of both approaches. Data-driven approaches make extensive use of large-scale datasets collected from physical assets to identify underlying failure mechanisms and root causes. In recent years, many data-driven PHM models have been developed to evaluate system’s health conditions using artificial intelligence (AI) and machine learning (ML) algorithms applied to condition monitoring data. The field of AI is fast gaining acceptance in various areas of applications such as robotics, autonomous vehicles and smart devices. With advancements in the use of AI technologies in Industry 4.0, where systems consist of multiple interconnected components in a cyber–physical space, there is increasing pressure on industries to move towards more predictive and proactive maintenance practices. In this paper, a thorough state-of-the-art review of the AI techniques adopted for PHM of engineering systems is conducted. Furthermore, given that the future of inspection and maintenance will be predominantly AI-driven, the paper discusses the soft issues relating to manpower, cyber-security, standards and regulations under such a regime. The review concludes that the current systems and methodologies for maintenance will inevitably become incompatible with future designs and systems; as such, continued research into AI-driven prognostics systems is expedient as it offers the best promise of bridging the potential gap.}
}
@incollection{SCHAAP2022131,
title = {Chapter Three - Data management infrastructures and their practices in Europe},
editor = {Giuseppe Manzella and Antonio Novellino},
booktitle = {Ocean Science Data},
publisher = {Elsevier},
pages = {131-193},
year = {2022},
isbn = {978-0-12-823427-3},
doi = {https://doi.org/10.1016/B978-0-12-823427-3.00007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234273000074},
author = {Dick M.A. Schaap and Antonio Novellino and Michele Fichaut and Giuseppe M.R. Manzella},
keywords = {Data infrastructures, Data management, Marine data, Monitoring services, Standards},
abstract = {Many marine observation and data collection initiatives are promoting data sharing and open data, and their main goals are to support research, make data available to the public, advance innovation, and support the blue economy. Data reuse is the basic concept behind data sharing and open data, a concept also supported by the political agenda. This paper presents and analyses the programs that have enabled coordination of the initiatives relating to the science for sustainable development of the ocean, particularly those infrastructures that allow access to data and information. This paper is using major European programs for the practical implementation of observation data organization and management. These programs and equivalent ones conducted in other areas are providing opportunities to start a new roadmap in the integration of data management infrastructures at the international level.}
}
@incollection{KILINTZIS2022213,
title = {Chapter 7 - Respiratory data management},
editor = {Rui Pedro Paiva and Paulo de Carvalho and Vassilis Kilintzis},
booktitle = {Wearable Sensing and Intelligent Data Analysis for Respiratory Management},
publisher = {Academic Press},
pages = {213-237},
year = {2022},
isbn = {978-0-12-823447-1},
doi = {https://doi.org/10.1016/B978-0-12-823447-1.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234471000099},
author = {Vassilis Kilintzis and Nikolaos Beredimas},
keywords = {Data modeling, HL7 FHIR, Problems of respiratory data management, Web services},
abstract = {Respiratory data management includes all the operations and provisions that ensure secure and unambiguous persistent storage and exchange of all the information that pertains to the respiratory function of an individual. Failure of the health data management framework negatively impacts the quality of the provided health-care services in several aspects. Proper design of the system and modeling of the data can reduce the probability of adverse events and enhance security, data safety, maintainability, and sustainability of the system. In this chapter, a set of modern technologies and practices are discussed along with the leading standards and regulation that pertain to the health data management.}
}