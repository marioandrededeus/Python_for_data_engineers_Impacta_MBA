@article{ATAMAN2022103462,
title = {Urban Interventions and Participation Tools in Urban Design Processes: A Systematic Review and Thematic Analysis (1995 – 2021)},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103462},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103462},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007356},
author = {Cem Ataman and Bige Tuncer},
keywords = {Urban intervention, participation tool, urban design process, participatory design, informed decision-making},
abstract = {All cities need to change and transform to become more livable. Urban interventions are effective for observing the changes and participation tools are in use for collecting data from urban contexts. Nevertheless, the two research fields remain thematically disintegrated within themselves and between each other in the literature that spread across disciplines. This article aims to contribute to and advance the academic conceptualization of urban interventions and participation tools within urban design processes. In order to establish a solid basis and provide conceptual clarity, the research domains of two study fields are explored from 1995 through 2021. We conducted a thematic analysis covering 176 peer-reviewed publications in English. The studies on urban interventions are synthesized and categorized into five main thematic areas: urbanism, community, sustainability, building types, and participation; while the studies on participation tools are investigated within four thematic areas: participation, digital tools, representations, and responsive cities. We conclude that the two research fields are highly interrelated and need to be studied together. This systematic review would trigger new perspectives and directions in the future, and provide a well-conceptualized base that combines urban interventions and digital participatory designs for both theory-based and practical studies.}
}
@article{GARFINKLE2022782,
title = {Assessment of long-term bowel dysfunction after restorative proctectomy for neoplastic disease: A population-based cohort study},
journal = {Surgery},
volume = {172},
number = {3},
pages = {782-788},
year = {2022},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2021.10.068},
url = {https://www.sciencedirect.com/science/article/pii/S0039606021011107},
author = {Richard Garfinkle and Sophie Dell’Aniello and Sahir Bhatnagar and Nancy Morin and Gabriela Ghitulescu and Julio Faria and Carol-Ann Vasilevsky and Paul Brassard and Marylise Boutros},
abstract = {Background
The purpose of this study was to describe postoperative bowel dysfunction after restorative proctectomy, and to identify factors associated with its development.
Methods
Patients who underwent restorative proctectomy for rectal cancer between April 1998 and November 2018 were identified from the Hospital Episode Statistics database and linked to the Clinical Practice Research Datalink for postoperative follow-up. Bowel dysfunction was defined according to relevant symptom-based read codes and medication prescription–product codes. A Cox proportional hazards model was performed to identify factors associated with postoperative bowel dysfunction, adjusting for relevant covariates.
Results
In total, 2,197 patients were included. The median age was 70.0 (interquartile range: 62.0–77.0) years old, and the majority (59.2%) of patients were male. After a median follow-up of 51.6 (24.0–90.0) months, bowel dysfunction was identified in 620 (28.2%) patients. Risk factors for postoperative bowel dysfunction included extremes of age (<40 years old: adjusted hazards ratio 2.35, 95% confidence interval 1.18–4.65; 70–79 years old: adjusted hazards ratio 1.25, 95% confidence interval 1.03–1.52), radiotherapy (adjusted hazards ratio 1.94, 95% confidence interval 1.56–2.42), distal tumors (adjusted hazards ratio 1.62, 95% confidence interval 1.34–1.94), history of diverting ostomy (adjusted hazards ratio 1.58, 95% confidence interval 1.33–1.89), and anastomotic leak (adjusted hazards ratio 1.48, 95% confidence interval 1.06–2.05). A minimally invasive surgical approach was protective for postoperative bowel dysfunction (adjusted hazards ratio 0.68, 95% confidence interval 0.53–0.86).
Conclusion
Bowel dysfunction was common after restorative proctectomy, and several patient, disease, and treatment-level factors were associated with its development.}
}
@incollection{WANG2022238,
title = {1.10 - CyberGIS and Geospatial Data Science for Advancing Geomorphology},
editor = {John (Jack) F. Shroder},
booktitle = {Treatise on Geomorphology (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {238-259},
year = {2022},
isbn = {978-0-12-818235-2},
doi = {https://doi.org/10.1016/B978-0-12-818234-5.00122-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012818234500122X},
author = {Shaowen Wang and Michael P. Bishop and Zhe Zhang and Brennan W. Young and Zewei Xu},
keywords = {Artificial intelligence, CyberGIS, Deep learning, Geomorphology, Geospatial data science, Land cover science, LiDAR, Uncertainty},
abstract = {Theoretical and practical issues in geomorphology have not been adequately addressed due to a lack of formalization and digital representation of spatial and temporal concepts, given the limitations associated with modern-day geographic information systems (GIS). Rapid advancements in geospatial technologies have resulted in new sensors and large volumes of geospatial data that have yet to be fully exploited given a variety of computational issues. Computational limitations involving storage, preprocessing, analysis, and modeling pose significant problems for Earth scientists. Consequently, advanced cyberinfrastructure is required to address geospatial data-science issues involving communication, representation, computation, information production, decision-making, and geovisualization. We identify and discuss important aspects of exploiting advances in cyberinfrastructure that involve computational scalability, artificial intelligence, and uncertainty characterization and analysis for addressing issues in the Earth sciences. Such developments can be termed cyber geographic information science and systems (cyberGIS). We discuss this important topic by addressing the significant overlap of concepts in GIS and geomorphology that can be formalized, digitally represented, implemented, and evaluated with cyberGIS. We then introduce the fundamentals of cyberinfrastructure and cyberGIS, including a discussion of the utilization of artificial intelligence and deep learning. We finally provide one case study demonstrating operational cyberGIS capabilities.}
}
@article{FADHILLAH2022463,
title = {Mapping of landslide potential in Pyeongchang-gun, South Korea, using machine learning meta-based optimization algorithms},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {25},
number = {2},
pages = {463-472},
year = {2022},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2022.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1110982322000382},
author = {Muhammad Fulki Fadhillah and Wahyu Luqmanul Hakim and Mahdi Panahi and Fatemeh Rezaie and Chang-Wook Lee and Saro Lee},
keywords = {Susceptibility map, Hybrid algorithm, ANFIS, Metaheuristic algorithm},
abstract = {Landslides are geological hazards that can have severe impacts, threatening both the people and the local environment of highlands or mountain slopes. Landslide susceptibility mapping is an essential tool for predicting landslides and mitigating landslide-associated damage in areas prone to these events. This study aims to investigate the combination of using an adaptive network-based fuzzy inference system (ANFIS) with metaheuristic optimization algorithms: gray wolf optimizer (GWO), particle swarm optimization algorithm (PSO), and the imperialist competitive algorithm (ICA) in mapping landslide potential. The study area was Pyeongchang-gun, South Korea, for which an accurate landslide inventory dataset is available. A landslide inventory map was organized, and the data were separated randomly into training data (70%) and validation data (30%). In addition, 16 landslide-related factors consisting of geo-environmental and topo-hydrological factors were considered as predictive variables. This landslide susceptibility model was be evaluated based on the value of the area under the receiver operating characteristic (ROC) curve (AUC) to measure its accuracy. Based on the maps, the validation results showed that the optimized models of ANFIS-ICA, ANFIS-PSO, and ANFIS-GWO had AUC accuracies of 0.927, 0.947, and 0.968, respectively. The result from the hybrid algorithms model of ANFIS with metaheuristic algorithms outperformed the standalone ANFIS model in terms of accuracy in predicting landslide potential. Therefore, the ML algorithm and optimization algorithm models proposed in this study are more suitable for landslide susceptibility mapping in the study area.}
}
@article{YU2022,
title = {Blockchain-empowered secure federated learning system: Architecture and applications},
journal = {Computer Communications},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2022.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366422003474},
author = {Feng Yu and Hui Lin and Xiaoding Wang and Abdussalam Yassine and M. Shamim Hossain},
keywords = {Blockchain, Federated learning, Deep learning, Internet of Things, Intelligent transportation},
abstract = {Federated learning (FL) is a promising paradigm to realize distributed machine learning on heterogeneous clients without exposing their private data. However, there is the risk of single point failure with FL because it relies on a central server to gather the model updates from clients, moreover, malicious behaviors of some clients may lead to low-quality or even poisoned global models. Blockchain as a revolutionary distributed ledger technology can alleviate the above problems to significantly enhance the security and scalability of FL systems. Therefore, this article presents a general framework of Blockchain-based Federated Learning (BFL) system with detailed description of its key technologies and operation steps. We then review and compare the most recent representative BFL applications. And we outlook some key challenges and opportunities of the future BFL system in terms of security, cost, and scalability. Finally, we propose PoS-BFL in IoT scenarios with malicious devices. The validator voting mechanism and role switching mechanism in PoS-BFL ensure the stakes of legitimate nodes, and effectively reduce the impact of malicious nodes on the accuracy of the system model. And the experiments are conducted to demonstrate that PoS-BFL can achieve 86% accuracy, which is much higher than vanilla FL and pFedMe, and PoS-BFL is robust to some extent by adjusting the ratio of workers, validators and miners.}
}
@article{ZIMMERMANN2022706,
title = {Job Profiles in the Field of Data-Driven Supply Chain Management An Analysis of the Austrian Job Market},
journal = {Procedia Computer Science},
volume = {204},
pages = {706-713},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922008237},
author = {Robert Zimmermann and Patrick Brandtner},
keywords = {Supply Chain Management, Data, Job Advertisments, Data Science, Data Analytics},
abstract = {Supply chains are immersed in extremely complex and dynamic environments. Reducing uncertainty and improving decision making by means of data-driven supply chain management (SCM) has increasingly become an indispensable core of organizational management. To implement data-driven SCM, companies need to possess the right skilled employees. Job advertisements in the field of data-driven SCM come with multiple different titles, sets of tasks, requirements, and desired soft skills. Therefore, determining which job profile typically inherits which specific requirements, tasks and soft skills presents a challenging task. To illuminate this question, we analyzed the entire Austrian SCM job market and extracted all available job profiles, their specific tasks, requirements, and basic salaries. Analyzing these data, we give recommendations about which qualifications and skills an applicant should inherit for a specific job profile. Additionally, we highlight which tasks typically need to be performed and what minimum salaries can be expected for the specific job profiles. Thus, our results help companies to specify their job advertisements in the field of data-driven SCM and provide job applicants with an overview of tasks they can expect, requirements they need to fulfill, and skills they need to acquire. From a scientific point of view, our results contribute to the body of knowledge by providing insights into the Austrian SCM domain, by offering starting points on how to adapt training and education programs and research projects in the university sector.}
}
@article{ZHAO202256,
title = {Metaverse: Perspectives from graphics, interactions and visualization},
journal = {Visual Informatics},
volume = {6},
number = {1},
pages = {56-67},
year = {2022},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2022.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X22000158},
author = {Yuheng Zhao and Jinjing Jiang and Yi Chen and Richen Liu and Yalong Yang and Xiangyang Xue and Siming Chen},
keywords = {Metaverse, Virtual reality/Augmented reality, Computer graphics, User interaction, Immersive visualization},
abstract = {The metaverse is a visual world that blends the physical world and digital world. At present, the development of the metaverse is still in the early stage, and there lacks a framework for the visual construction and exploration of the metaverse. In this paper, we propose a framework that summarizes how graphics, interaction, and visualization techniques support the visual construction of the metaverse and user-centric exploration. We introduce three kinds of visual elements that compose the metaverse and the two graphical construction methods in a pipeline. We propose a taxonomy of interaction technologies based on interaction tasks, user actions, feedback and various sensory channels, and a taxonomy of visualization techniques that assist user awareness. Current potential applications and future opportunities are discussed in the context of visual construction and exploration of the metaverse. We hope this paper can provide a stepping stone for further research in the area of graphics, interaction and visualization in the metaverse.}
}
@article{CARTOLOVNI2022104738,
title = {Ethical, legal, and social considerations of AI-based medical decision-support tools: A scoping review},
journal = {International Journal of Medical Informatics},
volume = {161},
pages = {104738},
year = {2022},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2022.104738},
url = {https://www.sciencedirect.com/science/article/pii/S1386505622000521},
author = {Anto Čartolovni and Ana Tomičić and Elvira {Lazić Mosler}},
keywords = {Artificial intelligence, Medical ethics, Decision-making, Transparency, ELSI, Ethics by design, decision-making, medical AI, bioethics, digital health},
abstract = {Introduction
Recent developments in the field of Artificial Intelligence (AI) applied to healthcare promise to solve many of the existing global issues in advancing human health and managing global health challenges. This comprehensive review aims not only to surface the underlying ethical and legal but also social implications (ELSI) that have been overlooked in recent reviews while deserving equal attention in the development stage, and certainly ahead of implementation in healthcare. It is intended to guide various stakeholders (eg. designers, engineers, clinicians) in addressing the ELSI of AI at the design stage using the Ethics by Design (EbD) approach.
Methods
The authors followed a systematised scoping methodology and searched the following databases: Pubmed, Web of science, Ovid, Scopus, IEEE Xplore, EBSCO Search (Academic Search Premier, CINAHL, PSYCINFO, APA PsycArticles, ERIC) for the ELSI of AI in healthcare through January 2021. Data were charted and synthesised, and the authors conducted a descriptive and thematic analysis of the collected data.
Results
After reviewing 1108 papers, 94 were included in the final analysis. Our results show a growing interest in the academic community for ELSI in the field of AI. The main issues of concern identified in our analysis fall into four main clusters of impact: AI algorithms, physicians, patients, and healthcare in general. The most prevalent issues are patient safety, algorithmic transparency, lack of proper regulation, liability & accountability, impact on patient-physician relationship and governance of AI empowered healthcare.
Conclusions
The results of our review confirm the potential of AI to significantly improve patient care, but the drawbacks to its implementation relate to complex ELSI that have yet to be addressed. Most ELSI refer to the impact on and extension of the reciprocal and fiduciary patient-physician relationship. With the integration of AIbased decision making tools, a bilateral patient-physician relationship may shift into a trilateral one.}
}
@article{VESKIOJA2022102720,
title = {Implications of digitalization in facilitating socio-technical energy transitions in Europe},
journal = {Energy Research & Social Science},
volume = {91},
pages = {102720},
year = {2022},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2022.102720},
url = {https://www.sciencedirect.com/science/article/pii/S2214629622002249},
author = {Kaija Veskioja and Ralf-Martin Soe and Einari Kisel},
keywords = {Smart energy services, Implications of energy data, Multi-level perspective of sustainability transitions, Adoption of smart services, Demand-side response},
abstract = {The energy sector is digitalizing - we see a lot of smart energy services providing higher value to customers through data processing, which also increases the importance of transparency and security of data access and processing. Nevertheless, the widespread use of these services is lagging behind for enabling fundamental transitions of energy systems. This interdisciplinary article operationalises the MLP of sustainability transitions and draws together previous research on the application and implications of energy data and consumer motivation for analysing the imbalance between the supply and demand of smart energy services in the current energy transition. Besides drawing together the opportunities and challenges with energy data of 85 international smart energy services, the empirical findings present some new energy data use cases aimed especially for consumers and provide an extensive overview of additional data types with reasoning needed by service providers. These findings are complemented with the more in-depth Estonian electricity sector digitalization case study. Furthermore, we propose a list of characteristics essential for Pan-European energy data access with the main aim to open up data, activate consumers and increase the demand of smart energy services for speeding up the green energy transition.}
}
@article{NGUYEN2022108381,
title = {Knowledge mapping of digital twin and physical internet in Supply Chain Management: A systematic literature review},
journal = {International Journal of Production Economics},
volume = {244},
pages = {108381},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108381},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321003571},
author = {Tiep Nguyen and Quang Huy Duong and Truong Van Nguyen and You Zhu and Li Zhou},
keywords = {, , , },
abstract = {Physical Internet (PI) is an open global logistics system of which components are hyperconnected for increased efficiency and sustainability. Digital twin (DT), referring to the virtual representation of a physical object, is well-perceived as a key driver in the development of PI-based Supply Chain Management (SCM). Due to the capabilities of real-time monitoring and evaluation of large-scale complex systems, significant research efforts have been made to exploit values of PI/DT in SCM. Despite this, the current literature remained largely unstructured and scattered due to a lack of systematic literature reviews to synergise research findings, analyse the evolution of research fronts and extract emerging trends in the field. To address this issue, the paper deploys a bibliometric knowledge mapping approach to provide a bird's eye view of the current research status in the PI/DT-SCM area. Using CiteSpace's keyword co-occurrence network, 518 journal articles are clustered into 10 key research streams on PI/DT applications in: job shop scheduling, smart manufacturing design, PI-based SCM, manufacturing virtualisation, information management, sustainability development, data analytics, manufacturing operations management, simulation and optimisation, and assembly process planning. Based on citation burst rate, keywords representing research frontiers of the PI/DT are detected and their temporal evolutions are discussed. Likewise, some identified emerging research trends are production process and system, robotics, computer architecture, and cost. Finally, seven future research directions are suggested, which emphasise on several PI/DT-related issues, including business ecosystem, sustainability development, SC downstream management, cognitive thinking in Industry 5.0, citizen twin in digital society, and SC resilience.}
}
@article{NEBELUNG2022548,
title = {Towards Real-Time Machining Tool Failure Forecast Approach for Smart Manufacturing Systems},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {2},
pages = {548-553},
year = {2022},
note = {14th IFAC Workshop on Intelligent Manufacturing Systems IMS 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.04.251},
url = {https://www.sciencedirect.com/science/article/pii/S240589632200252X},
author = {Nicolas Nebelung and Mario D.S. {de Oliveira Santos} and Sofia T. Helena and Athon F.C.S. {de Moura Leite} and Matheus B. Canciglieri and Anderson L. Szejka},
keywords = {Industry 4.0, Smart System, Artificial Intelligence, Machine Learning, Ontology, Machine Failure Forecast},
abstract = {Industry 4.0 is characterized by a dynamic market that constantly looking for new methods to optimize and integrate manufacturing processes. In this context, Artificial Intelligence has gained prominence in problem-solving, such as failure prediction and decision making, thus improving product quality, and consequently bringing competitiveness to the company. Aiming to contribute to this scenario, this research develops a data treatment system that, from an intelligent tool and an interoperable ontological model, automates the prediction and detection of failures in machining machines lines. The system was developed for the prediction of faults in machining lines includes an artificial intelligence formed from prediction algorithms and inferences, it is possible to guarantee the correct treatment and communication of data at different stages of the process. For the experimental research, was used data collected from a machining line of a public dataset. The information is collected and classified by Artificial Intelligence that supports a decision system. The prediction of tool wear would enable the system to infer the type of problem that is causing this wear, a possible root cause, and the needed maintenance based on the ontological inference tool. By this classification of data, it is possible to achieve, through inferences, a reduction in the decision scope, bringing the possible problems caused by the incoming value. The semantic interoperability ensures correct data exchange and processing, which generates a more assertive view of production failures. The system may help companies to increase their productive process by helping them identify future failures in production if applied in a real scenario.}
}
@article{ZHAO2022107658,
title = {How can dense results be differentiated in comprehensive evaluations? A hybrid information filtering model},
journal = {Knowledge-Based Systems},
volume = {235},
pages = {107658},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107658},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009205},
author = {Lu-Tao Zhao and Wen-Jing Wang and Da-Kuan Li},
keywords = {Multiindex comprehensive evaluation, Information filtering, Student evaluation of teaching, Differentiation, Entropy},
abstract = {Multiindex comprehensive evaluation (MICE) is the basis for scientific and democratic decision-making. One of its basic functions is to distinguish evaluation objects to the greatest extent possible. However, the behavioral bias of evaluators results in dense evaluation results, affecting the effectiveness of evaluations. Integrating feature engineering, an evaluator distance-based information filtering model (IFED) is proposed to increase the differentiation of dense evaluation results. The IFED model first quantitatively measures the validity of evaluators by calculating the feature distance. Then, it filters evaluators by dividing the whole set of evaluators into valid and invalid categories according to the threshold distance. Finally, the generated valid dataset is inputted into a traditional MICE model. An empirical analysis is conducted on the teaching evaluation dataset of universities to verify the performance of the model. The IFED model identified 22.44% of invalid evaluators, which led to a 43.44% increase in the differentiation of the evaluation results. The modified entropy weighting method based on the IFED model increased the stability of student evaluations of teaching by 27.08%. Finally, we confirmed the robustness of the IFED model by replacing the entropy weighting method with three other MICE methods.}
}
@article{ZHANG202246,
title = {Adaptive deep learning for network intrusion detection by risk analysis},
journal = {Neurocomputing},
volume = {493},
pages = {46-58},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.04.061},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222004337},
author = {Lijun Zhang and Xingyu Lu and Zhaoqiang Chen and Tianwei Liu and Qun Chen and Zhanhuai Li},
keywords = {Network intrusion detection, Risk analysis, Adaptive deep learning},
abstract = {With increasing connectedness, network intrusion has become a critical security concern for modern information systems. The state-of-the-art performance of Network Intrusion Detection (NID) has been achieved by deep learning. Unfortunately, NID remains very challenging, and deep models may still mislabel many activities in real networks. Therefore, there is a need for risk analysis, which aims to know which activities may be mislabeled and why. In this paper, we propose a novel solution of interpretable risk analysis for NID that can rank the activities by their mislabeling risk. Built upon the existing framework of LearnRisk, it first extracts interpretable risk features and then trains a risk model by a learning-to-rank objective. It constructs risk features based on domain knowledge of network intrusion as well as statistical characteristics of activities. Furthermore, we demonstrate how to leverage risk analysis to improve prediction accuracy of deep models. Specifically, we present an adaptive training approach for NID that can effectively fine-tune a deep model towards a particular workload by minimizing its misprediction risk. Finally, we empirically evaluate the performance of the proposed solutions on real benchmark data. Our extensive experiments have shown that the proposed solution of risk analysis can identify mislabeled activities with considerably higher accuracy than the existing alternatives, and the proposed solution of adaptive training can effectively improve the performance of deep models by considerable margins in both offline and online settings.}
}
@article{DONG2022105435,
title = {Recent text-based research and applications in railways: A critical review and future trends},
journal = {Engineering Applications of Artificial Intelligence},
volume = {116},
pages = {105435},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105435},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622004250},
author = {Kaitai Dong and Igor Romanov and Colin McLellan and Ahmet F. Esen},
keywords = {Natural language processing, Machine learning, Railway, Text-based analysis, Critical review},
abstract = {In the railway industry, a significant amount of data is stored in the textual format. The advanced development of natural language processing and text mining techniques enable automatic knowledge extraction and discovery from such documents. This paper presents a systematic review with quantitative and qualitative analyses to understand the current state of text-based research in the context of railway transport. The paper collects 107 relevant publications in the past decade and identifies different channels for researchers to obtain text data in railways and the corresponding text analysis application use-cases. Moreover, a comprehensive analysis is performed on the state-of-the-art machine learning and natural language processing methods. Four key research directions, namely multilingual NLP, digital maintenance, external data integration, and railway-centred solution pipeline, are identified from Siemens Mobility’s perspective to highlight the most prominent challenges faced in the railway industry.}
}
@article{LIAO2022104304,
title = {Knowledge synthesis of intelligent decision techniques applications in the AECO industry},
journal = {Automation in Construction},
volume = {140},
pages = {104304},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104304},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522001777},
author = {Longhui Liao and Lirong Quan and Chuan Yang and Linhui Li},
keywords = {Intelligent decision technique, Knowledge synthesis, Decision support, Neural network},
abstract = {Intelligent decision techniques (IDTs) have been increasingly applied to support (or even replace) decision-makers to make accurate decisions, such as supplier selection and energy retrofit, in the architecture, engineering, construction, and operations (AECO) industry. However, concerning substantial applications, fragmented knowledge of IDTs has prevented them from reaching their full potential. By evaluating 254 related articles, this study aims to investigate the status quo of IDTs applications in the AECO industry and synthesize knowledge in this domain. To this end, a mixed method, which integrates bibliometric analysis focusing on keywords co-occurrence analysis and citation burst detection, and systematic evaluation based on a 3D structure (knowledge, logic, and time), was conducted. A bottom-up knowledge structure was established, including knowledge basis, specific IDTs, five pillar topics, as well as current challenges and future directions. This study contributes to scholarship in the targeted domain and provides theoretical and practical references for both researchers and practitioners.}
}
@article{FAN2022103262,
title = {Road grade estimation based on Large-scale fuel consumption data of connected vehicles},
journal = {Transportation Research Part D: Transport and Environment},
volume = {106},
pages = {103262},
year = {2022},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2022.103262},
url = {https://www.sciencedirect.com/science/article/pii/S1361920922000918},
author = {Pengfei Fan and Guohua Song and Zijun Zhu and Yizheng Wu and Zhiqiang Zhai and Lei Yu},
keywords = {Road Grade, Fuel Consumption, Vehicle Specific Power, Connected Vehicle},
abstract = {Road grade is crucial in vehicle control and emission studies but challenging to obtain in large-scale road networks due to current methods’ expensive deployment costs or limited accuracy. This paper proposed a scale-deployable and cost-efficient road grade estimation solution based on the fuel consumption rate (FCR) difference between flat and graded roads. Real-world road grades from design drawings and 261,814 second-by-second vehicle operating data from 680 light-duty vehicles were collected to examine the proposed method’s performance. Sensitivity tests for vehicle types and sample sizes were conducted. Results show that (1) the proposed method acquired road grade with an accuracy of 0.12% mean absolute error (MAE), (2) in positive vehicle specific power (VSP) bins, a 1% road grade caused an average 16% FCR change, and (3) larger-scale fuel consumption data contributed to reducing estimation error which converged from 0.25% to 0.12% as the segment passes increased from 50 to 400.}
}
@article{ROESSLER2022105569,
title = {A machine learning approach for modelling the occurrence of Galba truncatula as the major intermediate host for Fasciola hepatica in Switzerland},
journal = {Preventive Veterinary Medicine},
volume = {200},
pages = {105569},
year = {2022},
issn = {0167-5877},
doi = {https://doi.org/10.1016/j.prevetmed.2022.105569},
url = {https://www.sciencedirect.com/science/article/pii/S0167587722000022},
author = {Anne S. Roessler and Andreas W. Oehm and Gabriela Knubben-Schweizer and Andreas Groll},
keywords = {trematodes, liver fluke, spatial risk model, intermediate host, snail habitats, cattle diseases},
abstract = {Fasciolosis caused by the trematode Fasciola hepatica is an important parasitosis in both livestock and humans across the globe. Chronic infections in cattle are associated with considerable economic losses. As a prerequisite for an effective control and prevention of fasciolosis in cattle fine-scale predictive models on farm-level are needed. Since disease transmission will only occur where the mollusc intermediate host is present, the objective of our research was to develop a regression model that allows to predict the local presence or absence of Galba truncatula as principal intermediate host for Fasciola hepatica in Switzerland. By implementing generalized linear mixed models (GLMMs) a total amount of 70 variables were analysed for their potential influence on the likelihood πi of finding Galba truncatula at a certain site. Important site-specific features could be considered by selecting suitable modelling procedures. The statistical software R was used to conduct regression analysis, performing the grplasso and the glmmLasso method. The selection of parameters was based on 10-fold cross validation and the Bayesian Information Criterion (BIC). This yielded a total number of 19 potential predictor variables for the grplasso and 13 variables for the glmmLasso model, which also included random effects. Nine variables appeared to be relevant predictors for the occurrence of Galba truncatula in both models. These included reed/humid area, spring water, water bodies within a 100 m radius, and trees/bushes as powerful positive predictors. High soil depth, temperatures frequently exceeding 30 °C in the year preceding the search for snails and temperatures below 0 °C especially in the second year before were identified to exert an adverse effect on the occurrence of Galba truncatula. Temperatures measured near ground level proved to be more powerful predictors than macroclimatic parameters. Precipitation values seemed to be of minor impact in the given setting. Both regression models may be convenient for a fine-scale prediction of the occurrence of Galba truncatula, and thus provide useful approaches for the development of future spatial transmission models, mapping the risk of fasciolosis in Switzerland on farm-level.}
}
@article{YABE2022101777,
title = {Mobile phone location data for disasters: A review from natural hazards and epidemics},
journal = {Computers, Environment and Urban Systems},
volume = {94},
pages = {101777},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101777},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000217},
author = {Takahiro Yabe and Nicholas K.W. Jones and P. Suresh C. Rao and Marta C. Gonzalez and Satish V. Ukkusuri},
keywords = {Mobile phone location data, Disaster risk management, Natural Hazards, Epidemics, Data for development},
abstract = {Rapid urbanization and climate change trends, intertwined with complex interactions of various social, economic, and political factors, have resulted in an increase in the frequency and intensity of disaster events. While regions around the world face urgent demands to prepare for, respond to, and to recover from such disasters, large-scale location data collected from mobile phone devices have opened up novel approaches to tackle these challenges. Mobile phone location data have enabled us to observe, estimate, and model human mobility dynamics at an unprecedented spatio-temporal granularity and scale. The COVID-19 pandemic, in particular, has spurred the use of mobile phone location data for pandemic and disaster management. However, there is a lack of a comprehensive review that synthesizes the last decade of work and case studies leveraging mobile phone location data for response to and recovery from natural hazards and epidemics. We address this gap by summarizing the existing work, and point to promising areas and future challenges for using mobile phone location data to support disaster response and recovery.}
}
@article{HEIDARI2022104089,
title = {Applications of ML/DL in the management of smart cities and societies based on new trends in information technologies: A systematic literature review},
journal = {Sustainable Cities and Society},
volume = {85},
pages = {104089},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.104089},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722004061},
author = {Arash Heidari and Nima Jafari Navimipour and Mehmet Unal},
keywords = {Smart cities, Sustainable city, Power management, Machine learning, City management, Deep learning, Review},
abstract = {The goal of managing smart cities and societies is to maximize the efficient use of finite resources while enhancing the quality of life. To establish a sustainable urban existence, smart cities use some new technologies such as the Internet of Things (IoT), Internet of Drones (IoD), and Internet of Vehicles (IoV). The created data by these technologies are submitted to analytics to obtain new information for increasing the smart societies and cities' efficiency and effectiveness. Also, smart traffic management, smart power, and energy management, city surveillance, smart buildings, and patient healthcare monitoring are the most common applications in smart cities. However, the Artificial intelligence (AI), Machine Learning (ML), and Deep Learning (DL) approach all hold a lot of promise for managing automated activities in smart cities. Therefore, we discuss different research issues and possible research paths in which the aforementioned techniques might help materialize the smart city notion. The goal of this research is to offer a better understanding of (1) the fundamentals of smart city and society management, (2) the most recent developments and breakthroughs in this field, (3) the benefits and drawbacks of existing methods, and (4) areas that require further investigation and consideration. IoT, cloud computing, edge computing, fog computing, IoD, IoV, and hybrid models are the seven key emerging developments in information technology that, in this paper, are considered to categorize the state-of-the-art techniques. The results indicate that the Conventional Neural Network (CNN) and Long Short-Term Memory (LSTM) are the most commonly used ML method in the publications. According to research, the majority of papers are about smart cities' power and energy management. Furthermore, most papers have concentrated on improving only one parameter, where the accuracy parameter obtains the most attention. In addition, Python is the most frequently used language, which was used in 69.8% of the papers.}
}
@article{LOUTFI2022473,
title = {A framework for evaluating the business deployability of digital footprint based models for consumer credit},
journal = {Journal of Business Research},
volume = {152},
pages = {473-486},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.07.057},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322006683},
author = {Ahmad Amine Loutfi},
keywords = {FinTech, Digital Finance, Alternative Data, Digital Footprint, Artificial Intelligence},
abstract = {Every time we interact with online digital services, we generate large amounts of data that reveal our shopping habits, social interactions, and much more. We refer to these data collectively as the user-generated digital footprint (UGDF). Today, there is growing interest in using UGDF data as an alternative to conventional financial data in building consumer credit models—UGDF models. Unfortunately, we also observe a hype where the models’ business deployability is reduced to simplistic technical metrics, namely, the model’s prediction accuracy. This study argues that this is a misleading oversimplification of the financial sector’s business realities as it ignores vital dimensions such as the model’s economic viability. Therefore, we develop a framework for evaluating the business deployability of UGDF models for consumer credit using a design science research methodology. The framework is composed of seven criteria: Data accessibility, data coverage, data timeliness, data authenticity, cost of deployment, interpretability, and compliance.}
}
@article{BOUHLAL2022819,
title = {The internet of things for smart ports},
journal = {Procedia Computer Science},
volume = {203},
pages = {819-824},
year = {2022},
note = {17th International Conference on Future Networks and Communications / 19th International Conference on Mobile Systems and Pervasive Computing / 12th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls, Ontario, Canada},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.07.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922007281},
author = {Amine BOUHLAL and Rachida AITABDELOUAHID and Abdelaziz MARZAK},
keywords = {Internet of things, Tangier Med Port, vessels, Containers, Terminals},
abstract = {Researchers have investigated the impact of the Internet of Things on port performance in order to identify IoT applications and determine any changes that may be needed. Tangier Med Port will be able to compete better than its rivals, significantly improving its efficiency. A real-time tracking and monitoring application can be used to track vessels and containers in the first application. In addition to managing traffic or allocating priority and services to vessels moving through the port jurisdiction, information about vessels and containers can also be utilized to stack containers optimally at the port terminals. Thirdly, the Internet of Things facilitates the transition from manual to automated ports/terminals. Fourth, they can spend less time interacting with customers daily. Furthermore, the increased exchange of data will allow existing processes to be optimized. If all the likely threats can be dealt with, the aforementioned points above may have profound effects on the performance of Tangier Med Port, especially its efficiency in its principal activity, which is container activity. This development should be driven by all stakeholders of Tangier Med Port. When compared to its two main rivals, Algeciras and Valencia, Tanger Med can become the most attractive port if it encourages other parties to follow the development of the Internet of Things. Additionally, Port Tanger Med has a geographical advantage.}
}
@article{CANAVERAHERRERA2022102970,
title = {On the relation between ‘resilience’ and ‘smartness’: A critical review},
journal = {International Journal of Disaster Risk Reduction},
volume = {75},
pages = {102970},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.102970},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922001893},
author = {Juan Sebastián Cañavera-Herrera and Junqing Tang and Timea Nochta and Jennifer M. Schooling},
keywords = {Smart city, Resilience, Sustainability, Digital technology, Data security},
abstract = {Cities continue to face significant challenges that test their capacity for resilience. With the development of smart cities, there needs to be a better understanding of how the introduction of smart technologies will affect urban resilience. To address this issue, this article presents a critical review of the literature on smart cities and smart technologies focussing on representations of resilience. The findings reveal that discussing resilience in relation to smart city components of the data layer, digital technologies and the physical city can provide some degree of clarity despite the existence of a multiplicity of definitions and interpretations. Furthermore, the analysis indicates that the nature of relationships between ‘smartness’ and ‘resilience’ remains contested, and largely dependent on the perceived role of digital technologies in resilience-building processes. This in turn is influenced by how these technologies are used and what the intention and expectations are in relation to their use. In order to address these issues, we conclude that further interdisciplinary research, extending to the physical, social and environmental systems of cities, is needed to better understand the relations between smartness and resilience.}
}
@article{YANG2022102230,
title = {A digital twin-driven hybrid approach for the prediction of performance degradation in transmission unit of CNC machine tool},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {73},
pages = {102230},
year = {2022},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2021.102230},
url = {https://www.sciencedirect.com/science/article/pii/S0736584521001125},
author = {Xin Yang and Yan Ran and Genbao Zhang and Hongwei Wang and Zongyi Mu and Shengguang Zhi},
keywords = {Digital twin, Data-driven, Wear, Simulation, Performance degradation, CNCMT},
abstract = {Precision performance prediction of transmission system is considered as a key technology to modern equipment health management. Given the importance of maintaining a transmission system's precision, this paper presents a hybrid approach framework driven by digital twin technology (DT), to predict performance degradation. Firstly, a DT model based on meta-action theory is established, and real-time monitoring and digital simulation, driven by DT data, is realized in order to analyze the precision of the transmission units in machine tools. Secondly, the wear of gear in transmission unit is studied through Achard wear theory, which considered the comprehensive influence of gear load and speed on surface wear of the gear pair tooth, based on the model driving method. The performance degradation of the transmission unit is obtained by using the RBF neural network algorithm based on the data-driven method to extrapolate the wear data to the field-measurable precision index value. In addition, the hybrid predictive approach of the performance degradation model through the particle filter algorithm is built, and the real-time data is used to update the current state estimation to improve the prediction accuracy. By combining the mechanism of the physical degradation processes with the real-time and historical data and turning them into a cooperative architecture, this prediction method uses the complementary advantages offered by the fusion of these methods to bridge the link between data-driven prediction and model-based prediction. Finally, the method has been successfully applied to the precision prediction of the transmission unit in CNCMT turntable, and it is compared with the single prediction method to verify the effectiveness and feasibility.}
}
@article{WELLSANDT2022382,
title = {Hybrid-augmented intelligence in predictive maintenance with digital intelligent assistants},
journal = {Annual Reviews in Control},
volume = {53},
pages = {382-390},
year = {2022},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1367578822000165},
author = {Stefan Wellsandt and Konstantin Klein and Karl Hribernik and Marco Lewandowski and Alexandros Bousdekis and Gregoris Mentzas and Klaus-Dieter Thoben},
keywords = {Engineering applications of artificial intelligence, Predictive maintenance, Human-automation integration, Hybrid intelligence systems},
abstract = {Industrial maintenance strategies increasingly rely on artificial intelligence to predict asset conditions and prescribe maintenance actions. The related maintenance software and human maintenance actors can form a hybrid-augmented intelligence system where each side benefits from and enhances the other side's intelligence. This system requires optimized human-machine interfaces to help users express their knowledge and retrieve information from difficult-to-use software. Therefore, this article proposes a novel approach for maintenance experts and operators to interact with a predictive maintenance system through a digital intelligent assistant. This assistant is artificial intelligence (AI) that could help its users interact with the system via natural language and collect their feedback about the success of maintenance interventions. Implementing hybrid-augmented intelligence in a predictive maintenance system faces several technical, social, economic, organizational, and legal challenges. The benefits, limitations, and risks of hybrid-augmented intelligence must be clear to all employees to advocate its use. AI-focused change management and employee training could be techniques to address these challenges. The success of the proposed approach also relies on the continuous improvement of natural language understanding. Such a process will need conversation-driven development where actual interactions with the assistant provide accurate training data for language and dialog models. Future research has to be interdisciplinary and may cover the integration of explainable AI, suitable AI laws, operationalized trustworthy AI, efficient design for human-computer interaction, and natural language processing adapted to predictive maintenance.}
}
@article{MIGLIORINI2022166869,
title = {A horizontally scalable online processing system for trigger-less data acquisition},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {1036},
pages = {166869},
year = {2022},
issn = {0168-9002},
doi = {https://doi.org/10.1016/j.nima.2022.166869},
url = {https://www.sciencedirect.com/science/article/pii/S0168900222003412},
author = {Matteo Migliorini and Jacopo Pazzini and Andrea Triossi and Marco Zanetti and Alberto Zucchetta},
keywords = {Data acquisition, Trigger, Online data processing},
abstract = {The vast majority of high energy physics experiments rely on data acquisition and hardware-based trigger systems performing a number of stringent selections before storing data for offline analysis. The online reconstruction and selection performed at the trigger level are bound to the synchronous nature of the data acquisition system, resulting in a trade-off between the amount of data collected and the complexity of the online reconstruction performed. Exotic physics processes, such as long-lived and slow-moving particles, are rarely targeted by online triggers as they require complex and nonstandard online reconstruction, usually incompatible with the time constraints of most data acquisition systems. The online trigger selection can thus impact as one of the main limiting factors to the experimental reach for exotic signatures. Alternative data acquisition solutions based on the continuous and asynchronous processing of the stream of data from the detectors are therefore foreseeable as a way to extend the experimental physics reach. Trigger-less data readout systems, paired with efficient streaming data processing solutions, can provide a viable alternative. In this document, an end-to-end implementation of a fully trigger-less data acquisition and online data processing system is discussed. An easily scalable and deployable implementation of such an architecture is proposed, based on open-source distributed computing frameworks capable of performing asynchronous online processing of streaming data. The proposed schema can be suitable for deployment as a fully integrated data acquisition system for small-scale experimental apparatus, or to complement the trigger-based data acquisition systems of larger experiments. A muon telescope setup consisting of a set of gaseous detectors is used as the experimental development testbed in this work, and a fully integrated online processing pipeline deployed on cloud computing resources is implemented and described.}
}
@article{WANG2022348,
title = {Blockchain Empowered Federated Learning for Data Sharing Incentive Mechanism},
journal = {Procedia Computer Science},
volume = {202},
pages = {348-353},
year = {2022},
note = {International Conference on Identification, Information and Knowledge in the internet of Things, 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.04.047},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922005816},
author = {Zexin Wang and Biwei Yan and Anming Dong},
keywords = {Federated learning, Blockchain, Incentive Mechanism, Shaply Value},
abstract = {In the machine learning, data sharing between different participants can increase the amount of data, improve the quality of the dataset, and thereby improve the quality of the model. Under the condition of data supervision, federated learning, as a distributed machine learning, aims to protect data while training models through collaboration among all parties to achieve data sharing and improve model quality. However, there are still some issues. For instance, the lack of trust between the participants makes it impossible to establish a secure and reliable sharing mechanism. In addition, how to fairly share the benefits generated by the model, identify honest participants and punish malicious participants is still a challenge. In this paper, we propose a new federated learning scheme based on blockchain architecture for federated learning data sharing. Moreover, an incentive mechanism based on reputation points and Shaply values is proposed to improve the sustainability of the federated learning system, which provides a credible participation mechanism for data sharing based on federated learning and fair incentives. The experimental results and analysis show that the loss of federated learning is more smooth than that of centralized machine learning.}
}
@article{DEBAUCHE20227494,
title = {Cloud and distributed architectures for data management in agriculture 4.0 : Review and future trends},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {9},
pages = {7494-7514},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002664},
author = {Olivier Debauche and Saïd Mahmoudi and Pierre Manneback and Frédéric Lebeau},
keywords = {Agriculture 4.0, Smart farming, Smart agriculture, Lambda architecture, Kappa architecture, Edge computing, Fog computing, Micro-service architecture, Data lake, Data house, Blockchain, Osmotic computing, Dew computing},
abstract = {The Agriculture 4.0, also called Smart Agriculture or Smart Farming, is at the origin of the production of a huge amount of data that must be collected, stored, and processed in a very short time. Processing this massive quantity of data needs to use specific infrastructure that use adapted IoT architectures. Our review offers a comparative panorama of Central Cloud, Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends used in the context of Agriculture 4.0. In this review, we try to answer 4 research questions: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and respond to its peculiarities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal development possibilities that allow the transition from research to industrialization? (4) What are the vertical valuations possibilities to move from algorithms trained in the cloud to embedded or stand-alone products? For this, we compare architectures with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput, Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the advantages and disadvantages of each of them.}
}
@article{CHEN2022100336,
title = {An Intelligent Government Complaint Prediction Approach},
journal = {Big Data Research},
volume = {30},
pages = {100336},
year = {2022},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2022.100336},
url = {https://www.sciencedirect.com/science/article/pii/S2214579622000302},
author = {Siqi Chen and Yanling Zhang and Bin Song and Xiaojiang Du and Mohsen Guizani},
keywords = {Machine learning, Text classification, Government complaint prediction, Automatic label correction},
abstract = {Recent advances in machine learning (ML) bring more opportunities for greater implementation of smart government construction. However, there are many challenges in terms of government data application due to the previous nonstandard records and man-made errors. In this paper, we propose a practical intelligent government complaint prediction (IGCP) framework that helps governments quickly respond to citizens' consultations and complaints via ML technologies. In addition, we put forward an automatic label correction method and demonstrate its effectiveness on the performance improvement of intelligent government complaint prediction task. Specifically, the central server collects the interaction records from users and departments and automatically integrates them by the label correction approach which is designed to evaluate the similarity between different labels in data, and merge highly similar labels and corresponding samples into their most similar category. Based on those refined data, the central server quickly generates accurate solutions to complaints through text classification algorithms. The main innovation of our approach is that we turn the task of government complaint distribution into a text classification problem which is uniformly coordinated by the central server, and employ the label correction approach to correct redundant labels for training better models based on limited complaint records. To explore the influences of our approach, we evaluate its performance on real-world government service records provided by our collaborator. The experimental results demonstrate the prediction task which uses the label correction algorithm achieves significant improvements on almost all metrics of the classifier.}
}
@article{KAUSAR202216,
title = {Automated Machine Learning based Elderly Fall Detection Classification},
journal = {Procedia Computer Science},
volume = {203},
pages = {16-23},
year = {2022},
note = {17th International Conference on Future Networks and Communications / 19th International Conference on Mobile Systems and Pervasive Computing / 12th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls, Ontario, Canada},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S187705092200610X},
author = {Firdous Kausar and Medhat Awadalla and Mostefa Mesbah and Taif AlBadi},
keywords = {Fall Detection, Automated Machine Learning, Classification Learner, Optimized Classifier},
abstract = {As we grow older, one of the most concerning aspects of our lives becomes increasingly challenging to manage our health. Fall is a leading cause of health problems or death in the elderly population. Using a wearable sensors device, this research presents a strategy for identifying and distinguishing fall activities from activities of daily living (ADL) in older persons. The conventional Machin learning method was applied by extracting features from telemetry data after pre-processing, and feature extraction. It is then compared to non-coding Automated Machine Learning (AutoML) method, where all the selected classifiers get automatically optimized. Furthermore, machine learning algorithms such as Support Vector Machine, K-Nearest Neighbor, Random Forest tree, and Artificial Neural Network are used to categorize acceleration signals as falling or regular activity. The test results indicate that AutoML can predict exceptionally accurate results in binary classifications with 99.9% accuracy on three of the four machine learning techniques it was tested against.}
}
@article{HU2022113343,
title = {Association between outdoor artificial light at night and sleep duration among older adults in China: A cross-sectional study},
journal = {Environmental Research},
volume = {212},
pages = {113343},
year = {2022},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2022.113343},
url = {https://www.sciencedirect.com/science/article/pii/S0013935122006703},
author = {Kejia Hu and Wanlu Li and Yunquan Zhang and Huashuai Chen and Chen Bai and Zhenchun Yang and Thiess Lorenz and Keyang Liu and Kokoro Shirai and Jinglu Song and Qi Zhao and Yali Zhao and Junfeng (Jim) Zhang and Jing Wei and Jiahao Pan and Jin Qi and Tingting Ye and Yi Zeng and Yao Yao},
keywords = {Nighttime light, Outdoor light, ALAN, Sleep duration, Sleep, China},
abstract = {Background
Light after dusk disrupts the circadian rhythms and shifts the timing of sleep later; but it is unknown whether outdoor artificial light at night (ALAN) affects sleep quality. This study aimed to explore the association between residential outdoor ALAN and sleep duration in a nationally representative sample of Chinese older adults.
Methods
We examined the cross-sectional associations of outdoor ALAN with self-reported sleep duration in 13,474 older adults participating in the 2017–2018 wave of the Chinese Longitudinal Healthy Longevity Survey (CLHLS). Outdoor ALAN exposure was estimated at the residence level using satellite images. We applied generalized linear mixed models to investigate the association between ALAN exposure and sleep duration. We performed stratified analyses by age, sex, education, and household income levels. Moreover, we used multi-level logistic regression models to investigate the effects of ALAN on the short sleep duration (≤6 h) and the long sleep duration (>8 h), respectively, in reference to sleep for >6–8 h per day.
Results
We found a significant association between outdoor ALAN intensity and sleep duration. The highest quartile of ALAN was associated with 17.04 (95% CI: 9.42–24.78) fewer minutes of sleep as compared to the lowest quartile. The reductions in sleep duration per quartile change in ALAN were greater in the young old (≥65–85 years) and in those with higher levels of education, and those with higher household income, respectively. We did not detect a sex difference. In addition, those in the highest quartile of ALAN were more likely to report a 25% (95% CI: 10%–42%) increase in short sleep (<6 h), and a 21% (95% CI: 9%–31%) decrease in long sleep (>8 h).
Conclusions
Increasing outdoor nighttime light intensity surrounding residences was associated with shorter sleep duration in older residents in China. This finding implies the importance of urban outdoor artificial light management as a potential means to lower the public health burden of sleep disorders.}
}
@article{MEAD2022100168,
title = {Generalised network architectures for environmental sensing: Case studies for a digitally enabled environment},
journal = {Array},
volume = {14},
pages = {100168},
year = {2022},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2022.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2590005622000303},
author = {M.I. Mead and M. Bevilacqua and C. Loiseaux and S.H. Hallett and S. Jude and C. Emmanouilidis and J. Harris and P. Leinster and S. Mutnuri and T.H. Tran and L. Williams},
keywords = {Ubiquitous sensor networks, Network analytics, Integrated sensing, Network policy considerations, Living laboratory, Digital environment, Internet of things, Urban observatory},
abstract = {A digitally enabled environment is a setting which incorporates sensors coupled with reporting and analytics tools for understanding, observing or managing that environment. Large scale data collection and analysis are a part of the emerging digitally enabled approach for the characterisation and understanding of our environment. It is recognised as offering an effective methodology for addressing a range of complex and interrelated social, economic and environmental concerns. The development and construction of the approach requires advances in analytics control linked with a clear definition of the issues pertaining to the interaction between elements of these systems. This paper presents an analysis of selected issues in the field of analytics control. It also discusses areas of progress, and areas in need of further investigation as sensing networks evolve. Three case studies are described to illustrate these points. The first is a physical analytics test kit developed as a part of the “Reinvent the Toilet Challenge” (RTTC) for process control in a range of environments. The second case study is the Cranfield Urban Observatory that builds on elements of the RTTC and is designed to allow users to develop user interfaces to monitor, characterise and compare a variety of environmental and infrastructure systems plus behaviours (e.g., water distribution, power grids). The third is the Data and Analytics Facility for National Infrastructure, a cloud-based high-performance computing cluster, developed to receive, store and present such data to advanced analytical and visualisation tools.}
}
@article{WANG2022244,
title = {Towards intelligent welding systems from a HCPS perspective: A technology framework and implementation roadmap},
journal = {Journal of Manufacturing Systems},
volume = {65},
pages = {244-259},
year = {2022},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2022.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0278612522001613},
author = {Baicun Wang and Yang Li and Theodor Freiheit},
keywords = {Smart manufacturing, Human-cyber-physical systems (HCPS), Human-centricity, Roadmap},
abstract = {A framework and implementation roadmap for an intelligent welding system (IWS) is proposed from the human-cyber-physical systems (HCPS) perspective of integrating cyber systems with humans and physical systems. Key technologies and system requirements for the framework are comprehensively analyzed. A technology network is proposed to explore the link between complex IWS technologies and application domain requirements. To investigate the practical extent of the state-of-the-art, an example enterprise illustrates the technologies necessary to implement an IWS and the representative technological gaps. Technologies required for IWS were evaluated for their maturity, benefit, and market availability using the Gartner hype-cycle and priority matrix methodology. Finally, an implementation roadmap with research suggestions towards IWS is recommended. This work can support enterprises or factories that want to implement intelligent welding into their operations by clarifying the development state of intelligent technologies and the priority by which further development should be pursued.}
}
@article{RAMMER2022104555,
title = {Artificial intelligence and industrial innovation: Evidence from German firm-level data},
journal = {Research Policy},
volume = {51},
number = {7},
pages = {104555},
year = {2022},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2022.104555},
url = {https://www.sciencedirect.com/science/article/pii/S0048733322000798},
author = {Christian Rammer and Gastón P. Fernández and Dirk Czarnitzki},
keywords = {Artificial Intelligence, Innovation, CIS data, Germany},
abstract = {This paper analyses the link between the use of Artificial Intelligence (AI) and innovation performance in firms. Based on firm-level data from the German part of the Community Innovation Survey (CIS) 2018, we examine the role of different AI methods and application areas in innovation. The results show that 5.8% of firms in Germany were actively using AI in their business operations or products and services in 2019. We find that the use of AI is associated with annual sales with world-first product innovations in these firms of about €16 billion (i.e. 18% of total annual sales of world-first innovations). In addition, AI technologies have been used in process innovation that contributed to about 6% of total annual cost savings of the German business sector. Firms that apply AI broadly (using different methods for different applications areas) and that have already several years of experience in using AI obtain significantly higher innovation results. These positive findings on the role of AI for innovation have to be interpreted with caution as they refer to a specific country (Germany) in a situation where AI started to diffuse rapidly.}
}
@article{MERHI2022102545,
title = {An evaluation of the critical success factors impacting artificial intelligence implementation},
journal = {International Journal of Information Management},
pages = {102545},
year = {2022},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2022.102545},
url = {https://www.sciencedirect.com/science/article/pii/S0268401222000792},
author = {Mohammad I. Merhi},
keywords = {Artificial intelligence implementation, Critical factors, Analytics, Ethics, Analytical hierarchy process},
abstract = {AI systems offer organizations great benefits causing decision-makers to invest more in these systems. The advantages of AI cannot be achieved without successful implementation. Thus, it is crucial to recognize the factors impacting the successful implementation of AI. It is also important to assess and rank these factors by their importance to assist decision-makers in implementing these systems and increasing the success rate. Due to its importance, scholars called for studies to expand our knowledge in this critical area. This paper identifies, extracts, and assesses the most critical factors that influence the implementation of AI systems. This study identifies nineteen factors and categorizes them into four categories: organization, technology, process, and environment. The analytical hierarchy process is used to evaluate the factors and the categories. The analysis offers two types of results, at the category level and the level of the factors. The results indicate that technology is the most significant of the four categories. The results also suggest that ethics is the most crucial factor among all nineteen factors. The order of all factors and discussions of the implications of the findings for practice and research are presented in the paper.}
}
@article{BI2022,
title = {Achieving dynamic privacy measurement and protection based on reinforcement learning for mobile edge crowdsensing of IoT},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822001614},
author = {Renwan Bi and Mingfeng Zhao and Zuobin Ying and Youliang Tian and Jinbo Xiong},
keywords = {Mobile edge crowdsensing, Dynamic privacy measurement, Personalized privacy threshold, Privacy protection, Reinforcement learning},
abstract = {With the maturity and development of 5G field, Mobile Edge CrowdSensing (MECS), as an intelligent data collection paradigm, provides a broad prospect for various applications in IoT. However, sensing users as data uploaders lack a balance between data benefits and privacy threats, leading to conservative data uploads and low revenue or excessive uploads and privacy breaches. To solve this problem, a Dynamic Privacy Measurement and Protection (DPMP) framework is proposed based on differential privacy and reinforcement learning. Firstly, a DPM model is designed to quantify the amount of data privacy, and a calculation method for personalized privacy threshold of different users is also designed. Furthermore, a Dynamic Private sensing data Selection (DPS) algorithm is proposed to help sensing users maximize data benefits within their privacy thresholds. Finally, theoretical analysis and ample experiment results show that DPMP framework is effective and efficient to achieve a balance between data benefits and sensing user privacy protection, in particular, the proposed DPMP framework has 63% and 23% higher training efficiency and data benefits, respectively, compared to the Monte Carlo algorithm.}
}
@article{RAMU2022103663,
title = {Federated learning enabled digital twins for smart cities: Concepts, recent advances, and future directions},
journal = {Sustainable Cities and Society},
volume = {79},
pages = {103663},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103663},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721009264},
author = {Swarna Priya Ramu and Parimala Boopalan and Quoc-Viet Pham and Praveen Kumar Reddy Maddikunta and Thien Huynh-The and Mamoun Alazab and Thanh Thi Nguyen and Thippa Reddy Gadekallu},
keywords = {Digital Twin, Federated Learning, Internet of Things, Virtual replica, Smart city},
abstract = {Recent advances in Artificial Intelligence (AI) and the Internet of Things (IoT) have facilitated continuous improvement in smart city based applications such as smart healthcare, transportation, and environmental management. Digital Twin (DT) is an AI-based virtual replica of the real-world physical entity. DTs have been successfully adopted in manufacturing and industrial sectors, they are however still at the early stage in smart city based applications. The major reason for this lag is the lack of trust and privacy issues in sharing sensitive data. Federated Learning (FL) is a technology that could be integrated along with DT to ensure privacy preservation and trustworthiness. This paper focuses on the integration of these two promising technologies for adoption in real-time and life-critical scenarios, as well as for ease of governance in smart city based applications. We present an extensive survey on the various smart city based applications of FL models in DTs. Based on the study, some prominent challenges and future directions are presented for better FL–DT integration in future applications.}
}
@article{KIM2022117405,
title = {Accurate and prompt answering framework based on customer reviews and question-answer pairs},
journal = {Expert Systems with Applications},
volume = {203},
pages = {117405},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117405},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007473},
author = {Eun Kim and Hyejung Yoon and Jungeun Lee and Misuk Kim},
keywords = {Question answering, E-commerce market, Customer reviews, Natural language processing},
abstract = {As e-commerce markets have gradually expanded, online shopping malls have provided various services aiming to secure competitiveness. A service for providing an accurate and prompt response when a customer writes an inquiry regarding a product represents a space directly connected to the customer and plays an important role, as it is directly related to product sales. However, the current online shopping mall answering service has disadvantages, e.g., it takes time for an administrator to write an answer directly, or to provide an answer within a set of answers. In this paper, we propose an answer framework for solving this problem, based on customer reviews. When a user writes a query, the framework provides an appropriate answer in real time through the system’s question-and-answer pairs and customer reviews. The framework’s performance is verified through a qualitative evaluation. In addition, it is confirmed that a customized model for reflecting the characteristics of each shopping mall can be created by using additional information from the collected data. The proposed framework is expected to support customers’ online shopping through more reliable and efficient information retrieval, and to reduce shopping mall operation and maintenance costs.}
}
@article{FAVI2022118671,
title = {Sustainable life cycle and energy management of discrete manufacturing plants in the industry 4.0 framework},
journal = {Applied Energy},
volume = {312},
pages = {118671},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.118671},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922001374},
author = {Claudio Favi and Marco Marconi and Marco Mandolini and Michele Germani},
keywords = {Energy/material flows, Sustainable manufacturing, Plant metabolism, Manufacturing plant, Life cycle assessment, Industry 4.0},
abstract = {Industry 4.0 (I4.0), through the digitalization and interconnection of manufacturing processes, can offer opportunities to improve production systems' sustainability. Despite the increasing number of scientific review papers related to I4.0 and production sustainability, most approaches and tools for sustainability evaluation lack of a tangible implementation framework. The paper presents a framework that originated from the plant metabolism concept, a simplified version of industrial metabolism. It is based on Energy Material Flow Analysis (EMFA) and Life Cycle Assessment (LCA) tools for production plants' economic and sustainability assessment, using the I4.0 enabling technologies. A Multi-Criteria Decision Making (MCDM) method combines the two sustainability pillars for aiding companies in optimizing their production processes towards a reduction of energy/material flows. The combination of EMFA, LCA and MCDM tools into a plant metabolism-based model is the main novelty of this paper. The framework consists of three main phases. The first phase allows to model the manufacturing system by defining the plant layout, the assets, and the input/output flows. The second phase allows gathering information from the manufacturing plant to assess environmental and economic Key Performance Indicators (KPIs) following the LCA principles. The third phase consists of post-processing results, minimizing specific KPIs for establishing the optimal production scenario. A washing machine plant has been chosen as a case study to demonstrate the proposed method's capability in authentic contexts. Besides, the effectiveness in supporting companies in the analysis, identifying criticalities, and the proper energy and material flows management of production plants has been verified. Plant managers could use this framework for managing the production plans. From the scientific standpoint, the proposed method positively contributes to integrating the existing state of the art studies concerning the I4.0-related framework for the sustainability assessment and energy/material flows minimization of production systems.}
}
@article{HU2022103059,
title = {EGC: A novel event-oriented graph clustering framework for social media text},
journal = {Information Processing & Management},
volume = {59},
number = {6},
pages = {103059},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103059},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001625},
author = {Die Hu and Dan Feng and Yulai Xie},
keywords = {Text clustering, Semantic features, Graph representation, Data mining},
abstract = {With the popularity of social platforms such as Sina Weibo, Tweet, etc., a large number of public events spread rapidly on social networks and huge amount of textual data are generated along with the discussion of netizens. Social text clustering has become one of the most critical methods to help people find relevant information and provides quality data for subsequent timely public opinion analysis. Most existing neural clustering methods rely on manual labeling of training sets and take a long time in the learning process. Due to the explosiveness and the large-scale of social media data, it is a challenge for social text data clustering to satisfy the timeliness demand of users. This paper proposes a novel unsupervised event-oriented graph clustering framework (EGC), which can achieve efficient clustering performance on large-scale datasets with less time overhead and does not require any labeled data. Specifically, EGC first mines the potential relations existing in social text data and transforms the textual data of social media into an event-oriented graph by taking advantage of graph structure for complex relations representation. Secondly, EGC uses a keyword-based local importance method to accurately measure the weights of relations in event-oriented graph. Finally, a bidirectional depth-first clustering algorithm based on the interrelations is proposed to cluster the nodes in event-oriented graph. By projecting the relations of the graph into a smaller domain, EGC achieves fast convergence. The experimental results show that the clustering performance of EGC on the Weibo dataset reaches 0.926 (NMI), 0.926 (AMI), 0.866 (ARI), which are 13%–30% higher than other clustering methods. In addition, the average query time of EGC clustered data is 16.7ms, which is 90% less than the original data.}
}
@article{ALSHAHRANI2022101617,
title = {An attention-based view of AI assimilation in public sector organizations: The case of Saudi Arabia},
journal = {Government Information Quarterly},
volume = {39},
number = {4},
pages = {101617},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101617},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000538},
author = {Albandari Alshahrani and Denis Dennehy and Matti Mäntymäki},
keywords = {Artificial intelligence, Decision making, Attention-based view, Public sector},
abstract = {Artificial Intelligence (AI) has been suggested to have transformative potential for public sector organizations through enabling increased productivity and novel ways to deliver public services. In order to materialize the transformative potential of AI, public sector organizations need to successfully assimilate AI in their operational activities. However, AI assimilation in the public sector appears to be fragmented and lagging the private sector, and the phenomena has really limited attention from academic research community. To address this gap, we adopt the case study approach to explore three Saudi-Arabian public sector organizations and analyze the results using the attention-based view of the organization (ABV) as the theoretical lens. This study elucidates the challenges related AI assimilation in public sector in terms of how organizational attention is focused situated and distributed during the assimilation process. Five key challenges emerged from the cases studied, namely (i) misalignment between AI and management decision-making, (ii) tensions with linguistics and national culture, (iii) developing and implementing AI infrastructure, (iv) data integrity and sharing, and (v) ethical and governance concerns. The findings reveal a re-enforcing relationship between the situated attention and structural distribution of attention that can accelerate the successful assimilation of AI in public sector organizations.}
}
@article{FOUNTAIN2022101645,
title = {The moon, the ghetto and artificial intelligence: Reducing systemic racism in computational algorithms},
journal = {Government Information Quarterly},
volume = {39},
number = {2},
pages = {101645},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101645},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000812},
author = {Jane E. Fountain},
keywords = {Digital government, Public management, Systemic racism, Discrimination, Artificial intelligence, Machine learning, Computational algorithms},
abstract = {Computational algorithms and automated decision making systems that include them offer potential to improve public policy and organizations. But computational algorithms based on biased data encode those biases into algorithms, models and their outputs. Systemic racism is institutionalized bias with respect to race, ethnicity and related attributes. Such bias is located in data that encode the results and outputs of decisions that have been discriminatory, in procedures and processes that may intentionally or unintentionally disadvantage people based on race, and in policies that may discriminate by race. Computational algorithms may exacerbate systemic racism if they are not designed, developed, and used–that is, enacted–with attention to identifying and remedying bias specific to race. Advancing social equity in digital governance requires systematic, ongoing efforts to assure that automated decision making systems, and their enactment in complex public organizational arrangements, are free from bias.}
}
@article{LI2022301,
title = {Artificial Intelligence and Mechanical Circulatory Support},
journal = {Heart Failure Clinics},
volume = {18},
number = {2},
pages = {301-309},
year = {2022},
note = {Digital Health},
issn = {1551-7136},
doi = {https://doi.org/10.1016/j.hfc.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1551713621001148},
author = {Song Li and Gavin W. Hickey and Matthew M. Lander and Manreet K. Kanwar},
keywords = {Artificial intelligence, Machine learning, Mechanical circulatory support, Heart failure}
}
@article{ARNDT2022118168,
title = {Making waves: Time for chemical surface water quality monitoring to catch up with its technical potential},
journal = {Water Research},
volume = {213},
pages = {118168},
year = {2022},
issn = {0043-1354},
doi = {https://doi.org/10.1016/j.watres.2022.118168},
url = {https://www.sciencedirect.com/science/article/pii/S0043135422001312},
author = {Julia Arndt and Julia S. Kirchner and Kevin S. Jewell and Michael P. Schluesener and Arne Wick and Thomas A. Ternes and Lars Duester},
keywords = {Surface water monitoring, Automated data processing, Online analysis, Real-time, Citizen science},
abstract = {A comprehensive real-time evaluation of the chemical status of surface water bodies is still utopian, but in our opinion, it is time to use the momentum delivered by recent advanced technical, infrastructural, and societal developments to get significantly closer. Procedures like inline and online analysis (in situ or in a bypass) with close to real-time analysis and data provision are already available in several industrial sectors. In contrast, atline and offline analysis involving manual sampling and time-decoupled analysis in the laboratory is still common practice in aqueous environmental monitoring. Automated tools for data analysis, verification, and evaluation are changing significantly, becoming more powerful with increasing degrees of automation and the introduction of self-learning systems. In addition, the amount of available data will most likely in near future be increased by societal awareness for water quality and by citizen science. In this analysis, we highlight the significant potential of surface water monitoring techniques, showcase “lighthouse” projects from different sectors, and pin-point gaps we must overcome to strike a path to the future of chemical monitoring of inland surface waters.}
}
@article{TOLIOPOULOS202259,
title = {Sboing4Real: A real-time crowdsensing-based traffic management system},
journal = {Journal of Parallel and Distributed Computing},
volume = {162},
pages = {59-75},
year = {2022},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2022.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0743731522000193},
author = {Theodoros Toliopoulos and Nikodimos Nikolaidis and Anna-Valentini Michailidou and Andreas Seitaridis and Theodoros Nestoridis and Chrysa Oikonomou and Anastasios Temperekidis and Fotios Gioulekas and Anastasios Gounaris and Nick Bassiliades and Panagiotis Katsaros and Apostolos Georgiadis and Fotis K. Liotopoulos},
keywords = {Vehicle traffic monitoring, IoT, Stream processing, Massive parallelism, OLAP},
abstract = {This work describes the architecture of the back-end engine of a real-time traffic data processing and satellite navigation system. The role of the engine is to process real-time feedback, such as speed and travel time, provided by in-vehicle devices and derive real-time reports and traffic predictions through leveraging historical data as well. We present the main building blocks and the versatile set of data sources and processing platforms that need to be combined together to form a fully-functional and scalable solution. We also present performance results focusing on meeting system requirements while keeping the need for computing resources low. The lessons and results presented are of value to additional real-time applications that rely on both recent and historical data. Finally, we discuss the application of the aforementioned solution to a successful pilot study, where the full system was deployed and processed data from 800 taxis for a period of 3 months.}
}
@article{HE2022399,
title = {Using a linear regression approach to sequential interindustry model for time-lagged economic impact analysis},
journal = {Structural Change and Economic Dynamics},
volume = {62},
pages = {399-406},
year = {2022},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2022.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X22000522},
author = {Kehan He and Zhifu Mi and D'Maris Coffman and Dabo Guan},
keywords = {Input-Output analysis, Sequential Interindustry model, Economic system modelling, Time series, Impact analysis},
abstract = {The input-output (IO) model is a powerful economic tool with many extended applications. However, one of the widely criticized drawbacks is its rather lengthy time lag in data preparation, making it impossible to apply IO in high-resolution time-series analysis. The conventional IO model is thus unfortunately unsuited for time-series analysis. In this study, we present an innovative algorithm that integrates linear regression techniques into a derivative of the IO method, the Sequential Interindustry Model (SIM), to overcome the inherent shortcomings of statistical lags in conventional IO studies. The regressed relationship can thus be used to predict, in the short term, the accumulated chronological impacts induced by fluctuations in sectorial economic demands under disequilibrium conditions. A simulated calculation is presented to serve as an illustration and verification of the new method. In the future, this application can be extended beyond economic studies to broader problems of system analysis.}
}
@article{KHAN2022107735,
title = {A Temperature-Aware Trusted Routing Scheme for Sensor Networks: Security Approach},
journal = {Computers & Electrical Engineering},
volume = {98},
pages = {107735},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107735},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622000477},
author = {Tayyab Khan and Karan Singh and Manisha Manjul and Mohammad Nazir Ahmad and Azlan Mohd Zain and Ali Ahmadian},
keywords = {Trust establishment, routing, Security, deep learning, internal threats, communication trust, energy trust, data trust, network lifetime},
abstract = {ABSTRACT
This paper presents a hybrid trust model, and a multifactor, depending on trust value of sensor nodes, remaining energy, and hop count, routing strategy known as Temperature-Aware Trusted Routing Scheme (TTRS). In fact, it establishes the shortest and most trusted routing path. The multifactor strategy selects trustworthy nodes to forward data and reduce energy utilization due to secure shorter routing paths. TTRS incorporates an efficient multifactor hotspot node detection algorithm (HNDA) along with route discovery as well as route maintenance mechanism to detect malicious relay nodes for consistent data delivery in an unattended environment. Experimental results express the admirable average performance gain of TTRS in terms of accurate trust evaluation, network lifetime, packet delivery rate, and average energy consumption per node, as compared to ATRP, EOSR, and SQEER. Consequently, TTRS is more accurate than the aforementioned competitive schemes under different loads in a hostile environment.}
}
@article{SHIROIWA202262,
title = {Developing a New Region-Specific Preference-Based Measure in East and Southeast Asia},
journal = {Value in Health Regional Issues},
volume = {32},
pages = {62-69},
year = {2022},
issn = {2212-1099},
doi = {https://doi.org/10.1016/j.vhri.2022.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212109922001339},
author = {Takeru Shiroiwa and Tatsunori Murata and Jeonghoon Ahn and Xue Li and Ryota Nakamura and Yot Teerawattananon and Zhao Kun and Asrul Akmal Shafie and Haidee Valverde and Hilton Lam and Kwong Ng and Mardiati Nadjib and Raoh-Fang Pwu and Ryan Rachmad Nugraha and Yong-Chen Chen and Takashi Fukuda},
keywords = {East and Southeast Asia, preference-based measure, qualitative study, quality-adjusted life years},
abstract = {Objectives
Almost all preference-based measures (PBMs) have been developed in Western countries, with none having been formulated in Asian countries. In this study, we construct a new generic PBM based on concept elicitation using interview surveys in East and Southeast Asian countries and qualitative analysis.
Methods
This cross-sectional study included 225 adults recruited from 9 East and Southeast Asian countries or regions (Indonesia, Japan, Korea, mainland China, Malaysia, the Philippines, Singapore, Taiwan, and Thailand). Trained interviewers conducted semistructured interviews with 25 participants from the general population of each country/region. Qualitative data were analyzed using a content analysis approach. The selection of items was determined based on interview surveys and team member discussions. The description of items was considered based on a detailed qualitative analysis of the interview survey.
Results
A new region-specific PBM—the Asia PBM 7 dimensions instrument—was designed. It reflects East and Southeast Asian values and comprises 7 items: pain, mental health, energy, mobility, work/school, interpersonal interactions, and burden to others.
Conclusions
The new region-specific instrument is one of the first PBMs developed in the context of non-Western countries. The Asia PBM 7 dimensions contains 7 items that address the core concepts of health-related quality of life that are deemed important based on East and Southeast Asian health concepts.}
}
@article{CZVETKO2022117,
title = {Data-driven business process management-based development of Industry 4.0 solutions},
journal = {CIRP Journal of Manufacturing Science and Technology},
volume = {36},
pages = {117-132},
year = {2022},
issn = {1755-5817},
doi = {https://doi.org/10.1016/j.cirpj.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1755581721001929},
author = {Tímea Czvetkó and Alex Kummer and Tamás Ruppert and János Abonyi},
keywords = {Business process management (BPM), Business process redesign (BPR), Industry 4.0 (I4.0), Digital technology, Discrete event simulation},
abstract = {Business process management (BPM) supports the management and transformation of organizational operations. This paper provides a structured guideline for improving data-based process development within the BPM life cycle. We show how Industry 4.0-induced tools and models can be integrated within the BPM life cycle to achieve more efficient process excellence and evidence-based decision-making. The paper demonstrates how standards of machine learning (CRISP-ML(Q)), BPM, and tools of design science research can support the redesign phases of Industry 4.0 development. The proposed methodology is carried out on an assembly company, where the proposed improvement steps are investigated by simulation and evaluated by relevant key performance indicators.}
}
@article{LIU2022118504,
title = {Uneven development of the lead industry leads to regional differences in blood lead levels of children},
journal = {Environmental Pollution},
volume = {293},
pages = {118504},
year = {2022},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.118504},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121020868},
author = {Yang Liu and Chengdong Xu and Feiyan Liu and Gexin Xiao and Shaoqi Zhou and Liming Huang and Ni Lin and Jianyi Li and Dong Chen and Qi Fu and Huijun Wang and Qingfeng Du},
keywords = {Blood lead levels, Lead industry, Regional inequality, Children's health, China},
abstract = {Children's exposure to lead is a global health problem, especially in low- and middle-income countries. However, research on the relationship between children's blood lead levels (BLLs) and the development of the lead industry is still limited. This study examined whether children's BLLs were associated with the development of lead industry in different regions. Using survey data on the BLLs of children living in 250 prefectures in China with corresponding data on their economic factors and lead industries, we explored the regional variation of children's BLLs using statistical methods. The results show that the level of economic development in leaded areas was associated with inequity in children's BLLs and met the environmental Kuznets hypothesis. In areas without lead industries, there was little correlation between the level of economic development and the BLLs of children and thus the environmental Kuznets hypothesis was not supported. Lead mines, lead smelting and chemical companies are major sources of blood lead in children living in leaded areas. This study demonstrated the success of control policies for lead-acid battery manufacturers in promoting the prevention and control of childhood lead poisoning in China. China should consciously support the improvement of children's BLLs in undeveloped areas with lead industries through national financing and policies to avoid the continuous effects of the regional inequality problem of high children's BLLs.}
}
@article{WANG2022109344,
title = {Smart contract-based caching and data transaction optimization in mobile edge computing},
journal = {Knowledge-Based Systems},
volume = {252},
pages = {109344},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109344},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006748},
author = {Ge Wang and Chunlin Li and Yong Huang and Xiangli Wang and Youlong Luo},
keywords = {Mobile edge computing, Blockchain, Smart contract, Data caching, Data transaction},
abstract = {The emergence of mobile edge computing can provide technical support for the development of Internet services and for coping with massive data traffic, thereby reducing network latency and ensuring efficient network operations and service delivery. However, the mobile edge computing environment is prone to data loss and privacy leakage, and data security and reliability cannot be guaranteed. The application of blockchain technology ensures the stability and dependability of data caching and transactions. In order to guarantee the security of data caching in the mobile edge computing environment and minimize the response time of caching servers, this paper proposes a decentralized data caching strategy in the mobile edge computing environment. The strategy uses a greedy algorithm to make the transmission delay of the requested content as small as possible under the multiple constraints of the storage space of each server and whether the content is cached on the server. To address the problem that data trading platforms are unable to afford the computation and storage of massive amounts of data and cannot guarantee that the data will not be leaked, this paper proposes a secure decentralized data transaction program. The scheme promotes the increase of transaction turnover rate and improves the revenue of both participating parties by establishing a buyer–seller matching algorithm. According to the experimental results, the proposed data caching strategy can improve the cache hit rate and reduce the transmission delay; the proposed data transaction solution can increase the revenue of both the data holder and the data buyer.}
}
@article{SHARIF2022103542,
title = {Smart City Dimensions and Associated Risks: Review of literature},
journal = {Sustainable Cities and Society},
volume = {77},
pages = {103542},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103542},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008088},
author = {Reem Al Sharif and Shaligram Pokharel},
keywords = {Smart cities, Smart city dimensions, Technical risks, Non-technical risks, Risk parameters, Risk assessment tools},
abstract = {Countries have been working on implementing smart city concepts in different regions. The need for the use of information and communication technology in various forms is needed in such cities. There are different dimensions that are to be considered for smart city planning and implementation. This complexity of the dimension, the use of technology, and their integration bring the risk perspectives into the implementation of the smart city concept. If such risks are not adequately understood and addressed, they can create issues in terms of privacy and security and, therefore, the functioning of smart cities. In this review, the identification of dimensions, smart city assessment tools, the available technologies, and the technical and non-technical risk parameters related to smart cities implementation are discussed. The current methods of risk assessment and the possible enhancements are highlighted. The findings of the literature review illustrate that not all smart cities adapt all of the smart city dimensions. The dominant technology used in smart cities’ applications is found to be the Internet of Things, Artificial Intelligence, and blockchain. The paper also provides some research directions for the design, implementation, and operation of smart cities.}
}
@article{XIAO2022448,
title = {Modeling and application of marketing and distribution data based on graph computing},
journal = {Global Energy Interconnection},
volume = {5},
number = {4},
pages = {448-460},
year = {2022},
issn = {2096-5117},
doi = {https://doi.org/10.1016/j.gloei.2022.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S2096511722000834},
author = {Kai Xiao and Daoxing Li and Xiaohui Wang and Pengtian Guo},
keywords = {Marketing and distribution connection, Graph data, Graph computing, Knowledge graph, Data model},
abstract = {Integrating marketing and distribution businesses is crucial for improving the coordination of equipment and the efficient management of multi-energy systems. New energy sources are continuously being connected to distribution grids; this, however, increases the complexity of the information structure of marketing and distribution businesses. The existing unified data model and the coordinated application of marketing and distribution suffer from various drawbacks. As a solution, this paper presents a data model of “one graph of marketing and distribution” and a framework for graph computing, by analyzing the current trends of business and data in the marketing and distribution fields and using graph data theory. Specifically, this work aims to determine the correlation between distribution transformers and marketing users, which is crucial for elucidating the connection between marketing and distribution. In this manner, a novel identification algorithm is proposed based on the collected data for marketing and distribution. Lastly, a forecasting application is developed based on the proposed algorithm to realize the coordinated prediction and consumption of distributed photovoltaic power generation and distribution loads. Furthermore, an operation and maintenance (O&M) knowledge graph reasoning application is developed to improve the intelligent O&M ability of marketing and distribution equipment.}
}
@article{SONG2022110360,
title = {Evaluation of hydraulic fracturing effect on coalbed methane reservoir based on deep learning method considering physical constraints},
journal = {Journal of Petroleum Science and Engineering},
volume = {212},
pages = {110360},
year = {2022},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2022.110360},
url = {https://www.sciencedirect.com/science/article/pii/S0920410522002479},
author = {Hongqing Song and Shuyi Du and Jiaosheng Yang and Yang Zhao and Mingxu Yu},
keywords = {Coalbed methane reservoir, Hydraulic fracturing effect, Machine learning, Deep neural network with physical constraints, Crack half-length},
abstract = {Data-driven deep learning algorithms have shown good performance in the field of petroleum industry. However, some research has begun to be keen to incorporate physical laws into machine learning algorithms, so as to establish a “data + physical laws” dual-drive model, which can more effectively guide deep learning. In this study, reservoir geology, hydraulic fracturing, and dynamic production data were considered to establish a fracturing effect evaluation model for coalbed methane reservoirs. The combined network is designed to fully excavate the characteristics of dynamic and static data and solve the problem that the network ignores static data due to excessive dimensions of dynamic data. Furthermore, a neural network considering physical constraints was developed to better evaluate the fracturing effect by incorporating the initial conditions and expert experiences into the loss function. The deep learning-based fracturing effect evaluation model not only fits data-driven methods including reservoir geology, hydraulic fracturing and dynamic production data, but also adheres to the guidance of physical constraints. The experimental results show that compared with the conventional machine learning methods, the fracturing effect evaluation model has better performance on the prediction of crack half-length and permeability after fracturing due to combined network and physical constraints, with the overall RMSE of 6.11 m and 0.533mD respectively. In addition, through the analysis of influencing factors, it can be obtained that reservoir geology and hydraulic fracturing parameters can contribute more than 90% to the prediction of fracture half-length. Moreover, reservoir geology, hydraulic fracturing and dynamic data all play an important role in the permeability after fracturing, among which dynamic data has the highest contribution rate, with more than 40%.}
}
@article{HUANG2022111310,
title = {Image feature selection based on orthogonal ℓ2,0 norms},
journal = {Measurement},
volume = {199},
pages = {111310},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.111310},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122005504},
author = {Guan-Yu Huang and Chiao-Yun Hung and Bo-Wei Chen},
keywords = {Feature selection, Image classification,  norms, Orthogonal constraints},
abstract = {This study presents a feature selection method based on orthogonal ℓ2,0-norms to reduce dimensions, especially for images, where correlated and redundant information is frequently present by nature. Recent ℓ2,0-norm methods have shown a way of discovering sparsity, but redundant features could still be selected in the process. In light of such, this study considers imposing an orthogonal constraint on sparsity, further limiting ℓ2,0 norms. To such an end, projection onto Stiefel manifolds is computed to satisfy the orthogonal constraint while ℓ2,0-norm regularization is computed via ℓp-box zero-one programming. Experiments on open datasets were carried out to evaluate the proposed method and different models, including ℓ1-, ℓ2,1-, and ℓ2,0-norm approaches. The experimental results showed that the mean accuracy and F1 scores of the proposed method were higher than those of the ℓ2,0-norm method without orthogonal constraints and those of the other baselines, subsequently proving the effectiveness of the proposed idea.}
}
@article{DHIMAN2022,
title = {Application of UPIoT based power monitoring system},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2022.09.131},
url = {https://www.sciencedirect.com/science/article/pii/S2214785322059430},
author = {Amandeep Dhiman and Rehana Perveen},
keywords = {Equipment monitoring, Invasive power monitoring, Non-Invasive power monitoring, Ubiquitous power Internet of Things},
abstract = {Power monitoring through the Internet of Things (IoT) is growing in demand concerning to current trends like electric vehicles, and energy conservation. A system that can monitor this continuously changing demand and adapt itself according to the user requirements is called a smart system. This is only possible by monitoring continuous power output and controlling the gathered data for valuable information with the help of smart systems and IoT devices. This paper discusses the structure of Ubiquitous power Internet of Things (UPIoT) and power monitoring by using UPIoT. The monitoring of data is done by two methods, the first is non-invasive power monitoring and the second is invasive power monitoring. The proposed devices transmit real-time data to the thingspeak cloud by using the ESP8266 Wi-Fi module. The performance of both systems is analyzed by using an electric blower.}
}
@article{MASHALAH2022102837,
title = {The impact of digital transformation on supply chains through e-commerce: Literature review and a conceptual framework},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {165},
pages = {102837},
year = {2022},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2022.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1366554522002216},
author = {Heider Al Mashalah and Elkafi Hassini and Angappa Gunasekaran and Deepa {Bhatt (Mishra)}},
keywords = {Digital transformation, e-commerce, Network analysis, Supply chains, Systematic literature review},
abstract = {One of the profound impacts of digitalization on supply chains is manifested through e-commerce. The latter has significantly grown during the last two decades, with further amplifications during the COVID-19 pandemic. This has created operational and policy making challenges for firms when deciding about how best to manage the resulting growth in e-commerce. While the impact of e-commerce on supply chains has been widely recognized in the literature, there was no effort to systematically review the literature, conceptualize some of the challenges and propose future research directions. This paper fills this gap by reviewing 153 publications from 1999 to 2019. We classify the reviewed literature based on which supply chain drivers were investigated, as well as, the employed research methodology. In addition, we conduct network and content analysis to uncover the main research themes and potential research directions namely, developing analytical centred; modelling based ecosystem for environment; leveraging data mining to enhance sustainability; balance between growth and sustainability; consumer demand and uncertainty; coordination in e-commerce logistics; last mile alternatives and cost management of innovative technique implementations. Furthermore, based on our literature review, we propose a conceptual framework where we interlink supply chain stages with a firm’s business strategy, digital transformation strategy and performance.}
}
@article{KEITH2022100824,
title = {Deeper learning in electrocatalysis: realizing opportunities and addressing challenges},
journal = {Current Opinion in Chemical Engineering},
volume = {36},
pages = {100824},
year = {2022},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2022.100824},
url = {https://www.sciencedirect.com/science/article/pii/S221133982200034X},
author = {John A Keith and James R McKone and Joshua D Snyder and Maureen H Tang},
abstract = {Emerging techniques in deep learning have created exciting opportunities for next-generation electrochemical technologies. While deep learning has been revolutionizing many research fields, strategies for its implementation for electrocatalysis remain nascent. This Opinion calls on the electrocatalysis community to join together and introduce a paradigm shift by establishing standards for reporting and sharing data from electrocatalysis investigations. We speculate on a possible future where crowd-sourced and standardized data from experimental and computational researchers can be analyzed collectively to better understand fundamental electrochemistry, yielding unprecedented insights for the development of new electrocatalysts. We identify key barriers to realizing this opportunity and how they might be overcome.}
}
@article{KUMAR2022108455,
title = {Applications of the internet of things for optimizing warehousing and logistics operations: A systematic literature review and future research directions},
journal = {Computers & Industrial Engineering},
volume = {171},
pages = {108455},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108455},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222004892},
author = {Devinder Kumar and Rajesh {Kr Singh} and Ruchi Mishra and Samuel {Fosso Wamba}},
keywords = {IoT, Industry 4.0, Logistics and Warehousing, PRISMA approach, TMC framework, Systematic literature review},
abstract = {The introduction of Industry 4.0 technologies such as the Internet of Things (IoT), artificial intelligence (AI), cloud computing, and others has revolutionised the traditional warehousing and logistics industry, resulting in significant changes to various operations and decision-making. Despite the undeniable importance of this topic, the primary research on the impact of IoT technology is inconsistent and scattered. The present study aims to review state-of-art literature on the application of IoT technology in the warehousing and logistics field and suggests a path for the future research through an in-depth analysis of studies done in this area. Sixty-four research articles were carefully selected after a thorough search of the Scopus and EBSCO databases, covering the period from January 2011 to 07th December 2021, to examine the applications of the IoT in the warehousing and logistics business. These articles were thoroughly reviewed and classified in terms of year-wise distribution, major publication outlets, types of study, and highly cited papers to understand the evolution and ongoing trends in this field. The findings reveal that majority of the studies on IoT in the warehousing and logistics domain have been conducted in developed countries. While logistics has been widely investigated, studies on the warehousing domain are limited. Also, there is an under-presentation of various theories in IoT research. The study highlights various gaps by synthesising existing literature and provides a fertile ground for conducting future research in this domain. Supply chain practitioners and researchers will find this review timely and valuable, which offers several valuable implications for them.}
}
@article{UYSAL2022100382,
title = {Machine learning-enabled healthcare information systems in view of Industrial Information Integration Engineering},
journal = {Journal of Industrial Information Integration},
volume = {30},
pages = {100382},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2022.100382},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X22000504},
author = {Murat Pasa Uysal},
keywords = {Machine learning, Industrial Information Integration Engineering, Enterprise architecture, System architecture, Healthcare information system, Hospital Information System},
abstract = {Recent studies on Machine learning (ML) and its industrial applications report that ML-enabled systems may be at a high risk of failure or they can easily fall short of business objectives. Cutting-edge developments in this field have increased complexity and also brought new challenges for enterprise information integration. This situation can even get worse when considering the vital importance of ML-enabled healthcare information systems (HEIS). Therefore, the main argument of this paper is that we need to adopt the principles of Industrial Information Integration Engineering (IIIE) for the design, development, and deployment processes of ML-enabled systems. A mixed research paradigm is adopted, and therefore, this study is conducted by following the guidelines and principles of Action Research, Design Science Research, and IIIE. The contributions of this study are two-fold: (a) to draw researchers’ and practitioners’ attention to the integration problems of ML-enabled systems and discuss them in view of IIIE, and (b) to propose an enterprise integration architecture for ML-enabled HEIS of a university hospital, which is designed and developed by following the guidelines and principles of IIIE.}
}
@article{CHEN2022,
title = {Reflection on the equitable attribution of responsibility for artificial intelligence-assisted diagnosis and treatment decisions},
journal = {Intelligent Medicine},
year = {2022},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2667102622000353},
author = {Antian Chen and Chenyu Wang and Xinqing Zhang},
keywords = {Artificial intelligence, Diagnosis, Treatment, Ethics, Responsibility attribution},
abstract = {Artificial intelligence (AI) is developing rapidly and is being used in several medical capacities, including assisting in diagnosis and treatment decisions. As a result, this raises the conceptual and practical problem of how to distribute responsibility when AI-assisted diagnosis and treatment have been used and patients are harmed in the process. Regulations on this issue have not yet been established. It would be beneficial to tackle responsibility attribution prior to the development of biomedical AI technologies and ethical guidelines. In general, human doctors acting as superiors need to bear responsibility for their clinical decisions. However, human doctors should not bear responsibility for the behavior of an AI doctor that is practicing medicine independently. According to the degree of fault—which includes internal institutional ethics, the AI bidding process in procurement, and the medical process—clinical institutions are required to bear corresponding responsibility. AI manufacturers are responsible for creating accurate algorithms, network security, and insuring patient privacy protection. However, the AI itself should not be subjected to legal evaluation since there is no need for it to bear responsibility. Corresponding responsibility should be borne by the employer, in this case the medical institution.}
}
@article{YANG2022421,
title = {Worldwide validation of an Earth Polychromatic Imaging Camera (EPIC) derived radiation product and comparison with recent reanalyses},
journal = {Solar Energy},
volume = {243},
pages = {421-430},
year = {2022},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X2200559X},
author = {Xiaoyi Yang and Jamie M. Bright and Christian A. Gueymard and Brendan Acord and Peng Wang},
keywords = {Deep-space remote sensing, Solar radiation, Solar resource assessment, EPIC DSCOVR, Validation},
abstract = {A very recent gridded product for the hourly global horizontal irradiance (GHI), derived from the measurements of the Earth Polychromatic Imaging Camera (EPIC) onboard the Deep Space Climate Observatory (DSCOVR) launched by a NOAA/NASA/USAF consortium, is validated at 31 locations worldwide, from January, 2017 to June, 2019. In contrast to those traditional methods that leverage (simplified) radiative transfer, this EPIC-derived product uses machine learning – a random forest model – to map out the connection between satellite-observed variables of various kinds and GHI. Nonetheless, the detailed validation conducted here shows that the quality of this EPIC-derived GHI dataset not only does not outperform those traditional gridded solar radiation datasets, but also contains undesirable artifacts that can be possibly attributed to inadequacies in the machine-learning procedure. For these reasons, it is not recommended to use this EPIC-derived dataset in its current form for solar resource assessment purposes.}
}
@article{YANG2022102590,
title = {Identifying intercity freight trip ends of heavy trucks from GPS data},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {157},
pages = {102590},
year = {2022},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2021.102590},
url = {https://www.sciencedirect.com/science/article/pii/S1366554521003458},
author = {Yitao Yang and Bin Jia and Xiao-Yong Yan and Jiangtao Li and Zhenzhen Yang and Ziyou Gao},
keywords = {Intercity freight trip ends, Heavy truck, GPS data, Time threshold method, Spatiotemporal characteristics},
abstract = {The intercity freight trips of heavy trucks are basic data for transportation system planning and management. In recent decades, extracting intercity freight trips from GPS data has gradually become the main alternative to traditional surveys. Identifying freight trip ends (origin and destination) is the first task in trip extraction. Although many trip end identification methods have been proposed in previous studies, most of these studies subjectively determined key parameters and ignored the complex characteristics of truck trajectory and freight activities. In this paper, we propose a data-driven trip end identification method based on massive GPS data of heavy trucks in China. First, we capture heavy truck trajectory characteristics under the influence of GPS drift to identify truck stops from GPS data. Second, we analyze the temporal characteristics of truck activities and use freight-related point-of-interest (POI) data and highway network GIS data to identify valid trip ends from truck stops. The results of method validation suggest that the accuracy of our proposed method is significantly improved in comparison with the benchmark methods. We further extract intercity freight trips from the identified trip ends and analyze the spatiotemporal characteristics of intercity freight trips in China.}
}
@article{DUAN2022336,
title = {Fed-DR-Filter: Using global data representation to reduce the impact of noisy labels on the performance of federated learning},
journal = {Future Generation Computer Systems},
volume = {137},
pages = {336-348},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002412},
author = {Shaoming Duan and Chuanyi Liu and Zhengsheng Cao and Xiaopeng Jin and Peiyi Han},
keywords = {Federated learning, Label noise, Data filtering, Deep learning, Local differential privacy, Privacy-preserving data representation},
abstract = {The label noise is a serious problem limiting the performance of federated learning. According to the performance evaluation for the trained federated models, data selection strategies or client selection strategies are used to solve this problem in previous studies. However, these methods require additional clean data to strengthen the election results, and they rely heavily on an initial model that is robust enough to not accumulate errors. To address these problems, we propose a novel data filtering method to deal with label noise in federated learning, which is called Fed-DR-Filter. Unlike previous methods, Fed-DR-filter focuses on identifying clean data by taking advantage of the correlation of the global data representations. The proposed solution transforms the private data into privacy-preserving data representations in each client, and identifies clean data based on the centralized data representations on the server. To evaluate the performance of Fed-DR-Filter, we conduct extensive experiments on three real-world datasets. The evaluation results show that our method outperforms the state-of-the-art approaches and is robust to various data distributions and noise levels.}
}
@article{CAO2022103558,
title = {An analytical model for quantifying the efficiency of traffic-data collection using instrumented vehicles},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {136},
pages = {103558},
year = {2022},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2022.103558},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X22000079},
author = {Peng Cao and Zhiqiang Xiong and Xiaobo Liu},
keywords = {Instrumented vehicles, Data collection, Efficiency, Stochastic geometry theory},
abstract = {Emerging instrumented vehicles (IVs), when equipped with high-precision positioning devices (e.g., DGPS) and ranging sensors (e.g., radar, LIDAR, cameras), are capable of generating high-quality traffic data. This study evaluates the efficiency of such data-collection procedures; this remains largely unknown because variable penetration rates of IVs rarely arise in the real world. We propose an analytical model that establishes a quantitative relationship between the ratio of collected trajectory points to total traffic trajectory points (RCT) and the IV penetration rate, according to stochastic geometry theory. With this, the data-collection efficiency (DCE) of IVs can be effectively evaluated. A simulation approach is developed to generate IV data and thereby validate the proposed analytical model, using a comprehensive set of traffic scenarios; these data consist of eight micro-trajectory datasets from the next-generation simulation (NGSIM) program and four typical sensor IV deployments. The numerical analysis demonstrates that the model perfectly reflects the simulated IV data for all traffic scenarios. In addition, an analytical comparison of the DCEs for fixed sensors, probe vehicles, and IVs reveals that IVs are the most efficient method for collecting traffic data in road networks. This study proposes a theory to predict the percentage of trajectory points that can be collected by a certain percentage of IVs within the entire traffic flow.}
}
@article{BELLOMARINI2022407,
title = {Data science with Vadalog: Knowledge Graphs with machine learning and reasoning in practice},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {407-422},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004179},
author = {Luigi Bellomarini and Ruslan R. Fayzrakhmanov and Georg Gottlob and Andrey Kravchenko and Eleonora Laurenza and Yavor Nenov and Stéphane Reissfelder and Emanuel Sallinger and Evgeny Sherkhonov and Sahar Vahdati and Lianlong Wu},
keywords = {Knowledge Graphs, Data science, Machine learning, Reasoning, Probabilistic reasoning},
abstract = {Following the recent successful examples of large technology companies, many modern enterprises seek to build Knowledge Graphs to provide a unified view of corporate knowledge, and to draw deep insights using machine learning and logical reasoning. There is currently a perceived disconnect between the traditional approaches for data science, typically based on machine learning and statistical modeling, and systems for reasoning with domain knowledge. In this paper, we demonstrate how to perform a broad spectrum of data science tasks in a unified Knowledge Graph environment. This includes data wrangling, complex logical and probabilistic reasoning, and machine learning. We base our work on the state-of-the-art Knowledge Graph Management System Vadalog, which delivers highly expressive and efficient logical reasoning and provides seamless integration with modern data science toolkits such as the Jupyter platform. We argue that this is a significant step forward towards practical, holistic data science workflows that combine machine learning and reasoning in data science.}
}
@article{LI2022101821,
title = {Deep learning method for Chinese multisource point of interest matching},
journal = {Computers, Environment and Urban Systems},
volume = {96},
pages = {101821},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101821},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000655},
author = {Pengpeng Li and Jiping Liu and An Luo and Yong Wang and Jun Zhu and Shenghua Xu},
keywords = {Multisource POI, Deep learning, Word2vec, Text-CNN, MLP, ESIM},
abstract = {Multisource point of interest (POI) matching refers to the pairing of POIs that refer to the same geographic entity in different data sources. This also constitutes the core issue in geospatial data fusion and update. The existing methods cannot effectively capture the complex semantic information from a text, and the manually defined rules largely affect matching results. This study developed a multisource POI matching method based on deep learning that transforms the POI pair matching problem into a binary classification problem. First, we used three different Chinese word segmentation methods to segment the POI text attributes and used the segmentation results to train the Word2Vec model to generate the corresponding word vector representation. Then, we used the text convolutional neural network (Text-CNN) and multilayer perceptron (MLP) to extract the POI attributes' features and generate the corresponding feature vector representation. Finally, we used the enhanced sequential inference model (ESIM) to perform local inference and inference combination on each attribute to realize the classification of POI pairs. We used the POI dataset containing Baidu Map, Tencent Map, and Gaode Map from Chengdu to train, verify, and test the model. The experimental results show that the matching precision, recall rate, and F1 score of the proposed method exceed 98% on the test set, and it is significantly better than the existing matching methods.}
}
@article{CHEN2022132617,
title = {Green financial risk management based on intelligence service},
journal = {Journal of Cleaner Production},
volume = {364},
pages = {132617},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.132617},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622022168},
author = {Haibei Chen and Xianglian Zhao},
keywords = {Green finance, Financial risk, Risk management, Intelligence service},
abstract = {Risk management is an important issue of green finance, and it is also a prominent issue of green economic development. The resolution of green financial risk will help protect the interests of all stakeholders and promote the development of green finance. This study suggests that intelligence service provides new ideas and ways for green financial risk management. Applying intelligence service to green financial risk management will contribute to the sustainable development of green finance and enrich the theoretical system of intelligence science. This study first builds an intelligence service system of green financial risk management from five aspects: intelligence demand, intelligence collection, intelligence processing, intelligence application, and intelligence tracking. A questionnaire is designed based on this system. The first batch of green finance pilot cities in China (Ganjiang, Gui'an, Guangzhou, Huzhou, Quzhou, Changji, Hami, and Karamay) are investigated. This study uses a regression model to analyze the data and analyzes the intelligence service status of green financial risk management in pilot cities. The research divides those green finance pilot cities into eastern, central, and western regions. It shows obvious differences in the intelligence service elements in the eastern, central, and western regions of green financial risk management. The eastern region pays more attention to the three elements of intelligence demand, intelligence application, and intelligence tracking when carrying out green financial risk management. In the process of green financial risk management in the western region, there are obvious deficiencies in the two elements of intelligence collection and intelligence processing, which may be due to the lack of advanced digital equipment and effective digital resource. The central region lies between the eastern and western regions on intelligence service of green financial risk management. Based on the above results, this study proposes that establishing an intelligence center, sharing intelligence resources, improving digital technology, and updating intelligence cases can enhance the effectiveness of intelligence service in the risk management of green finance.}
}
@article{SHADBOLT2022100612,
title = {The challenges of data in future pandemics},
journal = {Epidemics},
volume = {40},
pages = {100612},
year = {2022},
issn = {1755-4365},
doi = {https://doi.org/10.1016/j.epidem.2022.100612},
url = {https://www.sciencedirect.com/science/article/pii/S1755436522000548},
author = {Nigel Shadbolt and Alys Brett and Min Chen and Glenn Marion and Iain J. McKendrick and Jasmina Panovska-Griffiths and Lorenzo Pellis and Richard Reeve and Ben Swallow},
keywords = {Data and models, Data ecosystem, Data lifecycles, FAIR data, Pandemic preparedness, COVID-19},
abstract = {The use of data has been essential throughout the unfolding COVID-19 pandemic. We have needed it to populate our models, inform our understanding, and shape our responses to the disease. However, data has not always been easy to find and access, it has varied in quality and coverage, been difficult to reuse or repurpose. This paper reviews these and other challenges and recommends steps to develop a data ecosystem better able to deal with future pandemics by better supporting preparedness, prevention, detection and response.}
}
@article{BIARD202291,
title = {Reliability Assessment of an Electrical Network with Digital Twins},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {19},
pages = {91-96},
year = {2022},
note = {5th IFAC Workshop on Advanced Maintenance Engineering, Services and Technologies AMEST 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.09.189},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322014045},
author = {Gabrielle Biard and Georges Abdul-Nour},
keywords = {Digital Twin, Reliability, Complex systems, Electrical industry, Asset management},
abstract = {Assessing power systems’ reliability and condition is a difficult task. This is partly due to the complexity of the many interrelated components that compose these systems. As a result, traditional reliability assessment methods are inadequate. This raises the question of whether digital twins can be used to assess the reliability of power systems. The objective of this paper is to consolidate information on the use of digital twins in the electrical industry and demonstrate how they can be used to assess the reliability of such complex systems. To accomplish this, a literature review is conducted. Then a method for evaluating the reliability of a power system with DTs is proposed.}
}
@article{FRIEDERICH2022546,
title = {Process Mining for Dynamic Modeling of Smart Manufacturing Systems: Data Requirements},
journal = {Procedia CIRP},
volume = {107},
pages = {546-551},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122003079},
author = {Jonas Friederich and Giovanni Lugaresi and Sanja Lazarova-Molnar and Andrea Matta},
keywords = {Model generation, discrete event simulation, process mining, machine behavior, reliability models},
abstract = {Modern manufacturing systems can benefit from the use of digital tools to support both short- and long-term decisions. Meanwhile, such systems reached a high level of complexity and are frequently subject to modifications that can quickly make the digital tools obsolete. In this context, the ability to dynamically generate models of production systems is essential to guarantee their exploitation on the shop-floors as decision-support systems. The literature offers approaches for generating digital models based on real-time data streams. These models can represent a system more precisely at any point in time, as they are continuously updated based on the data. However, most approaches consider only isolated aspects of systems (e.g., reliability models) and focus on a specific modeling purpose (e.g., material flow identification). The research challenge is therefore to develop a novel framework that systematically enables the combination of models extracted through different process mining algorithms. To tackle this challenge, it is critical to define the requirements that enable the emergence of automated modeling and simulation tasks. In this paper, we therefore derive and define data requirements for the models that need to be extracted. We include aspects such as the structure of the manufacturing system and the behavior of its machines. The paper aims at guiding practitioners in designing coherent data structures to enable the coupling of model generation techniques within the digital support system of manufacturing companies.}
}
@article{HAJEK2022103709,
title = {Recent developments in smart city assessment: A bibliometric and content analysis-based literature review},
journal = {Cities},
volume = {126},
pages = {103709},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103709},
url = {https://www.sciencedirect.com/science/article/pii/S0264275122001482},
author = {Petr Hajek and Abdelrahman Youssef and Veronika Hajkova},
keywords = {Smart city, Assessment, Framework, Bibliometric analysis, Content analysis, Literature review},
abstract = {Cities around the world are increasingly competing to upgrade their infrastructure and smartness levels to attract talent, become more effective and sustainable. However, assessing the progress of smart cities is often challenging due to the lack of theoretical foundation and consensus on an assessment methodology. These contradictions can pose major constraints on the development of the smart city concept and its implementation in practice. This paper analyzes a set of 164 articles published between 2010 and 2020 that deal with smart city assessment. The present study aims to identify the most influential research and key research themes, and suggests future research directions in the field of smart city assessment. A bibliometric analysis is used to reveal the most influential articles and their associations. Furthermore, a content analysis is performed to explore recent developments in the field of smart city assessment in terms of research hotspots and research themes. The analysis reveals the existence of 11 research themes and their timelines. The most influential research addresses (1) multiple-criteria decision-based performance measurement frameworks, (2) data connectivity challenges, (3) composite indexes for smart sustainable cities, (4) holistic performance evaluations of smart cities, and (5) the characteristics of indicator sets. Based on these results, current advances in smart city assessment are discussed, and future research directions in this field are suggested.}
}
@article{DEBRAH2022108443,
title = {Green finance gap in green buildings: A scoping review and future research needs},
journal = {Building and Environment},
volume = {207},
pages = {108443},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108443},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321008398},
author = {Caleb Debrah and Albert Ping Chuen Chan and Amos Darko},
keywords = {Sustainability, Climate change, Green buildings, Green finance, Scoping review},
abstract = {Green buildings, although critical to climate change mitigation, have a huge investment deficit. Green finance provides a viable option for bridging the green buildings investment gap. Despite the benefits of green finance in green buildings (GF-in-GBs), limited attention has been paid to this research area. To provide an overview of and map the area for the first time, this study conducted a systematic scoping review. Systematic searches across the five databases of Scopus, the Web of Science, ScienceDirect, Google Scholar, and normal Google identified a total of 28 relevant studies, including both the grey and academic literature. Study selection and data charting were conducted independently by two reviewers using standardized forms, with disagreements resolved through discussions. General and methodological characteristics of GF-in-GBs research were mapped. Results indicated that this is a highly under-researched and under-invested area. Asia has so far however contributed most. Previous studies embraced a variety of research designs, but most were content or report analysis-based, with limited empirical work. Based on identified gaps this study suggested future research directions, including (1) green incentives for GF-in-GBs, (2) GF-in-GBs rating software, (3) AI-enabled GF-in-GBs performance assessment software, and (4) intelligent GF-in-GBs cost-benefit analysis framework. The findings of this study provide an understanding of the status quo and future needs of GF-in-GBs, which would help researchers, policymakers, and practitioners improve and promote the implementation of green finance for promoting green buildings to combat climate change.}
}
@article{CHANG2022103587,
title = {Predicting aspect-based sentiment using deep learning and information visualization: The impact of COVID-19 on the airline industry},
journal = {Information & Management},
volume = {59},
number = {2},
pages = {103587},
year = {2022},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103587},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621001610},
author = {Yung-Chun Chang and Chih-Hao Ku and Duy-Duc Le Nguyen},
keywords = {Aspect-based Sentiment Analysis, Social Media Analysis, Natural Language Processing, Deep Learning, Information Visualization, Bidirectional Encoder Representations from Transformers},
abstract = {ABSTRACT
This study investigates customer satisfaction through aspect-level sentiment analysis and visual analytics. We collected and examined the flight reviews on TripAdvisor from January 2016 to August 2020 to gauge the impact of COVID-19 on passenger travel sentiment in several aspects. Till now, information systems, management, and tourism research have paid little attention to the use of deep learning and word embedding techniques, such as bidirectional encoder representations from transformers, especially for aspect-level sentiment analysis. This paper aims to identify perceived aspect-based sentiments and predict unrated sentiments for various categories to address this research gap. Ultimately, this study complements existing sentiment analysis methods and extends the use of data-driven and visual analytics approaches to better understand customer satisfaction in the airline industry and within the context of the COVID-19. Our proposed method outperforms baseline comparisons and therefore contributes to the theoretical and managerial literature.}
}
@article{HE2022104168,
title = {Integrated structural health monitoring in bridge engineering},
journal = {Automation in Construction},
volume = {136},
pages = {104168},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104168},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000413},
author = {Zhiguo He and Wentao Li and Hadi Salehi and Hao Zhang and Haiyi Zhou and Pengcheng Jiao},
keywords = {Structural health monitoring (SHM), Bridge engineering},
abstract = {Integrated structural health monitoring (SHM) uses the mechanism analysis, monitoring technology and data analytics to diagnose the classification, location and significance of structural situations (e.g., sudden or cumulative damages) to ensure the functionality and operation of bridges. Integrated SHM systems have improved the maintenance, management and decision-making of bridges by continuously monitoring and evaluating working conditions. This review article discusses the current process and future trends of bridge monitoring focusing on the cutting-edge SHM technologies, transmission and analytics methods of the sensing data, and prediction and early-warning models. In particular, four extensively applied sensing technologies (i.e., fiber optic sensors, piezoelectric sensors, global navigation satellite system and magnetostrictive sensors) are reviewed and compared, the wireless data transmission approaches (i.e., ZigBee, Bluetooth, NB-IoT, Wi-Fi, LoRa) are discussed, the artificial intelligence-based data processing methods are presented, and the performance prediction and early warning systems are summarized. In the end, the challenges and future research avenues of the current integrated SHM systems are discussed with respect to the characteristics of bridges.}
}
@article{LIU2022775,
title = {Risk Prediction of Digital Transformation of Manufacturing Supply Chain Based on Principal Component Analysis and Backpropagation Artificial Neural Network},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {1},
pages = {775-784},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821003707},
author = {Caihong Liu},
keywords = {Digital transformation, manufacturing supply chain (MSC), risk factor, backpropagation neural network (BPNN), principal component analysis (PCA)},
abstract = {Digital transformation of manufacturing is a hot topic among strategic managers of manufacturing companies. The crux of digital transformation lies in the digitalization of manufacturing supply chain (MSC). However, the digital transformation of the MSC is highly uncertain, owing to the dynamic and complex changes of its nodes and structure in response to growing customer demand and fierce market competition. To propel the MSC digital transformation, it is crucial to effectively identify and predict the risk factors in the course of digital transformation. Therefore, this paper attempts to help manufacturing companies in China to successfully switch to a digital MSC. Firstly, the risk sources of the MSC digitization were identified, and complied into an evaluation index system for the digital transformation of the MSC. Next, the principal component analysis (PCA) was performed to reduce the dimension of the original data by revealing the three key principal components, and then the characteristic parameters of risk prediction are selected, so as to simplify the structure of neural network and improve the speed and efficiency of network training. On this basis, a backpropagation neural network (BPNN) was constructed for predicting the risks in MSC digitization. The results of training the model based on some data show that the proposed BPNN model has a good predictive effect. Furthermore, our model was compared with the traditional artificial neural network (ANN) model on a test set. The comparison demonstrates that our model achieved better effect than the traditional model in risk prediction. The results also show that the selected three principal components are reasonable, and the evaluation index system is valuable. The research results provide new insights to the smooth digital transformation of the MSC.}
}
@article{SARKER2022100528,
title = {Smart City Data Science: Towards data-driven smart cities with open research issues},
journal = {Internet of Things},
volume = {19},
pages = {100528},
year = {2022},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2022.100528},
url = {https://www.sciencedirect.com/science/article/pii/S2542660522000300},
author = {Iqbal H. Sarker},
keywords = {Smart cities, Data science, Machine learning, Internet of Things, Data-driven decision making, Intelligent services, Cybersecurity},
abstract = {Cities are undergoing huge shifts in technology and operations in recent days, and ‘data science’ is driving the change in the current age of the Fourth Industrial Revolution (Industry 4.0 or 4IR). Extracting useful knowledge or actionable insights from city data and building a corresponding data-driven model is the key to making a city system automated and intelligent. Data science is typically the scientific study and analysis of actual happenings with historical data using a variety of scientific methodologies, machine learning techniques, processes, and systems. In this paper, we concentrate on and explore “Smart City Data Science”, where city data collected from various sources such as sensors, Internet-connected devices, or other external sources, is being mined for insights and hidden correlations to enhance decision-making processes and deliver better and more intelligent services to citizens. To achieve this goal, artificial intelligence, particularly, machine learning analytical modeling can be employed to provide deeper knowledge about city data, which makes the computing process more actionable and intelligent in various real-world city services. Finally, we identify and highlight ten open research issues for future development and research in the context of data-driven smart cities. Overall, we aim to provide an insight into smart city data science conceptualization on a broad scale, which can be used as a reference guide for the researchers, industry professionals, as well as policy-makers of a country, particularly, from the technological point of view.}
}
@article{SANI20221526,
title = {Strategies for Achieving Pre-emptive Resilience in Military Supply Chains},
journal = {Procedia CIRP},
volume = {107},
pages = {1526-1532},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.186},
url = {https://www.sciencedirect.com/science/article/pii/S221282712200470X},
author = {S. Sani and D. Schaefer and J. Milisavljevic-Syed},
keywords = {Military supply chain, Supply chain disruptions, Pre-emptive resilience, Simulation, Mathematical modelling, Decision support, Digital twin},
abstract = {As technological advancement is rapidly evolving modern warfare, military supply chains are becoming more dynamic and complex with high vulnerability to unexpected disruptions. To increase their overall resilience against such unexpected disruptions, traditional approaches are no longer sufficient. To date, research on supply chain resilience has mainly focused on reactive responses and recovery strategies (post-disruption). Hence, the research gap addressed in this paper is that of identifying new and proactive strategies to enable pre-emptive resilience in military supply chains (pre-disruption). In this paper, the authors first provide a critical review of the pertinent literature and research conducted over the past 12 years. Following on from there, they identify new research directions for enabling pre-emptive resilience to aid military logistic planners in monitoring supply chains and strategic decision-making to maintain their resilience.}
}
@article{YANG2022101800,
title = {Can digital financial inclusion promote female entrepreneurship? Evidence and mechanisms},
journal = {The North American Journal of Economics and Finance},
volume = {63},
pages = {101800},
year = {2022},
issn = {1062-9408},
doi = {https://doi.org/10.1016/j.najef.2022.101800},
url = {https://www.sciencedirect.com/science/article/pii/S106294082200136X},
author = {Xiaolan Yang and Yidong Huang and Mei Gao},
keywords = {Digital financial inclusion, Female entrepreneurship, CFPS},
abstract = {Female entrepreneurship is important for business and economic development. However, women face greater obstacles than men in accessing financing and information, making it more difficult for them to engage in entrepreneurship. This paper examines the impact of digital financial inclusion on female entrepreneurship by using a national sample consisting of matched data from a digital financial inclusion index and a nationally representative survey. The results show that digital financial inclusion significantly promotes women’s entrepreneurial behavior. We find that digital financial inclusion can ease women’s financing constraints and provide business information to alleviate their information constraints. Furthermore, the development of digital financial inclusion improves women’s work flexibility, inspiring them to engage in entrepreneurship. In addition, digital financial inclusion has a greater effect on entrepreneurship among vulnerable women, such as those with less education or a lack of financial autonomy and those living in areas with high gender inequality, which supports the idea that digital financial inclusion can empower women.}
}
@article{YALCIN2022121193,
title = {The use of multi-criteria decision-making methods in business analytics: A comprehensive literature review},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121193},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121193},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006260},
author = {Ahmet Selcuk Yalcin and Huseyin Selcuk Kilic and Dursun Delen},
keywords = {Business analytics, Decision support, Multi-criteria decision making (MCDM), Multi-attribute decision-making (MADM), Multi-objective decision-making (MODM)},
abstract = {Business analytics (BA) systems are considered significant investments for enterprises because they have the potential to considerably improve firms’ performance. With the value offered by BA, companies are able to discover the hidden information in the data, improve decision-making processes, and support strategic planning. On the other hand, because there are multiple criteria and multiple alternatives involved in most decision-making situations, multi-criteria decision-making (MCDM) methods play an important role in BA practices. Providing inputs to the components of descriptive or predictive analytics or being used as a decision-making tool for evaluating the alternatives within prescriptive analytics exemplify the roles. Therefore, the use of hidden information discovered by business analytics and the need for utilizing the right MCDM method for optimal decision-making made these two concepts inseparable. In this paper, in order to review the use of MCDM methods in BA, the subject of BA is investigated from a taxonomical perspective (descriptive, predictive, and prescriptive), and its connection with MCDM techniques is revealed. Similarly, MCDM methods are studied using two main categories, multi-attribute decision making (MADM) and multi-objective decision making (MODM) methods. Furthermore, tabular and graphical analyses are also performed within the proposed review methodology. To the best of our knowledge, this review is the first attempt that holistically considers the use of MCDM methods in BA.}
}
@article{MA2022105082,
title = {Knowledge graph construction and application in geosciences: A review},
journal = {Computers & Geosciences},
volume = {161},
pages = {105082},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2022.105082},
url = {https://www.sciencedirect.com/science/article/pii/S0098300422000450},
author = {Xiaogang Ma},
keywords = {Knowledge graph, Open data, Machine learning, Artificial intelligence, Data science},
abstract = {Knowledge graph (KG) is a topic of great interests to geoscientists as it can be deployed throughout the data life cycle in data-intensive geoscience studies. Nevertheless, comparing with the large amounts of publications on machine learning applications in geosciences, summaries and reviews of geoscience KGs are still limited. The aim of this paper is to present a comprehensive review of KG construction and implementation in geosciences. It consists of four major parts: 1) concepts relevant to KG and approaches for KG construction, 2) KG application in data collection, curation, and service, 3) KG application in data analysis, and 4) challenges and trends of geoscience KG creation and application in the near future. For each of the first three parts, a list of concepts, exemplar studies, and best practices are summarized. Those summaries are synthesized together in the challenge and trend analyses. As artificial intelligence and data science are thriving in geosciences, we hope this review of geoscience KGs can be of value to practitioners in data-intensive geoscience studies.}
}
@incollection{YANG2022,
title = {Building Energy Management Systems},
booktitle = {Reference Module in Earth Systems and Environmental Sciences},
publisher = {Elsevier},
year = {2022},
isbn = {978-0-12-409548-9},
doi = {https://doi.org/10.1016/B978-0-323-90386-8.00025-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323903868000255},
author = {Tong Yang and Derek Clements-Croome and Matthew Marson},
keywords = {Building automation, Energy management, Interoperability and adaptability, Sustainable design and operation, Technology and system integration},
abstract = {Building energy management systems (BEMS) are integrated building automation and energy management systems, utilizing IT or ICT, intelligent and interoperable digital communication technologies promoting a holistic approach to controls and providing adaptive operational optimization. The system may have multiple levels from individual sensors and actuators to users’ interface, to facilitate data collection, analysis, diagnose, trend finding, and decision-making. BEMS could provide flexible access to the building automation systems from several different platforms and locations. By using service-oriented abstractions to connect building, systems, and people, BEMS dynamically control indoor climate in a cost-effective manner and ensures the comfort, safety, and wellbeing of the occupants in buildings.}
}
@article{MEDIAVILLA20221126,
title = {Review and analysis of artificial intelligence methods for demand forecasting in supply chain management},
journal = {Procedia CIRP},
volume = {107},
pages = {1126-1131},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.119},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122004036},
author = {Mario Angos Mediavilla and Fabian Dietrich and Daniel Palm},
keywords = {Demand Forecasting, Supply Chain Management, Artificial Intelligence, Machine Learning, Deep Learning, Review, Analysis},
abstract = {The proper selection of a demand forecasting method is directly linked to the success of supply chain management (SCM). However, today’s manufacturing companies are confronted with uncertain and dynamic markets. Consequently, classical statistical methods are not always appropriate for accurate and reliable forecasting. Algorithms of Artificial intelligence (AI) are currently used to improve statistical methods. Existing literature only gives a very general overview of the AI methods used in combination with demand forecasting. This paper provides an analysis of the AI methods published in the last five years (2017-2021). Furthermore, a classification is presented by clustering the AI methods in order to define the trend of the methods applied. Finally, a classification of the different AI methods according to the dimensionality of data, volume of data, and time horizon of the forecast is presented. The goal is to support the selection of the appropriate AI method to optimize demand forecasting.}
}
@article{PERDANA2022100547,
title = {Data analytics in small and mid-size enterprises: Enablers and inhibitors for business value and firm performance},
journal = {International Journal of Accounting Information Systems},
volume = {44},
pages = {100547},
year = {2022},
issn = {1467-0895},
doi = {https://doi.org/10.1016/j.accinf.2021.100547},
url = {https://www.sciencedirect.com/science/article/pii/S146708952100049X},
author = {Arif Perdana and Hwee Hoon Lee and SzeKee Koh and Desi Arisandi},
keywords = {IT business value, Data analytics, Dual factor concept, Resource-based view, RBV, Small-and-midsize enterprises, SMEs, IT-enabled resources},
abstract = {A critical question arises as to whether data analytics (DA) can bring value and improve organizational performance. The benefit offered by DA can be achieved only when organizations are able to direct their attention on the conditioning factors that amplify business value. At the same time, organizations should cautiously resolve the issues that dampen DA business value. This study applied resource-based view (RBV) and the dual factor concept to understand such factors within the Small and Mid-size Enterprises (SMEs) context. The results revealed that information and systems qualities were the catalysts for data analytics business value, whereas lack of understanding and concerns over data security and privacy were the most salient predictors that could prevent SMEs from realizing DA business value. Our study highlights the importance of understanding both enablers and inhibitors in IT business value research. We also offer strategies to stakeholders to help SMEs realize DA business value.}
}
@article{LIU2022101847,
title = {Exploring the effect of urban spatial development pattern on carbon dioxide emissions in China: A socioeconomic density distribution approach based on remotely sensed nighttime light data},
journal = {Computers, Environment and Urban Systems},
volume = {96},
pages = {101847},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101847},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000916},
author = {Shirao Liu and Jingwei Shen and Guifen Liu and Yizhen Wu and Kaifang Shi},
keywords = {Urban spatial development pattern, Carbon dioxide emissions, Nighttime light data, NPP-VIIRS, Socioeconomic density distribution, China},
abstract = {Exploring the effect of urban spatial development pattern (UPD) on carbon dioxide emissions (CDEs) (EUC) is important for understanding low-carbon sustainable development. Numerous studies on EUC have mainly focused on individual cities or regions within the mixed conclusions due to the lack of reliable UPD indices and reasonable methods. Thus, taking China's 257 prefecture-level cities as experimental objects, a novel system approach was developed from the perspective of socioeconomic density distribution (SED) index to measure UPD on the basis of the Suomi National Polar-orbiting Partnership (NPP) visible infrared imaging radiometer suite (VIIRS) nighttime light data. EUC was then analyzed on the basis of the dynamic panel data model from multiple perspectives. Results show that the SED index can effectively measure UPD with rich spatial information from multiple dimensions. The coefficients of SED and (SED)2 are 0.129 and − 1.240, respectively, indicating that EUC shows a clear inverted U-shaped curve in China, i.e., an increase in UPD compactness increases CDEs at the beginning, and when a certain height is reached, an increase in UPD compactness decreases CDEs. Heterogeneity analysis indicates a U-shaped curve of EUC is found in megalopolis, and inverse U-shaped curve are observed in medium and small cities. Bus passenger volume, energy consumption, infrastructure, and housing demand are proven as the transmission factors of EUC. It is suggested that utilizing the positive externality effect of agglomeration and accelerating the inflection point of the inverse U-shaped curve may be necessary because the improvement of urban socioeconomic agglomeration will improve the UPD compactness and reduce CDEs.}
}
@article{LIANG2022115410,
title = {Assessing the validity of mobile device data for estimating visitor demographics and visitation patterns in Yellowstone National Park},
journal = {Journal of Environmental Management},
volume = {317},
pages = {115410},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.115410},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722009835},
author = {Yun Liang and Junjun Yin and Bing Pan and Michael S. Lin and Lauren Miller and B. Derrick Taff and Guangqing Chi},
keywords = {Mobile device data, Visitor demographics, Temporal visitation patterns, National park},
abstract = {Monitoring visitor demographics and temporal visitation patterns can help national park managers understand their visitors and allocate resources more effectively. Traditional approaches, such as visitor surveys or vehicle counts, are limited by time, space, labor, and financial resources. More recently, mobile device data have been adopted for monitoring visitors in park-related or tourism research. However, few studies validated mobile device data with traditional visitor surveys or count data. Combining mobile device data with the American Community Survey (ACS), this study assessed mobile device data's validity in a national park context with three approaches: Points of Interest (POIs), visitor demographics, and temporal visitation patterns. The results revealed that only half of the POIs inside Yellowstone National Park are valid. Compared to traditional visitor surveys, mobile device data are limited due to platform bias and the exclusion of international visitors, resulting in discrepancies in visitor demographics, such as education and income levels. Conversely, mobile device data have strong correlations with count data regarding monthly and daily visitation patterns. The results suggest that with careful consideration, mobile device data can serve as an additional and complementary source of information to traditional survey data for understanding visitor demographics and temporal visitation patterns.}
}
@article{GROVER2022103639,
title = {A theoretical perspective on organizational culture and digitalization},
journal = {Information & Management},
volume = {59},
number = {4},
pages = {103639},
year = {2022},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2022.103639},
url = {https://www.sciencedirect.com/science/article/pii/S0378720622000519},
author = {Varun Grover and Shih-Lun Tseng and Wenxi Pu},
keywords = {Organizational culture, Digitalization, Digital culture},
abstract = {Digitalization has fundamentally changed organizational structures and processes and affects how people interact with each other, thereby impacting organizational culture. Given the pervasiveness of digitalization today, it is useful to study its profound effects on organizational culture through new theoretical lenses. In this paper, we offer a fresh perspective on organizational culture in the digital world. We accomplish this by integrating two competing perspectives and then leveraging the new perspective to identify digital cultural resources and propose a conceptualization of digital culture. We frame our conceptualization around the cultural resources for digitalization and describe four digital culture archetypes.}
}
@article{TANG2022103833,
title = {Automatic number plate recognition (ANPR) in smart cities: A systematic review on technological advancements and application cases},
journal = {Cities},
volume = {129},
pages = {103833},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103833},
url = {https://www.sciencedirect.com/science/article/pii/S0264275122002724},
author = {Junqing Tang and Li Wan and Jennifer Schooling and Pengjun Zhao and Jun Chen and Shufen Wei},
keywords = {Automatic license plate recognition, Automatic number plate recognition, Automatic vehicle identification, Traffic sensing, Systematic literature review},
abstract = {Automatic Number Plate Recognition (ANPR) technology has been intensively engaged in managing the smartification and digitalization of cities in recent years as an effective tool for acquiring information about vehicle movements. As a traffic sensing technology, it has been popular across multiple scientific fields such as urban science, computer vision, and transportation management. However, we still lack a comprehensive review of this smart sensing technology, especially covering the current state and perspectives of how the technology can be leveraged in different aspects of urban management and what policy and social implications can be drawn from its application cases. In this paper, a systematic review of ANPR is delivered to discuss three aspects: the first aspect covers the technical advancements of ANPR technology; the second aspect focuses on analyzing the influential factors of its sensing performance in various contexts; the third aspect surveys the application cases of this technology and its practical implications from a user's perspective. Policy comparisons, emerging themes, and major underdeveloped areas are subsequently discussed and identified. Finally, four future ANPR research propositions in the smart city context are suggested with discussions of both theoretical and practical implications for scholars and practitioners.}
}
@article{YANG2022106417,
title = {Laser-induced breakdown spectroscopy combined with a convolutional neural network: A promising methodology for geochemical sample identification in Tianwen-1 Mars mission},
journal = {Spectrochimica Acta Part B: Atomic Spectroscopy},
volume = {192},
pages = {106417},
year = {2022},
issn = {0584-8547},
doi = {https://doi.org/10.1016/j.sab.2022.106417},
url = {https://www.sciencedirect.com/science/article/pii/S0584854722000611},
author = {Fan Yang and Lu-Ning Li and Wei-Ming Xu and Xiang-Feng Liu and Zhi-Cheng Cui and Liang-Chen Jia and Yang Liu and Jun-Hua Xu and Yu-Wei Chen and Xue-Sen Xu and Jian-Yu Wang and Hai Qi and Rong Shu},
keywords = {Laser-induced breakdown spectroscopy, Convolutional neural network, Sampling distance, Multi-distance spectra, MarSCoDe},
abstract = {As an in-situ and stand-off detection technique, laser-induced breakdown spectroscopy (LIBS) can perform efficient geochemical sample identification and classification with chemometrics, and therefore LIBS has played a shining role in planetary exploration missions. Unlike in laboratory experiments, the LIBS sampling distance in field detection for planetary exploration naturally varies. The considerable spectral differences caused by the varying distance can be a critical challenge for chemometrics model training and testing. In this research, we address this issue by focusing on the construction of a chemometrics model with powerful learning ability rather than the conventional spectral data processing for distance correction. Specifically, we have investigated the performance of a designed deep convolutional neural network (CNN) on datasets consisting of multi-distance spectra. More than 18,000 LIBS spectra were collected by a duplicate model of the MarSCoDe instrument for China's Tianwen-1 Mars mission, at eight different distances ranging from 2.0 m to 5.0 m. These spectra were acquired from 39 geochemical standard samples, which were classified by the deep CNN. The competence of the CNN is compared with that of four alternative chemometrics, i. e. back-propagation neural network, support vector machine, linear discriminant analysis, and logistic regression. The CNN can surpass the other four algorithms in terms of overall prediction accuracy. In addition, we have inspected the dependence of the CNN performance on the distance number involved in the training set and the data properties of the testing set. Furthermore, it has been revealed that the CNN model can behave even better if an extremely simple distance correction procedure is supplemented. Our results show that CNN is an extraordinary chemometrics for material classification on multi-distance spectra datasets, implying that CNN-LIBS is a promising methodology for geochemical sample identification/classification in Tianwen-1 mission and other future planetary exploration missions, and in even more field detection scenarios with varying sampling distance.}
}
@article{REN2022127709,
title = {Evaluating geographic and social inequity of urban parks in Shanghai through mobile phone-derived human activities},
journal = {Urban Forestry & Urban Greening},
volume = {76},
pages = {127709},
year = {2022},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2022.127709},
url = {https://www.sciencedirect.com/science/article/pii/S1618866722002527},
author = {Xiyuan Ren and ChengHe Guan},
keywords = {Geographic and social inequity, Urban park, Mobile phone data, Recreational activity, Low-recreation-demand population},
abstract = {The equity of urban park access has received great attention from studies on public service provision. However, individuals’ growing demands for recreational activities have brought diversity and complexity to park usages, drawing doubts on traditional measurements of park accessibility. To fill the gap, this study explores park equity issues with a dataset containing 12.03 million mobile phone users who accessed one of the 332 parks in Shanghai. We measured community-level park accessibility with two traditional place-based indicators – park area proportion and Gaussian-based 2SFCA accessibility, and three innovative activity-based indicators – park activity frequency, park activity trip length, and park activity duration. We then explored the geographic and social inequity by calculating Gini index and conducting correlation analysis. The results show that place-based and activity-based indicators presented citywide differences, indicating a significant impact of human activities on urban park accessibility. The geographic inequality of park distribution was undermined by people’s actual park usages. However, residents in communities with higher quality of built-environment had higher park activity frequency while shorter trip length, and social inequity of park access among the total population was more obvious than the low-recreation-demand population. Therefore, policy-makers should rethink how to provide park resources to address the inequity issues brought by human activities. Our study contributes to the existing literature in the following ways: (1) compared place-based park accessibility and activity-based park accessibility in the same context, and (2) identified low-recreation-demand population as a comparison group to explore impacts of recreation demand on park equity.}
}
@article{ABBASI2022100042,
title = {The digitization of agricultural industry – a systematic literature review on agriculture 4.0},
journal = {Smart Agricultural Technology},
volume = {2},
pages = {100042},
year = {2022},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2022.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2772375522000090},
author = {Rabiya Abbasi and Pablo Martinez and Rafiq Ahmad},
keywords = {Agriculture 4.0, Industry 4.0, Digitization, Connectivity, Internet of things, Smart agricultural systems},
abstract = {Agriculture is considered one of the most important sectors that play a strategic role in ensuring food security. However, with the increasing world's population, agri-food demands are growing — posing the need to switch from traditional agricultural methods to smart agriculture practices, also known as agriculture 4.0. To fully benefit from the potential of agriculture 4.0, it is significant to understand and address the problems and challenges associated with it. This study, therefore, aims to contribute to the development of agriculture 4.0 by investigating the emerging trends of digital technologies in the agricultural industry. For this purpose, a systematic literature review based on Protocol of Preferred Reporting Items for Systematic Reviews and Meta-Analyses is conducted to analyse the scientific literature related to crop farming published in the last decade. After applying the protocol, 148 papers were selected and the extent of digital technologies adoption in agriculture was examined in the context of service type, technology readiness level, and farm type. The results have shown that digital technologies such as autonomous robotic systems, internet of things, and machine learning are significantly explored and open-air farms are frequently considered in research studies (69%), contrary to indoor farms (31%). Moreover, it is observed that most use cases are still in the prototypical phase. Finally, potential roadblocks to the digitization of the agriculture sector were identified and classified at technical and socio-economic levels. This comprehensive review results in providing useful information on the current status of digital technologies in agriculture along with prospective future opportunities.}
}
@article{WUTTKE2022226,
title = {Synthetic Demand Generation with Seasonality for Data Mining on a Data-Farmed Data Basis of a Two-Echelon Supply Chain},
journal = {Procedia Computer Science},
volume = {204},
pages = {226-234},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922007657},
author = {Alexander Wuttke and Joachim Hunker and Anne Antonia Scheidler and Markus Rabe},
keywords = {Data Farming, Knowledge Discovery in Databases, Data Mining, Simulation, Supply Chains, Synthetic Demand, Demand Generator},
abstract = {A widely used method in the context of supply chain analytics and management is data mining. It is used to discover patterns in a supply chain's data basis. Besides preprocessing observational real-world data, simulation can be used to create a suitable data basis. This process is referred to as data farming and involves using a simulation model as a data generator. A common input to a simulation model of a supply chain is demand of stock keeping units that is likely to project to the model's behavior. When testing novel approaches or in planning stages, demand of real-world supply chains is not always available or viable to adept. In this case, synthetically created demand can be used. A general approach of realistic demand generation with seasonality by a demand generator in the context of data farming is presented and further exemplified on a data farming and data mining framework of a two-echelon supply chain.}
}
@article{ALWAN2022109384,
title = {Time-series clustering for sensor fault detection in large-scale Cyber-Physical Systems},
journal = {Computer Networks},
pages = {109384},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109384},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622004182},
author = {Ahmed A. Alwan and Allan J. Brimicombe and Mihaela Anca Ciupala and Seyed Ali Ghorashi and Andres Baravalle and Paolo Falcarin},
keywords = {Cyber-physical systems (CPSs), Wireless sensor networks(WSNs), Time-series clustering, Dynamic time warping, K-shape, Characteristics based time-series clustering},
abstract = {Large-scale Cyber-Physical Systems (CPSs) are information systems that involve a vast network of sensor nodes and other devices that stream observations in real-time and typically are deployed in uncontrolled, broad geographical terrains. Sensor node failures are inevitable and unpredictable events in large-scale CPSs, which compromise the integrity of the sensors measurements and potentially reduce the quality of CPSs services and raise serious concerns related to CPSs safety, reliability, performance, and security. While many studies were conducted to tackle the challenge of sensor nodes failure detection using domain-specific solutions, this paper proposes a novel sensor nodes failure detection approach and empirically evaluates its validity using a real-world case study. This paper investigates time-series clustering techniques as a feasible solution to identify sensor nodes malfunctions by detecting long-segmental outliers in their observations’ time series. Three different time-series clustering techniques have been investigated using real-world observations collected from two various sensor node networks, one of which consists of 275 temperature sensors distributed around London. This study demonstrates that time-series clustering effectively detects sensor node’s continuous (halting/repeating) and incipient faults. It also showed that the feature-based time series clustering technique is a more efficient long-segmental outliers detection mechanism compared to shape-based time-series clustering techniques such as DTW and K-Shape, mainly when applied to shorter time-series windows.}
}
@article{VARADHARAJAN2022105024,
title = {BASIN-3D: A brokering framework to integrate diverse environmental data},
journal = {Computers & Geosciences},
volume = {159},
pages = {105024},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.105024},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421003058},
author = {Charuleka Varadharajan and Valerie C. Hendrix and Danielle S. Christianson and Madison Burrus and Catherine Wong and Susan S. Hubbard and Deborah A. Agarwal},
keywords = {Data integration, Multiscale diverse data, Synthesis, Environmental data},
abstract = {Diverse observational and simulation datasets are needed to understand and predict complex ecosystem behavior over seasonal to decadal and century time-scales. Integration of these datasets poses a major barrier towards advancing environmental science, particularly due to differences in the structure and formats of data provided by various sources. Here, we describe BASIN-3D (Broker for Assimilation, Synthesis and Integration of eNvironmental Diverse, Distributed Datasets), a data integration framework designed to dynamically retrieve and transform heterogeneous data from different sources into a common format to provide an integrated view. BASIN-3D enables users to adopt a standardized approach for data retrieval and avoid customizations for the data type or source. We demonstrate the value of BASIN-3D with two use cases that require integration of data from regional to watershed spatial scales. The first application uses the BASIN-3D Python library to integrate time-series hydrological and meteorological data to provide standardized inputs to analytical and machine learning codes in order to predict the impacts of hydrological disturbances on large river corridors of the United States. The second application uses the BASIN-3D Django framework to integrate diverse time-series data in a mountainous watershed in East River, Colorado, United States to enable scientific researchers to explore and download data through an interactive web portal. Thus, BASIN-3D can be used to support data integration for both web-based tools, as well as data analytics using Python scripting and extensions like Jupyter notebooks. The framework is expected to be transferable to and useful for many other field and modeling studies.}
}
@article{SIRCAR2022,
title = {Digital twin in hydrocarbon industry},
journal = {Petroleum Research},
year = {2022},
issn = {2096-2495},
doi = {https://doi.org/10.1016/j.ptlrs.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2096249522000266},
author = {Anirbid Sircar and Abhishek Nair and Namrata Bist and Kriti Yadav},
keywords = {Digital twin technology, Hydrocarbon exploration, Industry 4.0, Oil and gas, Digitalization, Automation},
abstract = {The hydrocarbon industry is considering a range of digital technologies to improve productivity, efficiency, and safety of their operations while minimizing capital and operating costs, health and environmental risks, and variability in oil and gas project life cycles. Due to the emergence of industry 4.0 the improvement in performance, efficiency, and cost reduction, the hydrocarbon industry is gradually shifting towards solutions that are data-oriented. Understanding such complex systems involves the analysis of data from various sources at the same time. Digital Twin (DT) modelling is the foundation for the next generation of real-time production monitoring and optimization systems. It is a solution that boosts productivity by combining information, simulation, and visualization throughout the entire value chain of an operational firm, from subsurface equipment to central production plants. Oil and gas companies can majorly benefit from Hydrocarbon Exploration with the right use of such advanced technologies. This study focuses on the advancements in technology in the context of DT and how it has been used by the hydrocarbon industry. The study discusses about the emergence of the DT concept, various types, 5D representation, and tools for DT. Further, the study tries to implement fields of DT in hydrocarbon industry especially in the domains of exploration, drilling, and production. Challenges associated with DT strategy like accessibility, confidentiality integration, and maintenance are also discussed.}
}
@article{BATCHU2022104571,
title = {On improving the performance of DDoS attack detection system},
journal = {Microprocessors and Microsystems},
volume = {93},
pages = {104571},
year = {2022},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2022.104571},
url = {https://www.sciencedirect.com/science/article/pii/S0141933122001235},
author = {Raj Kumar Batchu and Hari Seetha},
keywords = {DDoS attacks, Data preprocessing, Feature selection, Extreme learning machine, CICDDoS-2019 dataset},
abstract = {A DDoS (Distributed Denial of Service) attack is a harmful way of preventing regular access to a targeted machine, resources, or any network by flooding the target or its neighbouring infrastructure with massive traffic in an attempt to cause an interruption. As a result, the network environment's security has suffered significantly. Although numerous ways have been proposed in previous studies, there is still room for new ones as attacker patterns, and strategies change rapidly. This work designs a quick and efficient detection model to identify the latest real-world attacks. An attempt was made for an effective data pre-processing that includes both memory optimization and hybrid feature selection to improve the model's generalizability. Furthermore, the extreme learning machine (ELM) classifier is analyzed with the extracted features by varying weight ranges, hidden neurons, and activation functions to classify the attacks. Experiments are conducted using the CICDDoS-2019 traffic data. The experimental outcomes indicate that the suggested model is superior to previous strategies, with a detection accuracy of 99.94%.}
}
@article{LIU2022100187,
title = {DIA-Based Proteomics Identifies IDH2 as a Targetable Regulator of Acquired Drug Resistance in Chronic Myeloid Leukemia},
journal = {Molecular & Cellular Proteomics},
volume = {21},
number = {2},
pages = {100187},
year = {2022},
issn = {1535-9476},
doi = {https://doi.org/10.1016/j.mcpro.2021.100187},
url = {https://www.sciencedirect.com/science/article/pii/S1535947621001596},
author = {Wei Liu and Yaoting Sun and Weigang Ge and Fangfei Zhang and Lin Gan and Yi Zhu and Tiannan Guo and Kexin Liu},
keywords = {drug resistance, DIA, imatinib, adriamycin, IDH2, Chronic Myeloid Leukemia},
abstract = {Drug resistance is a critical obstacle to effective treatment in patients with chronic myeloid leukemia. To understand the underlying resistance mechanisms in response to imatinib mesylate (IMA) and adriamycin (ADR), the parental K562 cells were treated with low doses of IMA or ADR for 2 months to generate derivative cells with mild, intermediate, and severe resistance to the drugs as defined by their increasing resistance index. PulseDIA-based (DIA [data-independent acquisition]) quantitative proteomics was then employed to reveal the proteome changes in these resistant cells. In total, 7082 proteins from 98,232 peptides were identified and quantified from the dataset using four DIA software tools including OpenSWATH, Spectronaut, DIA-NN, and EncyclopeDIA. Sirtuin signaling pathway was found to be significantly enriched in both ADR-resistant and IMA-resistant K562 cells. In particular, isocitrate dehydrogenase (NADP(+)) 2 was identified as a potential drug target correlated with the drug resistance phenotype, and its inhibition by the antagonist AGI-6780 reversed the acquired resistance in K562 cells to either ADR or IMA. Together, our study has implicated isocitrate dehydrogenase (NADP(+)) 2 as a potential target that can be therapeutically leveraged to alleviate the drug resistance in K562 cells when treated with IMA and ADR.}
}
@article{KINKEL2022102375,
title = {Prerequisites for the adoption of AI technologies in manufacturing – Evidence from a worldwide sample of manufacturing companies},
journal = {Technovation},
volume = {110},
pages = {102375},
year = {2022},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2021.102375},
url = {https://www.sciencedirect.com/science/article/pii/S0166497221001565},
author = {Steffen Kinkel and Marco Baumgartner and Enrica Cherubini},
keywords = {Artificial intelligence (AI), Machine learning (ML), Industry 4.0, Digital skills, Technology adoption, Technology-organization-environment framework},
abstract = {In current discussions, Artificial Intelligence (AI) is ascribed great influence on production processes. Research on AI has seen tremendous growth in recent years. However, most of the research has focused primarily on various AI technologies, and less on prerequisites and enablers for adoption of AI at firm-level. This is surprising, given the fact that many companies are still struggling to establish AI in their production and to drive their AI adoption forward. To close this gap, this study analyses the impact of various technological, organizational and environmental (TOE) prerequisites for a successful adoption of AI technologies in manufacturing. Based on a cross-national survey of 655 company representatives from the manufacturing industry, our results contribute to a better understanding of why some companies are more determined than others when it comes to implementing AI in their production. We find evidence that organizational factors, such as digital skills, company size, and R&D intensity, have the greatest impact on the adoption of AI in manufacturing. Furthermore, in order to gain new insights into the interplay of new technology adoption and global production strategies, this paper addresses the question of which factors explain a primarily domestic or globally oriented technology adoption. We find that especially research-intensive, knowledge-based and service-oriented companies tend to roll out AI technologies not only at their domestic but also at their foreign production sites.}
}
@article{LI2022102803,
title = {Assessing personal travel exposure to on-road PM2.5 using cellphone positioning data and mobile sensors},
journal = {Health & Place},
volume = {75},
pages = {102803},
year = {2022},
issn = {1353-8292},
doi = {https://doi.org/10.1016/j.healthplace.2022.102803},
url = {https://www.sciencedirect.com/science/article/pii/S1353829222000648},
author = {Qiuping Li and Shen Liang and Yang Xu and Lin Liu and Suhong Zhou},
keywords = {Travel exposure, On-road PM concentrations, Cellphone positioning data, Mobile sensors},
abstract = {PM2.5 pollution imposes substantial health risks on urban residents. Previous studies mainly focused on assessing peoples' exposures at static locations, such as homes or workplaces. There has been a scarcity of research that quantifies the dynamic PM2.5 exposures of people when they travel in cities. To address this gap, we use cellphone positioning data and PM2.5 concentration data collected from smart sensors along roads in Guangzhou, China, to assess personal travel exposure to on-road PM2.5. First, we extract the trips of cellphone users from their trajectories and use the shortest path algorithm to calculate their travel routes on the road network. Second, the travel exposure of each user is estimated by associating their movement patterns with PM2.5 concentrations on roads. The result shows that most users’ average travel exposures per hour fall within the range of 20 ug/m3 to 75 ug/m3. Travel exposure varies across users, and 54.0% of users experience low travel exposure throughout the day, 25.5% of users experience high travel exposure in the evening, and 20.5% of users experience high travel exposure in the afternoon. Furthermore, the impacts of on-road PM2.5 on urban populations are uneven across roads. More attention should be given to roads with high PM2.5 concentrations and traffic flows in each period, such as Huan Shi Middle Road in the morning, Inner Ring Road in the afternoon, and Xinjiao Middle Road in the evening. The findings in this study can contribute to a more in-depth understanding of the relationship between air pollution and the travel activities of urban populations.}
}
@article{NWANOSIKE2022104679,
title = {Potential applications and performance of machine learning techniques and algorithms in clinical practice: A systematic review},
journal = {International Journal of Medical Informatics},
volume = {159},
pages = {104679},
year = {2022},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2021.104679},
url = {https://www.sciencedirect.com/science/article/pii/S1386505621003051},
author = {Ezekwesiri Michael Nwanosike and Barbara R Conway and Hamid A Merchant and Syed Shahzad Hasan},
keywords = {Machine learning, Clinical studies, Electronic health records (EHRs), Clinical practice, Model deployment, AUROC, Prediction, COVID-19},
abstract = {Purpose
The advent of clinically adapted machine learning algorithms can solve numerous problems ranging from disease diagnosis and prognosis to therapy recommendations. This systematic review examines the performance of machine learning (ML) algorithms and evaluates the progress made to date towards their implementation in clinical practice.
Methods
Systematic searching of databases (PubMed, MEDLINE, Scopus, Google Scholar, Cochrane Library and WHO Covid-19 database) to identify original articles published between January 2011 and October 2021. Studies reporting ML techniques in clinical practice involving humans and ML algorithms with a performance metric were considered.
Results
Of 873 unique articles identified, 36 studies were eligible for inclusion. The XGBoost (extreme gradient boosting) algorithm showed the highest potential for clinical applications (n = 7 studies); this was followed jointly by random forest algorithm, logistic regression, and the support vector machine, respectively (n = 5 studies). Prediction of outcomes (n = 33), in particular Inflammatory diseases (n = 7) received the most attention followed by cancer and neuropsychiatric disorders (n = 5 for each) and Covid-19 (n = 4). Thirty-three out of the thirty-six included studies passed more than 50% of the selected quality assessment criteria in the TRIPOD checklist. In contrast, none of the studies could achieve an ideal overall bias rating of ‘low’ based on the PROBAST checklist. In contrast, only three studies showed evidence of the deployment of ML algorithm(s) in clinical practice.
Conclusions
ML is potentially a reliable tool for clinical decision support. Although advocated widely in clinical practice, work is still in progress to validate clinically adapted ML algorithms. Improving quality standards, transparency, and interpretability of ML models will further lower the barriers to acceptability.}
}
@article{LIN202233,
title = {A GAN-based method for time-dependent cloud workload generation},
journal = {Journal of Parallel and Distributed Computing},
volume = {168},
pages = {33-44},
year = {2022},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2022.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S074373152200123X},
author = {Weiwei Lin and Kun Yao and Lan Zeng and Fagui Liu and Chun Shan and Xiaobin Hong},
keywords = {Cloud computing, Time-dependent workload generation, Generative adversarial networks, Deep learning},
abstract = {To design repeatable and comparable resource management policies for data centers, researchers mainly conduct experiments in the simulation environment, which requires large-scale workload traces to simulate real scenes. However, issues related to data collection, security and privacy hinder the public availability of cloud workload datasets. Though workload generation is a promising solution, due to the unpredictable time dependency, cloud workloads are difficult to model. In light of this, we propose a novel end-to-end model for time-dependent cloud workload generation using Generative Adversarial Networks, which adopts improved Temporal Convolution Networks and Spectral Normalization to capture the time dependency and stabilize the adversarial training. Experimental results on real cloud datasets demonstrate that our model can efficiently generate realistic workloads that fulfill the diversity, fidelity and usefulness. Further, we also propose a conditional GAN which is trained with labeled data and can generate specific kind of workloads according to the input.}
}