@article{ZAREJEDDI2022107476,
title = {Developing human biomonitoring as a 21st century toolbox within the European exposure science strategy 2020–2030},
journal = {Environment International},
volume = {168},
pages = {107476},
year = {2022},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2022.107476},
url = {https://www.sciencedirect.com/science/article/pii/S0160412022004032},
author = {Maryam {Zare Jeddi} and Nancy B. Hopf and Henriqueta Louro and Susana Viegas and Karen S. Galea and Robert Pasanen-Kase and Tiina Santonen and Vicente Mustieles and Mariana F. Fernandez and Hans Verhagen and Stephanie K. Bopp and Jean Philippe Antignac and Arthur David and Hans Mol and Robert Barouki and Karine Audouze and Radu-Corneliu Duca and Peter Fantke and Paul Scheepers and Manosij Ghosh and An {Van Nieuwenhuyse} and Joana {Lobo Vicente} and Xenia Trier and Loïc Rambaud and Clémence Fillol and Sebastien Denys and André Conrad and Marike Kolossa-Gehring and Alicia Paini and Jon Arnot and Florian Schulze and Kate Jones and Ovnair Sepai and Imran Ali and Lorraine Brennan and Emilio Benfenati and Francesco Cubadda and Alberto Mantovani and Alena Bartonova and Alison Connolly and Jaroslav Slobodnik and Yuri {Bruinen de Bruin} and Jacob {van Klaveren} and Nicole Palmen and Hubert Dirven and Trine Husøy and Cathrine Thomsen and Ana Virgolino and Martin Röösli and Tim Gant and Natalie {von Goetz} and Jos Bessems},
keywords = {Human biomonitoring, Chemicals mixtures, Data governance, Zero Pollution Ambition, One substance-one assessment, Circular economy},
abstract = {Human biomonitoring (HBM) is a crucial approach for exposure assessment, as emphasised in the European Commission’s Chemicals Strategy for Sustainability (CSS). HBM can help to improve chemical policies in five major key areas: (1) assessing internal and aggregate exposure in different target populations; 2) assessing exposure to chemicals across life stages; (3) assessing combined exposure to multiple chemicals (mixtures); (4) bridging regulatory silos on aggregate exposure; and (5) enhancing the effectiveness of risk management measures. In this strategy paper we propose a vision and a strategy for the use of HBM in chemical regulations and public health policy in Europe and beyond. We outline six strategic objectives and a roadmap to further strengthen HBM approaches and increase their implementation in the regulatory risk assessment of chemicals to enhance our understanding of exposure and health impacts, enabling timely and targeted policy interventions and risk management. These strategic objectives are: 1) further development of sampling strategies and sample preparation; 2) further development of chemical-analytical HBM methods; 3) improving harmonisation throughout the HBM research life cycle; 4) further development of quality control / quality assurance throughout the HBM research life cycle; 5) obtain sustained funding and reinforcement by legislation; and 6) extend target-specific communication with scientists, policymakers, citizens and other stakeholders. HBM approaches are essential in risk assessment to address scientific, regulatory and societal challenges. HBM requires full and strong support from the scientific and regulatory domain to reach its full potential in public and occupational health assessment and in regulatory decision-making.}
}
@article{YANG2022104871,
title = {The framework of safety management on university laboratory},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {80},
pages = {104871},
year = {2022},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2022.104871},
url = {https://www.sciencedirect.com/science/article/pii/S0950423022001474},
author = {Jianfeng Yang and Shenqing Xuan and Yuanhao Hu and Xinyong Liu and Mingcheng Bian and Liangchao Chen and Siyun Lv and Pengchao Wang and Ru Li and Jianwen Zhang and Chi-Min Shu and Zhan Dou},
keywords = {University laboratory, Hazardous chemicals, safety management system, inherent safety process safety management},
abstract = {In recent years, with accidents in campus laboratories happening more frequently, and sporadically many personnel and property concerned are under serious threat. To address this issue, it has become a priority for universities in China to enhance safety management in the laboratory. To begin with, this study analyzed accidents that occurred in a university laboratory in the past ten years. The aim of this act was to conclude the problems in current safety management in the university laboratory. This was followed by exploring solutions and measures for those problems, making hazardous chemicals management a critical factor in campus laboratory safety management. With this idea, an assessment of hazardous chemicals of their holistic life-cycle on campus has been conducted, which realizes the information perception throughout its entire life-cycle on campus as well. Last but not least, a platform for safety and emergency management of hazardous chemicals has been built. This platform can act as a catalyst, effectively improving the regulatory levels of hazardous chemicals. Thus, the main responsibility for hazardous chemicals units can be further implemented. Through the construction of the safety management system for the full life-cycle of hazardous chemicals, the process of safety management of the university laboratory is fulfilled, and the inherent safety of the university laboratory is finally realized.}
}
@article{LI2022493,
title = {Emplacement ages of diamondiferous kimberlites in the Wafangdian District, North China Craton: New evidence from LA-ICP-MS U-Pb geochronology of andradite-rich garnet},
journal = {Gondwana Research},
volume = {109},
pages = {493-517},
year = {2022},
issn = {1342-937X},
doi = {https://doi.org/10.1016/j.gr.2022.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S1342937X22001617},
author = {Dongsheng Li and Zhongwei Wu and Xiaoming Sun and Song Shuai and Yu Fu and Dengfeng Li and Hongjun Chen and Yang Lu and Lubing Hong},
keywords = {Kimberlite, Andradite-rich garnet, LA-ICP-MS U-Pb dating, Wafangdian diamond deposit, North China Craton},
abstract = {This contribution presents new U-Pb geochronological data and attempts to elucidate the complex evolution history of various garnet types identified from two kimberlite pipes in the Wafangdian diamond mining district, southern Liaoning Province. These calcic garnets are dominated by andradite with relatively low proportions of schorlomite, grossular and pyrope. Abundant euhedral to subhedral, highly brecciated andradite phenocrysts hosted by LN30 “carbonatite-like” kimberlite samples yield a lower-intercept age of 459.3 ± 3.4 Ma, which is in excellent agreement with the previously reported phlogopite Ar-Ar (463.9 ± 0.9 Ma) and Rb-Sr ages (461.7 ± 4.8 Ma). Based on their trace element and C-O isotopic compositions of associated groundmass carbonate, we infer that these primary magmatic andradites probably originated from kimberlitic magmas. By comparison, three compositionally and texturally distinct groups of Ti-bearing andradites from LN42 hypabyssal kimberlites separately define three well-fitted regression lines with lower intercept ages at 581 ± 12 Ma, 414.9 ± 9.3 Ma and 292.0 ± 5.7 Ma, respectively. Relict andradite xenocrysts implies that ancient lower crust of the North China Craton (NCC) might have been affected by a significant but less-known tectonothermal event to varying degrees at ∼ 0.6 Ga. By contrast, fresh grains of magmatic Ti-andradites with chemical zoning produce a relatively young age of ∼ 415 Ma, which can still provide minimum age estimates for the most recent pulses of Paleozoic kimberlite magmatism in this study area. Noteworthily, a yet unrecognized local-scale hydrothermal alteration event at ∼ 292 Ma has been recorded in the texturally distinct population of secondary hydroandradites, whose age reported here for the first time is geologically meaningful. To sum up, this study further highlights andradite U-Pb dating as a potential robust geochronometer for constraining the late-stage evolution of kimberlite magmas as well as post emplacement hydrothermal alteration.}
}
@article{ASADZADEH2022109633,
title = {UAV-based remote sensing for the petroleum industry and environmental monitoring: State-of-the-art and perspectives},
journal = {Journal of Petroleum Science and Engineering},
volume = {208},
pages = {109633},
year = {2022},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2021.109633},
url = {https://www.sciencedirect.com/science/article/pii/S0920410521012675},
author = {Saeid Asadzadeh and Wilson José de Oliveira and Carlos Roberto de {Souza Filho}},
keywords = {UAV, UAS, Drone remote sensing, Oil and gas industry, Detection and inspection, Petroleum exploration and mapping},
abstract = {An unmanned aerial vehicle (UAV), popularly known as a drone, is an aircraft without a human pilot aboard. Recent developments in sensor technology and navigation systems have made drones a powerful and reliable basis for professional data acquisition. Today, the use of UAVs has expanded massively in the civil and commercial sectors and this technology has found its way into almost every industrial sector including the petroleum industry. Drone technology offers a great potential to revolutionize the mapping, monitoring, inspection, and surveillance procedures of the petroleum industry by providing a faster, safer, and more cost-efficient way of mass data collection. This article offers a review of the common UAV platforms and sensor systems and highlights the state-of-the-art and application examples of drone remote sensing in the oil and gas industry. Six broad areas are recognized comprising offshore oil spill detection, oil leakage detection, pipeline monitoring, gas emission sensing, remote facility inspection, petroleum exploration (i.e., land surveying, geologic mapping, and petroleum exploration), and environmental monitoring. Research gaps and open issues along with opportunities for further developments in each of these areas are highlighted.}
}
@article{2022177,
title = {Diabetes mortality and trends before 25 years of age: an analysis of the Global Burden of Disease Study 2019},
journal = {The Lancet Diabetes & Endocrinology},
volume = {10},
number = {3},
pages = {177-192},
year = {2022},
issn = {2213-8587},
doi = {https://doi.org/10.1016/S2213-8587(21)00349-1},
url = {https://www.sciencedirect.com/science/article/pii/S2213858721003491},
author = {Ewerton Cousin and Bruce B Duncan and Caroline Stein and Kanyin Liane Ong and Theo Vos and Cristiana Abbafati and Mohsen Abbasi-Kangevari and Michael Abdelmasseh and Amir Abdoli and Rami Abd-Rabu and Hassan Abolhassani and Eman Abu-Gharbieh and Manfred Mario Kokou Accrombessi and Qorinah Estiningtyas Sakilah Adnani and Muhammad Sohail Afzal and Gina Agarwal and Krishna K Agrawaal and Marcela Agudelo-Botero and Bright Opoku Ahinkorah and Sajjad Ahmad and Tauseef Ahmad and Keivan Ahmadi and Sepideh Ahmadi and Ali Ahmadi and Ali Ahmed and Yusra {Ahmed Salih} and Wuraola Akande-Sholabi and Tayyaba Akram and Hanadi {Al Hamad} and Ziyad Al-Aly and Jacqueline Elizabeth Alcalde-Rabanal and Vahid Alipour and Syed Mohamed Aljunid and Rajaa M Al-Raddadi and Nelson Alvis-Guzman and Saeed Amini and Robert Ancuceanu and Tudorel Andrei and Catalina Liliana Andrei and Ranjit Mohan Anjana and Adnan Ansar and Ippazio Cosimo Antonazzo and Benny Antony and Anayochukwu Edward Anyasodor and Jalal Arabloo and Damian Arizmendi and Benedetta Armocida and Anton A Artamonov and Judie Arulappan and Zahra Aryan and Samaneh Asgari and Tahira Ashraf and Thomas Astell-Burt and Prince Atorkey and Maha Moh'd Wahbi Atout and Martin Amogre Ayanore and Ashish D Badiye and Atif Amin Baig and Mohan Bairwa and Jennifer L Baker and Ovidiu Constantin Baltatu and Palash Chandra Banik and Anthony Barnett and Mark Thomaz Ugliara Barone and Francesco Barone-Adesi and Amadou Barrow and Neeraj Bedi and Rebuma Belete and Uzma Iqbal Belgaumi and Arielle Wilder Bell and Derrick A Bennett and Isabela M Bensenor and David Beran and Akshaya Srikanth Bhagavathula and Sonu Bhaskar and Krittika Bhattacharyya and Vijayalakshmi S Bhojaraja and Ali Bijani and Boris Bikbov and Setognal Birara and Virginia Bodolica and Aime Bonny and Hermann Brenner and Nikolay Ivanovich Briko and Zahid A Butt and Florentino Luciano {Caetano dos Santos} and Luis Alberto Cámera and Ismael R Campos-Nonato and Yin Cao and Chao Cao and Ester Cerin and Promit Ananyo Chakraborty and Joht Singh Chandan and Vijay Kumar Chattu and Simiao Chen and Jee-Young Jasmine Choi and Sonali Gajanan Choudhari and Enayet Karim Chowdhury and Dinh-Toi Chu and Barbara Corso and Omid Dadras and Xiaochen Dai and Albertino Antonio Moura Damasceno and Lalit Dandona and Rakhi Dandona and Claudio Alberto Dávila-Cervantes and Jan-Walter {De Neve} and Edgar Denova-Gutiérrez and Deepak Dhamnetiya and Daniel Diaz and Sanam Ebtehaj and Hisham Atan Edinur and Sahar Eftekharzadeh and Iman {El Sayed} and Islam Y Elgendy and Muhammed Elhadi and Mohamed A Elmonem and Mohammed Faisaluddin and Umar Farooque and Xiaoqi Feng and Eduarda Fernandes and Florian Fischer and David Flood and Marisa Freitas and Peter Andras Gaal and Mohamed M Gad and Piyada Gaewkhiew and Lemma Getacher and Mansour Ghafourifard and Reza {Ghanei Gheshlagh} and Ahmad Ghashghaee and Nermin Ghith and Ghozali Ghozali and Paramjit Singh Gill and Ibrahim Abdelmageed Ginawi and Ekaterina Vladimirovna Glushkova and Mahaveer Golechha and Sameer Vali Gopalani and Rafael Alves Guimarães and Rajat Das Gupta and Rajeev Gupta and Vivek Kumar Gupta and Veer Bala Gupta and Sapna Gupta and Tesfa Dejenie Habtewold and Nima Hafezi-Nejad and Rabih Halwani and Asif Hanif and Graeme J Hankey and Shafiul Haque and Ahmed I Hasaballah and Syed Shahzad Hasan and Abdiwahab Hashi and Soheil Hassanipour and Simon I Hay and Khezar Hayat and Mohammad Heidari and Mohammad Bellal Hossain Hossain and Sahadat Hossain and Mostafa Hosseini and Soodabeh Hoveidamanesh and Junjie Huang and Ayesha Humayun and Rabia Hussain and Bing-Fang Hwang and Segun Emmanuel Ibitoye and Kevin S Ikuta and Leeberk Raja Inbaraj and Usman Iqbal and Md Shariful Islam and Sheikh Mohammed Shariful Islam and Rakibul M Islam and Nahlah Elkudssiah Ismail and Gaetano Isola and Ramaiah Itumalla and Masao Iwagami and Ihoghosa Osamuyi Iyamu and Mohammad Ali Jahani and Mihajlo Jakovljevic and Ranil Jayawardena and Ravi Prakash Jha and Oommen John and Jost B Jonas and Tamas Joo and Ali Kabir and Rohollah Kalhor and Ashwin Kamath and Tanuj Kanchan and Himal Kandel and Neeti Kapoor and Gbenga A Kayode and Sewnet Adem Kebede and Pedram Keshavarz and Mohammad Keykhaei and Yousef Saleh Khader and Himanshu Khajuria and Moien AB Khan and Md Nuruzzaman Khan and Maseer Khan and Amir M Khater and Tawfik Ahmed Muthafer Khoja and Jagdish Khubchandani and Min Seo Kim and Yun Jin Kim and Ruth W Kimokoti and Sezer Kisa and Adnan Kisa and Mika Kivimäki and Vladimir Andreevich Korshunov and Oleksii Korzh and Ai Koyanagi and Kewal Krishan and Barthelemy {Kuate Defo} and G Anil Kumar and Nithin Kumar and Dian Kusuma and Carlo {La Vecchia} and Ben Lacey and Anders O Larsson and Savita Lasrado and Wei-Chen Lee and Chiachi Bonnie Lee and Paul H Lee and Shaun Wen Huey Lee and Ming-Chieh Li and Stephen S Lim and Lee-Ling Lim and Giancarlo Lucchetti and Azeem Majeed and Ahmad Azam Malik and Borhan Mansouri and Lorenzo Giovanni Mantovani and Santi Martini and Prashant Mathur and Colm McAlinden and Nafiul Mehedi and Teferi Mekonnen and Ritesh G Menezes and Amanual Getnet Mersha and Junmei {Miao Jonasson} and Tomasz Miazgowski and Irmina Maria Michalek and Andreea Mirica and Erkin M Mirrakhimov and Agha Zeeshan Mirza and Prasanna Mithra and Abdollah Mohammadian-Hafshejani and Reza Mohammadpourhodki and Arif Mohammed and Ali H Mokdad and Mariam Molokhia and Lorenzo Monasta and Mohammad Ali Moni and Farhad Moradpour and Rahmatollah Moradzadeh and Ebrahim Mostafavi and Ulrich Otto Mueller and Christopher J L Murray and Ahmad Mustafa and Gabriele Nagel and Vinay Nangia and Atta Abbas Naqvi and Biswa Prakash Nayak and Javad Nazari and Rawlance Ndejjo and Ruxandra Irina Negoi and Sandhya {Neupane Kandel} and Cuong Tat Nguyen and Huong Lan Thi Nguyen and Jean Jacques Noubiap and Christoph Nowak and Bogdan Oancea and Oluwakemi Ololade Odukoya and Ayodipupo Sikiru Oguntade and Temitope T Ojo and Andrew T Olagunju and Obinna E Onwujekwe and Alberto Ortiz and Mayowa O Owolabi and Raffaele Palladino and Songhomitra Panda-Jonas and Seithikurippu R Pandi-Perumal and Shahina Pardhan and Tarang Parekh and Mojtaba Parvizi and Veincent Christian Filipino Pepito and Arokiasamy Perianayagam and Ionela-Roxana Petcu and Manju Pilania and Vivek Podder and Roman V Polibin and Maarten J Postma and Akila Prashant and Navid Rabiee and Mohammad Rabiee and Vafa Rahimi-Movaghar and Muhammad Aziz Rahman and Md. Mosfequr Rahman and Mosiur Rahman and Setyaningrum Rahmawaty and Nazanin Rajai and Pradhum Ram and Juwel Rana and Kamal Ranabhat and Priyanga Ranasinghe and Chythra R Rao and Satish Rao and Salman Rawaf and David Laith Rawaf and Lal Rawal and Andre M N Renzaho and Nima Rezaei and Aziz Rezapour and Seyed Mohammad Riahi and Daniela Ribeiro and Jefferson Antonio Buendia Rodriguez and Leonardo Roever and Peter Rohloff and Godfrey M Rwegerera and Paul MacDaragh Ryan and Maha Mohamed Saber-Ayad and Siamak Sabour and Basema Saddik and Sahar {Saeedi Moghaddam} and Amirhossein Sahebkar and Harihar Sahoo and KM Saif-Ur-Rahman and Hamideh Salimzadeh and Mehrnoosh Samaei and Juan Sanabria and Milena M Santric-Milicevic and Brijesh Sathian and Thirunavukkarasu Sathish and Markus P Schlaich and Abdul-Aziz Seidu and Mario Šekerija and Nachimuthu {Senthil Kumar} and Allen Seylani and Masood Ali Shaikh and Hina Shamshad and Md Shajedur Rahman Shawon and Sara Sheikhbahaei and Jeevan K Shetty and Rahman Shiri and K M Shivakumar and Kerem Shuval and Jasvinder A Singh and Ambrish Singh and Valentin Yurievich Skryabin and Anna Aleksandrovna Skryabina and Ahmad Sofi-Mahmudi and Amin Soheili and Jing Sun and Viktória Szerencsés and Miklós Szócska and Rafael Tabarés-Seisdedos and Hooman Tadbiri and Eyayou Girma Tadesse and Md. Tariqujjaman and Kavumpurathu Raman Thankappan and Rekha Thapar and Nihal Thomas and Binod Timalsina and Ruoyan Tobe-Gai and Marcello Tonelli and Marcos Roberto Tovani-Palone and Bach Xuan Tran and Jaya Prasad Tripathy and Lorainne {Tudor Car} and Biruk Shalmeno Tusa and Riaz Uddin and Era Upadhyay and Sahel {Valadan Tahbaz} and Pascual R Valdez and Tommi Juhani Vasankari and Madhur Verma and Victor E Villalobos-Daniel and Sergey Konstantinovitch Vladimirov and Bay Vo and Giang Thu Vu and Rade Vukovic and Yasir Waheed and Richard G Wamai and Andrea Werdecker and Nuwan Darshana Wickramasinghe and Andrea Sylvia Winkler and Befikadu Legesse Wubishet and Xiaoyue Xu and Suowen Xu and Seyed Hossein {Yahyazadeh Jabbari} and Hiroshi Yatsuya and Sanni Yaya and Taklo Simeneh Yazie Yazie and Siyan Yi and Naohiro Yonemoto and Ismaeel Yunusa and Siddhesh Zadey and Sojib Bin Zaman and Maryam Zamanian and Nelson Zamora and Mikhail Sergeevich Zastrozhin and Anasthasia Zastrozhina and Zhi-Jiang Zhang and Chenwen Zhong and Mohammad Zmaili and Alimuddin Zumla and Mohsen Naghavi and Maria Inês Schmidt},
abstract = {Summary
Background
Diabetes, particularly type 1 diabetes, at younger ages can be a largely preventable cause of death with the correct health care and services. We aimed to evaluate diabetes mortality and trends at ages younger than 25 years globally using data from the Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) 2019.
Methods
We used estimates of GBD 2019 to calculate international diabetes mortality at ages younger than 25 years in 1990 and 2019. Data sources for causes of death were obtained from vital registration systems, verbal autopsies, and other surveillance systems for 1990–2019. We estimated death rates for each location using the GBD Cause of Death Ensemble model. We analysed the association of age-standardised death rates per 100 000 population with the Socio-demographic Index (SDI) and a measure of universal health coverage (UHC) and described the variability within SDI quintiles. We present estimates with their 95% uncertainty intervals.
Findings
In 2019, 16 300 (95% uncertainty interval 14 200 to 18 900) global deaths due to diabetes (type 1 and 2 combined) occurred in people younger than 25 years and 73·7% (68·3 to 77·4) were classified as due to type 1 diabetes. The age-standardised death rate was 0·50 (0·44 to 0·58) per 100 000 population, and 15 900 (97·5%) of these deaths occurred in low to high-middle SDI countries. The rate was 0·13 (0·12 to 0·14) per 100 000 population in the high SDI quintile, 0·60 (0·51 to 0·70) per 100 000 population in the low-middle SDI quintile, and 0·71 (0·60 to 0·86) per 100 000 population in the low SDI quintile. Within SDI quintiles, we observed large variability in rates across countries, in part explained by the extent of UHC (r2=0·62). From 1990 to 2019, age-standardised death rates decreased globally by 17·0% (−28·4 to −2·9) for all diabetes, and by 21·0% (–33·0 to −5·9) when considering only type 1 diabetes. However, the low SDI quintile had the lowest decline for both all diabetes (−13·6% [–28·4 to 3·4]) and for type 1 diabetes (−13·6% [–29·3 to 8·9]).
Interpretation
Decreasing diabetes mortality at ages younger than 25 years remains an important challenge, especially in low and low-middle SDI countries. Inadequate diagnosis and treatment of diabetes is likely to be major contributor to these early deaths, highlighting the urgent need to provide better access to insulin and basic diabetes education and care. This mortality metric, derived from readily available and frequently updated GBD data, can help to monitor preventable diabetes-related deaths over time globally, aligned with the UN's Sustainable Development Targets, and serve as an indicator of the adequacy of basic diabetes care for type 1 and type 2 diabetes across nations.
Funding
Bill & Melinda Gates Foundation.}
}
@article{KALOGIROU2022101716,
title = {Assessing and improving the National Interoperability Frameworks of European Union Member States: The case of Greece},
journal = {Government Information Quarterly},
volume = {39},
number = {3},
pages = {101716},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2022.101716},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X22000491},
author = {Victoria Kalogirou and Antonis Stasis and Yannis Charalabidis},
keywords = {Interoperability (IOP), European Interoperability Framework (EIF), Greek National Interoperability Framework (Greek NIF/eGIF), e-Government (e-Gov), Public Administration (PA), Once-Only Principle (OOP), Single Digital Gateway (SDG)},
abstract = {Interoperability (IOP) is the ability of a product or system – whose interfaces (APIs) are publicly documented – to connect to and operate with other products or systems, without restrictions. Interoperability further enables information and usable data to be properly exchanged and ensures the alignment of different business processes in critical sectors. In addition, is a prerequisite for transparent, domain-agnostic, and sustainable public sector digital services, where Public Administrations (PA) can efficiently interact across borders and domains by using common frameworks, standards, and processes for sharing information and data. The European Interoperability Framework (EIF) enables interoperability with guidelines for digital services. Therefore, the alignment with EIF becomes pivotal for the European Union (EU) countries since different regulations that facilitate and impose the implementation of European policies such as the Single Digital Gateway (SDG) regulation and the Once-Only Principle (OOP) consider the IOP a crucial technical and operational component for government digital services. This article proposes the update of the Greek NIF, with guidelines of EIF, OOP and other technological trends in conjunction with new legal and policy provisions. This proposed assessment methodology can be reused in other countries and can be further adapted for updating the EIF.}
}
@article{YE2022,
title = {A Survey on Methods for Predicting Polyadenylation Sites from DNA Sequences, Bulk RNA-seq, and Single-cell RNA-seq},
journal = {Genomics, Proteomics & Bioinformatics},
year = {2022},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1672022922001218},
author = {Wenbin Ye and Qiwei Lian and Congting Ye and Xiaohui Wu},
keywords = {Polyadenylation, Predictive modeling, RNA-seq, Single-cell RNA-seq, Machine learning},
abstract = {Alternative polyadenylation (APA) plays important roles in modulating mRNA stability, translation, and subcellular localization, and contributes extensively to shaping eukaryotic transcriptome complexity and proteome diversity. Identification of poly(A) sites (pAs) on a genome-wide scale is a critical step toward understanding the underlying mechanism of APA-mediated gene regulation. A number of established computational tools have been proposed to predict pAs from diverse genomic data. Here we provided an exhaustive overview of computational approaches for predicting pAs from DNA sequences, bulk RNA sequencing (RNA-seq) data, and single-cell RNA-seq (scRNA-seq) data. Particularly, we examined several representative tools using RNA-seq and scRNA-seq data from peripheral blood mononuclear cells and put forward operable suggestions on how to assess the reliability of pAs predicted by different tools. We also proposed practical guidelines on choosing appropriate methods applicable to diverse scenarios. Moreover, we discussed in depth the challenges in improving the performance of pA prediction and benchmarking different methods. Additionally, we highlighted outstanding challenges and opportunities using new machine learning and integrative multi-omics techniques and provided our perspective on how computational methodologies might evolve in the future for non-3' untranslated region (UTR), tissue-specific, cross-species, and single-cell pA prediction.}
}
@article{BENHAMAID2022103257,
title = {Recent advances in energy management for Green-IoT: An up-to-date and comprehensive survey},
journal = {Journal of Network and Computer Applications},
volume = {198},
pages = {103257},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103257},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002551},
author = {Sana Benhamaid and Abdelmadjid Bouabdallah and Hicham Lakhlef},
keywords = {Internet-of-Things (IoT), Green-IoT, Energy management, Energy harvesting, Energy saving},
abstract = {Internet-of-Things (IoT) refers to the massive network interconnection of objects often equipped with ubiquitous intelligence employed to provide smart services to end users. However, one of the substantial issues of IoT is the limited energy of IoT devices that are expected to run consistently for a long period of time without battery replacement. Moreover, in the wake of pervasive IoT, the number of IoT devices has exploded and lead to a tremendous rise in IoT networks carbon footprint. In this regard, Green-IoT and energy management of IoT emerged as challenging and attractive research topics for both academia and industry. In this paper, we conduct a comprehensive and an up-to-date survey on recent energy management techniques in IoT networks. We start by presenting the challenges of energy consumption in IoT networks. Then, we will present novel and well-known energy management approaches for IoT but focus on the most recent solutions proposed in each approach. Next, we will provide a comprehensive survey of the most recent energy management solutions for IoT ecosystem. We will also present recent trends and new research perspectives that can be exploited for energy conservation in IoT networks. Finally, we will give recommendations on how to exploit the techniques presented in our survey to achieve the IoT applications QoS requirements.}
}
@article{ACHIR2022103331,
title = {Service discovery and selection in IoT: A survey and a taxonomy},
journal = {Journal of Network and Computer Applications},
volume = {200},
pages = {103331},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103331},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521003167},
author = {Meriem Achir and Abdelkrim Abdelli and Lynda Mokdad and Jalel Benothman},
keywords = {Taxonomy, Service discovery, Service selection, IoT, QoS, QoE, Classification, Architecture, Object discovery},
abstract = {Recently, Internet has evolved into a new generation, called Internet of Things, thus enabling the connection between the physical and the digital worlds by creating an ubiquitous and self-organizing network. A huge number of smart objects are becoming now identifiable and addressable while being able to communicate with each other. Moreover, the integration of cloud infrastructures in the design of IoT, has moved this new trademark technology into a new dimension, enabling virtualisation and service provisioning. Billions of cloud services with different performance levels, requirements and functionalities are thus being offered in IoT, raising however the issues of their management, discovery and selection. In the literature, a considerable effort has been invested to address service discovery and selection in the context of IoT, despite the lack of standardization that meets the IoT requirements. In this paper, we propose an exhaustive taxonomy to classify service discovery approaches in the context of IoT, that we subsequently evaluate according to different aspects and criteria. Then, we discuss the gaps and advantages of each class of our taxonomy and locate the context and the requirements under which each can operate. Finally, we identify the challenges and future research directions in this domain.}
}
@article{MATTHESS2022100038,
title = {Supplier sustainability assessment in the age of Industry 4.0 – Insights from the electronics industry},
journal = {Cleaner Logistics and Supply Chain},
volume = {4},
pages = {100038},
year = {2022},
issn = {2772-3909},
doi = {https://doi.org/10.1016/j.clscn.2022.100038},
url = {https://www.sciencedirect.com/science/article/pii/S2772390922000117},
author = {Marcel Matthess and Stefanie Kunkel and Bing Xue and Grischa Beier},
keywords = {Supplier sustainability assessment, Sustainable supply chain management, Industry 4.0, Digital technologies, Supply chain transparency, Digitalization},
abstract = {Achieving transparency of the social and environmental impacts of industrial production poses significant obstacles for companies operating in complex global supply chains. They often do not possess sufficient information of other actors, especially at lower tiers in the supply chain. In recent years, data collection and information exchange in industry has been increasingly assisted by digital technologies, coining the term Industry 4.0. However, it remains largely unknown how companies try to foster transparency in their supply chains and how digital technologies are utilized for this purpose. In this study, we employ a qualitative, interview-based approach from both buyers’ and suppliers’ perspectives to investigate practices of supplier sustainability assessments in the electronics industry as well as their current and envisioned utilization of digital technologies. With regard to the exchange of sustainability-related information, we find that buying firms do not consistently check for the availability of digital interfaces to suppliers. Systematic and well-structured collection of such data is rare in suppliers, relying on manual self-assessments and lacking the means of automated data collection. This poses difficulties for buying firms to ensure validity of sustainability performance claims, highlighted by the fact that not all buying firms analyze suppliers’ self-assessments. To overcome such issues, ongoing industry-wide efforts of standardizing sustainability requirements should be extended to include strategic considerations of streamlining technology implementation to enhance data availability and validity.}
}
@article{MEZGAR2022391,
title = {From ethics to standards – A path via responsible AI to cyber-physical production systems},
journal = {Annual Reviews in Control},
volume = {53},
pages = {391-404},
year = {2022},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1367578822000177},
author = {István Mezgár and József Váncza},
keywords = {Artificial intelligence, Cyber-physical production system, Agents, Ethics, Control, Trust},
abstract = {The central claim of the paper is that the development and control of Cyber-Physical Production Systems (CPPS) requires a systematic approach to handle and include explicit ethical considerations. Since the contribution of artificial intelligence (AI) technologies, and of agent-based models in particular, was instrumental in the evolution of CPPSs, approaches of ethical AI should be endorsed in CPPS development by design. The paper discusses recent advances for ethical AI and suggests a pathway from ethical norms towards standards. As it is argued, taking the responsible AI approach is promising when tackling the main ethic-related challenges of Cyber-Physical Production Systems. We expose a number of dilemmas to be resolved so that AI systems incorporated in CPPS cause no damages either in humans, equipment or in the environment and increase the trust in the users of current and future AI technologies.}
}
@article{PARVEN2022103119,
title = {Impacts of disaster and land-use change on food security and adaptation: Evidence from the delta community in Bangladesh},
journal = {International Journal of Disaster Risk Reduction},
volume = {78},
pages = {103119},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103119},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922003387},
author = {Afshana Parven and Indrajit Pal and Apichon Witayangkurn and Malay Pramanik and Masahiko Nagai and Hiroyuki Miyazaki and Chanakan Wuthisakkaroon},
keywords = {Food security, Land-use change, Land-accretion, Socio-ecological system, Land ownership, Resilience etc},
abstract = {Climate-related disasters severely threaten the livelihoods and food security of millions of Bangladesh is living in deltaic areas. The study looked at shifting patterns of land use, the state of food security, and adaption mechanisms in pre-and post-disaster contexts to anticipate the future situation and its influence on livelihood. The study used Landsat 5 and 8 satellite images to evaluate land cover changes from 1990 to 2015. The study also used various interview tools to assess disaster impacts on land-use change, food security, and adaptive measures. In addition, logistic regression was used to determine land-use change factors and people's perceptions of disaster risk. Satellite image analysis in this study reveals significant positive changes in aquaculture and negative changes in fallow and agricultural land. The changes due to natural disasters considerably affect their socio-ecological system, family income, agriculture production, and out-migration in the study area. Land ownership has a substantial impact on food security. According to the study, disasters disrupt ecosystem services, agriculture production, and food security and impair people's capabilities. Human activity and land accretion are the major physical driving forces influencing land use and land cover changes. People's risk perceptions should be factored into disaster management planning at the local level; this could lead to a better understanding of the policy requirements for reducing food insecurity and poverty in deltaic Bangladesh, as well as strengthening community resilience.}
}
@article{CHENG2022102398,
title = {How companies configure digital innovation attributes for business model innovation? A configurational view},
journal = {Technovation},
volume = {112},
pages = {102398},
year = {2022},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2021.102398},
url = {https://www.sciencedirect.com/science/article/pii/S0166497221001796},
author = {Cong Cheng and Limin Wang},
keywords = {DI attributes, IT infrastructure Capability, Business model innovation, fsQCA},
abstract = {Digital innovation (DI) has garnered considerable attention across a broad array of literatures. However, empirical evidence about the impact of DI on business model innovation (BMI) is sparse with frameworks probably not fully capturing the complexities of DI attributes. We use the fuzzy-set approach by conducting qualitative comparative analysis (fsQCA) to explore the configurations of DI attributes and IT infrastructure capability that exist among the 167 manufacturing and service firms in China that undergoes different levels of BMI. Results reveal that DI attributes work in three pathways to promote BMI, including organization-oriented with emphasis on improvisation, product-oriented by focusing on user experience and value proposition, and product-organization complemented. When to additionally include IT infrastructure capability for deeper analysis, results demonstrate three more representative configurations among DI attributes and IT infrastructure capability to facilitate BMI: IT-enabled organization-product orchestration, IT-enabled product-organization orchestration, and IT-dominated orchestration. This research contributes to DI literature by uncovering the configurations among DI attributes in promoting BMI, and clarifying the complicated interacting effects between DI attributes and IT infrastructure capability to facilitate BMI.}
}
@article{MERCIER2022119438,
title = {Advances in human intracranial electroencephalography research, guidelines and good practices},
journal = {NeuroImage},
volume = {260},
pages = {119438},
year = {2022},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2022.119438},
url = {https://www.sciencedirect.com/science/article/pii/S1053811922005559},
author = {Manuel R. Mercier and Anne-Sophie Dubarry and François Tadel and Pietro Avanzini and Nikolai Axmacher and Dillan Cellier and Maria Del Vecchio and Liberty S. Hamilton and Dora Hermes and Michael J. Kahana and Robert T. Knight and Anais Llorens and Pierre Megevand and Lucia Melloni and Kai J. Miller and Vitória Piai and Aina Puce and Nick F Ramsey and Caspar M. Schwiedrzik and Sydney E. Smith and Arjen Stolk and Nicole C. Swann and Mariska J Vansteensel and Bradley Voytek and Liang Wang and Jean-Philippe Lachaux and Robert Oostenveld},
keywords = {Intracranial recording in humans, Stereotactic electroencephalography, sEEG, Electrocorticogram, ECoG, Good research practice},
abstract = {Since the second half of the twentieth century, intracranial electroencephalography (iEEG), including both electrocorticography (ECoG) and stereo-electroencephalography (sEEG), has provided an intimate view into the human brain. At the interface between fundamental research and the clinic, iEEG provides both high temporal resolution and high spatial specificity but comes with constraints, such as the individual's tailored sparsity of electrode sampling. Over the years, researchers in neuroscience developed their practices to make the most of the iEEG approach. Here we offer a critical review of iEEG research practices in a didactic framework for newcomers, as well addressing issues encountered by proficient researchers. The scope is threefold: (i) review common practices in iEEG research, (ii) suggest potential guidelines for working with iEEG data and answer frequently asked questions based on the most widespread practices, and (iii) based on current neurophysiological knowledge and methodologies, pave the way to good practice standards in iEEG research. The organization of this paper follows the steps of iEEG data processing. The first section contextualizes iEEG data collection. The second section focuses on localization of intracranial electrodes. The third section highlights the main pre-processing steps. The fourth section presents iEEG signal analysis methods. The fifth section discusses statistical approaches. The sixth section draws some unique perspectives on iEEG research. Finally, to ensure a consistent nomenclature throughout the manuscript and to align with other guidelines, e.g., Brain Imaging Data Structure (BIDS) and the OHBM Committee on Best Practices in Data Analysis and Sharing (COBIDAS), we provide a glossary to disambiguate terms related to iEEG research.}
}
@article{QIN2022100326,
title = {A Segmented PageRank-Based Value Compensation Method for Personal Data in Alliance Blockchains},
journal = {Big Data Research},
volume = {30},
pages = {100326},
year = {2022},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2022.100326},
url = {https://www.sciencedirect.com/science/article/pii/S221457962200020X},
author = {Chaoxia Qin and Bing Guo and Yun Zhang and Omar Cheikhrouhou and Yan Shen and Zhen Zhang and Hong Su},
keywords = {Alliance blockchains, Personal data, Value compensation, Markov model, Segmented PageRank (SPR)},
abstract = {Alliance blockchains provide a multi-party trusted data trading environment, promoting the development of the data trading market in which the value compensation for personal data is still a key issue. However, limited by the data format and content, traditional attempts on data value compensation cannot form a widely applicable solution. Therefore, we propose a universal value compensation method for personal data in alliance blockchains. The basic idea of this method is to evaluate the value weight of data based on the collaborative relationship of data value. First, we construct a Data Collaboration Markov Model (DCMM) to formalize the collaboration network of data value. Then, aiming at data collaboration networks with different structures, the corresponding Segmented PageRank (SPR) algorithm is proposed. SPR can universally evaluate the value weight of each data account without being subjected to the data format or content. Finally, we theoretically deduce that the time complexity and space complexity of SPR algorithm are respectively 1/K and 1/K2 taken by PageRank algorithm. Experiments show the feasibility and superior performance of SPR.}
}
@article{RAUF2022111903,
title = {Machine learning in state of health and remaining useful life estimation: Theoretical and technological development in battery degradation modelling},
journal = {Renewable and Sustainable Energy Reviews},
volume = {156},
pages = {111903},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111903},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121011692},
author = {Huzaifa Rauf and Muhammad Khalid and Naveed Arshad},
keywords = {Battery degradation modelling, SOH Estimation, RUL Prediction, Li-ion Batteries, Electric vehicles, Machine learning},
abstract = {Designing and deployment of state-of-the-art electric vehicles (EVs) in terms of low cost and high driving range with appropriate reliability and security are identified as the key towards decarbonization of the transportation sector. Nevertheless, the utilization of lithium-ion batteries face a core difficulty associated with environmental degradation factors, capacity fade, aging-induced degradation, and end-of-life repurposing. These factors play a pivotal role in the field of EVs. In this regard, state-of-health (SOH) and remaining useful life (RUL) estimation outlines the efficacy of the batteries as well as facilitate in the development and testing of numerous EV optimizations with identification of parameters that will enhance and further improve their efficiency. Both indices give an accurate estimation of the battery performance, maintenance, prognostics, and health management. Accordingly, machine learning (ML) techniques provide a significant developmental scope as best parameters and approaches cannot be identified for these estimations. ML strategies comparatively provide a non-invasive approach with low computation and high accuracy considering the scalability and timescale issues of battery degradation. This paper objectively provides an inclusively extensive review on these topics based on the research conducted over the past decade. An in-depth introductory is provided for SOH and RUL estimation highlighting their process and significance. Furthermore, numerous ML techniques are thoroughly and independently investigated based on each category and sub-category implemented for SOH and RUL measurement. Finally, applications-oriented discussion that explicates the advantages in terms of accuracy and computation is presented that targets to provide an insight for further development in this field of research.}
}
@article{GIORDANO2022111475,
title = {On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {193},
pages = {111475},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111475},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001613},
author = {Giammaria Giordano and Fabio Palomba and Filomena Ferrucci},
keywords = {Data privacy, Artificial intelligence, Internet-of-Things, Software engineering for IoT},
abstract = {The Internet of Things (IoT) refers to a network of Internet-enabled devices that can make different operations, like sensing, communicating, and reacting to changes arising in the surrounding environment. Nowadays, the number of IoT devices is already higher than the world population. These devices operate by exchanging data between them, sometimes through an intermediate cloud infrastructure, and may be used to enable a wide variety of novel services that can potentially improve the quality of life of billions of people. Nonetheless, all that glitters is not gold: the increasing adoption of IoT comes with several privacy concerns due to the lack or loss of control over the sensitive data exchanged by these devices. This represents a key challenge for software engineering researchers attempting to address those privacy concerns by proposing (semi-)automated solutions to identify sources of privacy leaks. In this respect, a notable trend is represented by the adoption of smart solutions, that is, the definition of techniques based on artificial intelligence (AI) algorithms. This paper proposes a systematic literature review of the research in smart detection of privacy concerns in IoT devices. Following well-established guidelines, we identify 152 primary studies that we analyze under three main perspectives: (1) What are the privacy concerns addressed with AI-enabled techniques; (2) What are the algorithms employed and how they have been configured/validated; and (3) Which are the domains targeted by these techniques. The key results of the study identified six main tasks targeted through the use of artificial intelligence, like Malware Detection or Network Analysis. Support Vector Machine is the technique most frequently used in literature, however in many cases researchers do not explicitly indicate the domain where to use artificial intelligence algorithms. We conclude the paper by distilling several lessons learned and implications for software engineering researchers.}
}
@article{SHANKAR2022541,
title = {Digital marketing communication in global marketplaces: A review of extant research, future directions, and potential approaches},
journal = {International Journal of Research in Marketing},
volume = {39},
number = {2},
pages = {541-565},
year = {2022},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167811621000720},
author = {Venkatesh Shankar and Dhruv Grewal and Sarang Sunder and Beth Fossen and Kay Peters and Amit Agarwal},
keywords = {Digital, Marketing communication, Global, International, Social media, Mobile, Internet, B2C, B2B, C2C, C2B},
abstract = {Digital marketing communication, that is, communication through digital or electronic media among businesses and consumers, is growing rapidly, especially during the COVID-19 era. We propose a framework for analyzing digital marketing communication along four major dyads, business-to-consumer (B2C), business-to-business (B2B), consumer-to-consumer (C2C), and consumer-to-business (C2B). We review and summarize, for researchers and practitioners, the literature during 2000–2021 in these dyads along four major components: goals; channels, media, and platforms; content; and responses. We find that extant research in digital marketing communication pertains mostly to a specific, national level rather than a global level, despite the porousness of national boundaries for digital marketing. We derive important insights, identify key research gaps and questions in each of the dyads along these dimensions. We suggest approaches to address these research questions under three major components: substantive issues, data, and methods. These approaches can offer the insights that managers need to better formulate digital marketing strategies in local and global contexts.}
}
@incollection{2022727,
title = {Index},
editor = {Thomas Mehner and Klement Tockner},
booktitle = {Encyclopedia of Inland Waters (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {727-768},
year = {2022},
isbn = {978-0-12-822041-2},
doi = {https://doi.org/10.1016/B978-0-12-819166-8.09973-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128191668099734}
}
@article{MAIERHEIN2022102306,
title = {Surgical data science – from concepts toward clinical translation},
journal = {Medical Image Analysis},
volume = {76},
pages = {102306},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102306},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521003510},
author = {Lena Maier-Hein and Matthias Eisenmann and Duygu Sarikaya and Keno März and Toby Collins and Anand Malpani and Johannes Fallert and Hubertus Feussner and Stamatia Giannarou and Pietro Mascagni and Hirenkumar Nakawala and Adrian Park and Carla Pugh and Danail Stoyanov and Swaroop S. Vedula and Kevin Cleary and Gabor Fichtinger and Germain Forestier and Bernard Gibaud and Teodor Grantcharov and Makoto Hashizume and Doreen Heckmann-Nötzel and Hannes G. Kenngott and Ron Kikinis and Lars Mündermann and Nassir Navab and Sinan Onogur and Tobias Roß and Raphael Sznitman and Russell H. Taylor and Minu D. Tizabi and Martin Wagner and Gregory D. Hager and Thomas Neumuth and Nicolas Padoy and Justin Collins and Ines Gockel and Jan Goedeke and Daniel A. Hashimoto and Luc Joyeux and Kyle Lam and Daniel R. Leff and Amin Madani and Hani J. Marcus and Ozanan Meireles and Alexander Seitel and Dogu Teber and Frank Ückert and Beat P. Müller-Stich and Pierre Jannin and Stefanie Speidel},
keywords = {Surgical data science, Artificial intelligence, Deep learning, Computer aided surgery, Clinical translation},
abstract = {Recent developments in data science in general and machine learning in particular have transformed the way experts envision the future of surgery. Surgical Data Science (SDS) is a new research field that aims to improve the quality of interventional healthcare through the capture, organization, analysis and modeling of data. While an increasing number of data-driven approaches and clinical applications have been studied in the fields of radiological and clinical data science, translational success stories are still lacking in surgery. In this publication, we shed light on the underlying reasons and provide a roadmap for future advances in the field. Based on an international workshop involving leading researchers in the field of SDS, we review current practice, key achievements and initiatives as well as available standards and tools for a number of topics relevant to the field, namely (1) infrastructure for data acquisition, storage and access in the presence of regulatory constraints, (2) data annotation and sharing and (3) data analytics. We further complement this technical perspective with (4) a review of currently available SDS products and the translational progress from academia and (5) a roadmap for faster clinical translation and exploitation of the full potential of SDS, based on an international multi-round Delphi process.}
}
@article{DUC2022115927,
title = {An ensemble deep learning for automatic prediction of papillary thyroid carcinoma using fine needle aspiration cytology},
journal = {Expert Systems with Applications},
volume = {188},
pages = {115927},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115927},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421012811},
author = {Nguyen Thanh Duc and Yong-Moon Lee and Jae Hyun Park and Boreom Lee},
keywords = {Papillary thyroid carcinoma, Fine needle aspiration cytology, Computer-aided diagnosis, Deep CNN models, Ensemble learning, ThinPrep},
abstract = {Accurately cytopathological diagnosis of Papillary Thyroid Carcinoma (PTC) is of importance for reducing costs and increasing efficiency of treatments. In this paper, we pursue that goal by introducing artificial intelligence (AI) for automatic classification of malignant PTC cell clusters from Fine Needle Aspiration Cytology (FNAC) processed by ThinPrep. High-resolution cytological images obtained with a 40 × objective lens digital camera attached to an Olympus microscope were segmented into fragments and then divided into training, validation, and testing subsets. Fragments are non-overlapped patches containing only regions-of-interest that cover informative tissue structures for making proper diagnoses. Deep learning CNN models were pre-trained and fine-tuned on large-scale ImageNet domain before they were re-trained on cytology fragments. Moreover, we proposed a method to compute certainty of the patient-level prediction that undoubtedly provides additional evidence for reliability and confidence of the prediction. Results showed that the best classification performance on digital FNAC images achieved using DenseNet161, obtaining a mean accuracy of 0.9556 (p < 0.01), a mean sensitivity of 0.9734, and a mean specificity of 0.9405 on yet-to-be-seen test-set. Ensemble learning findings suggested combinations of AdaBoost classifier with multiple CNN models boosted predictive performances, up to 0.9971 accuracy. Moreover, stain normalization introduced by Reinhard increased the predictive ability, outperforming histogram specification, and Macenko methods. Presented findings demonstrate deep learning can integrate into computer-aided diagnosis systems to support cytopathologists in accurate diagnosis of PTC.}
}
@article{CHONG2022194,
title = {Bridging unlinkability and data utility: Privacy preserving data publication schemes for healthcare informatics},
journal = {Computer Communications},
volume = {191},
pages = {194-207},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2022.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S014036642200144X},
author = {Kah Meng Chong and Amizah Malip},
keywords = {Healthcare, Privacy, Utility, Anonymization, Unlinkability},
abstract = {Publishing patient data without revealing their sensitive information is one of the challenging research issues in the healthcare sector. Patient records contain useful information that is often released to healthcare industries and government institutions to support medical and census research. There are several existing privacy models in protecting healthcare data privacy, which are mainly built upon the anonymity of patients. In this paper, we incorporate unlinkability in the context of healthcare data publication, where two new privacy notions namely identity unlinkability and attribute unlinkability are introduced. We design two schemes using the proposed models to address identity disclosure and attribute disclosure problems in publishing healthcare data. Experimental results on real and synthetic datasets show that our schemes efficiently achieve data utility preservation and privacy protection simultaneously.}
}
@incollection{BRYANT202284,
title = {7.05 - Remote Sensing of Aeolian Processes},
editor = {John (Jack) F. Shroder},
booktitle = {Treatise on Geomorphology (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {84-119},
year = {2022},
isbn = {978-0-12-818235-2},
doi = {https://doi.org/10.1016/B978-0-12-818234-5.00132-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128182345001322},
author = {Robert G. Bryant and Matthew C. Baddock},
keywords = {Aeolian processes, Bedform, Coastal dune, Dune morphology, Dunefield, Dust source, Geospatial data, Lidar, Remote camera, Remote sensing, Structure from motion, Unpiloted aerial vehicle},
abstract = {This review focuses on recent advances that have taken place in the use of remote sensing to observe aeolian processes, and to highlight recent approaches that have enabled and been employed to observe and quantify aeolian processes at a range of scales. As remote technologies continue to develop, the review emphasizes the significance that, in their different forms, these data are applicable across all scales at which aeolian processes operate. To address this, the review examines a range of space-borne, airborne and near-surface technologies.}
}
@article{LENFLE2022104455,
title = {Project-oriented agency and regeneration in socio-technical transition: Insights from the case of numerical weather prediction (1978–2015)},
journal = {Research Policy},
volume = {51},
number = {3},
pages = {104455},
year = {2022},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2021.104455},
url = {https://www.sciencedirect.com/science/article/pii/S004873332100247X},
author = {Sylvain Lenfle and Jonas Söderlund},
keywords = {Socio-technical transition, Regeneration, Multi-level perspective, Reverse salient, Project-oriented agency, Data assimilation, Weather forecasting},
abstract = {This paper analyzes the unfolding of socio-technical transition (STT) using the multi-level perspective (MLP) framework. It relies on an in-depth case study of the “quiet revolution” of numerical weather prediction. The study reveals how key actors targeted the reverse salient of data assimilation and thereby facilitated the transition toward a new “variational” regime. In so doing, the paper makes three contributions to the STT literature: (1) it identifies a new type of transition pathway, “regeneration,” in which the regime transforms itself from within, despite the lack of changes in landscape pressure, to overcome internal tensions; (2) it showcases “project-oriented agency” as the central mechanism of this transition, which allows the actors to join forces and cooperate to counteract the reverse salient; and (3) it proposes a process model of project-oriented agency that accounts for the role of the reverse salient in the regeneration pathway.}
}
@article{KOSEOGLU2022316,
title = {Relational bibliometrics for hospitality and tourism research: A best practice guide},
journal = {Journal of Hospitality and Tourism Management},
volume = {52},
pages = {316-330},
year = {2022},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2022.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1447677022001243},
author = {Mehmet Ali Koseoglu and Melissa Yan {Yee Yick} and Brian King and Hasan Evrim Arici},
keywords = {Bibliometrics, Co-citation, Co-word, Co-authorship, Tourism, Hospitality},
abstract = {Noting the growing literature on relational bibliometrics and prevailing methodological challenges in hospitality and tourism research – inadequate bibliometric-focused structure and methodological transparency – this study contributes to knowledge about applicable analytical procedures. The authors uncover methodological issues by content analyzing 85 relational bibliometric articles published in 19 hospitality and tourism journals. The findings provide a basis for best practice recommendations. Four guiding principles are proposed for the scholarly deployment of relational bibliometrics, namely: (1) using multiple relational techniques to ensure a rich and comprehensive coverage of the pertinent field, (2) providing sufficient methodological disclosure, particularly language selection, data extraction from the applicable sampling, data cleaning and supplemental materials provided, (3) following a best practice work flow, including relational study methodologies, and (4) ensuring methodological adherence to three desired attributes – structured, comprehensive and transparent. The latter can potentially improve the thoroughness, clarity, and trustworthiness of future studies. The study concludes with a discussion of the findings, and a future research agenda which presents significant insights offering encouragement for bibliometric analyses, as well as acknowledging potential limitations.}
}
@article{WENDT2022103688,
title = {A multi-criteria CCUS screening evaluation of the Gulf of Mexico, USA},
journal = {International Journal of Greenhouse Gas Control},
volume = {118},
pages = {103688},
year = {2022},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2022.103688},
url = {https://www.sciencedirect.com/science/article/pii/S1750583622001062},
author = {Anna Wendt and Alana Sheriff and Chung Yan Shih and Derek Vikara and Tim Grant},
keywords = {Geologic carbon storage, Multi-criteria evaluation, Site screening, Gulf of Mexico, Outer continental shelf, Offshore CO storage},
abstract = {Continued research into reservoir characterization along with offshore carbon dioxide (CO2) transportation and infrastructure assets is needed to facilitate development of safe and successful carbon capture, utilization, and storage (CCUS) projects. This paper outlines a multi-criteria evaluation methodology that incorporates disparate sets of quantitative, spatially variable data into a decision-making framework for screening the Gulf of Mexico (GOM) outer continental shelf (OCS) for potentially viable CO2 storage and enhanced oil recovery (EOR) sites. Criteria categories include favorable geologic characteristics, logistics, and potential risks. Data compiled for 14 criteria from several publicly available geographic information system (GIS) layers was aggregated over 2559 spatially balanced points across the study area using the National Energy Technology Laboratory (NETL)-developed Cumulative Spatial Impact Layers™ (CSIL) GIS tool. Criteria are weighted by qualitative expert opinion relative to their perceived importance to given scenarios— the output of combined criteria values and weights enables regional CO2 storage suitability differentiation. The methodology considers both technical and non-technical factors impacting CCUS decision-making. The flexible methodology enables a systematic approach to regional ranking at high spatial resolution over a large study domain. Additionally, the framework enables high-grading of priority sites that warrant further characterization and follow-on analysis. Areas along the Louisiana coast and Mississippi River Delta consistently rank high for all scenarios largely a result of the favorable geology with the potential for stacked storage, as well as the density of existing pipelines and platforms, and proximity to several onshore CO2 sources. High-graded regions for the CO2 EOR-related scenarios are typically located further offshore towards the middle and edge of the OCS compared to higher priority regions for the geologic storage scenarios which fall closer to the Louisiana coastline.}
}
@article{MARCON202297,
title = {Capabilities supporting digital servitization: A multi-actor perspective},
journal = {Industrial Marketing Management},
volume = {103},
pages = {97-116},
year = {2022},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2022.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0019850122000487},
author = {Érico Marcon and Arthur Marcon and Néstor F. Ayala and Alejandro G. Frank and Vicky Story and Jamie Burton and Chris Raddats and Judy Zolkiewski},
keywords = {Digital transformation, Servitization, Digital servitization, Capabilities, Service actors},
abstract = {Digital transformation in business solutions is offering opportunities for servitization to become more digitalized. In this context, digital servitization requires the actors involved to perform new roles and develop new capabilities. Although servitization actor capabilities in the digital transformation context have been addressed in prior studies, the literature lacks a detailed understanding of how they operate according to different service types and different actor roles. Through a systematic literature review, our study aims to expound the capabilities required for digital servitization, for Base, Intermediate, and Advanced services, and analyze who of the main actors of the service triad (manufacturer, intermediaries, and customer) should own such capabilities. This analysis resulted in a final sample of 47 main articles addressing capabilities. We show how the structure of the service triad shifts the digital service provision based on the capabilities required by each actor. For instance, Base Services demand less capabilities, thus, intermediary actors play a less important role since they just execute services usually on behalf of a manufacturer in a more discrete capacity. For Intermediate Services, the intermediary actor becomes more important, with capabilities needed to deliver the digital solution. In Advanced Services, customers' relationships with manufacturers become stronger, as this actor reassumes a central role in the solution offer, and intermediaries move to a supporting role again. Our analysis offers propositions for future research on digital servitization and practical implications on the capabilities required.}
}
@article{MA2022103244,
title = {Quantitative assessment of essential tremor based on machine learning methods using wearable device},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103244},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103244},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421008417},
author = {Chenbin Ma and Deyu Li and Longsheng Pan and Xuemei Li and Chunyu Yin and Ailing Li and Zhengbo Zhang and Rui Zong},
keywords = {Essential Tremor, Wearable Sensor, Rating of Severity, Machine Learning},
abstract = {Background
Essential tremor (ET) is a progressive neurological disorder with characteristic motor symptoms. Current clinical assessments are primarily based on expert consultation combined with reviewing patient complaints and physician expertise and diagnostic experience. Research on objective quantification through wearable sensor technology combined with machine learning methods has excellent potential for application. This study automatically rates the severity of symptoms in ET patients using wearable sensors in a standardized scenario.
Methods
This study relied on a rigorous clinical trial paradigm and a wearable device based on a nine-axis Inertial Measurement Unit (IMU) to collect a large amount of kinematic data from ET patients and obtain professional physician-supported scale scores. In this paper, hand tremor signals were comprehensively analyzed, and multiple kinematic features in the time and frequency domains were extracted. These features were used to explore different machine learning approaches to automatically and quantitatively assess the disease severity in ET patients.
Results
The optimized algorithm AdaBoost has a multi-classification F1 score of up to 97.33%, with 99.64% accuracy and 99.39% specificity, respectively. The model still has a better AUC for predicting a few classes and has the current optimal automatic ET symptom recognition performance.
Discussion
These results show that the proposed method is suitable for applying standardized laboratory tests to help clinicians automate the scoring of complex or early ET cases to aid decision-making and improve disease management efficiency.}
}
@article{WEI2022113233,
title = {Global satellite water classification data products over oceanic, coastal, and inland waters},
journal = {Remote Sensing of Environment},
volume = {282},
pages = {113233},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2022.113233},
url = {https://www.sciencedirect.com/science/article/pii/S003442572200339X},
author = {Jianwei Wei and Menghua Wang and Karlis Mikelsons and Lide Jiang and Susanne Kratzer and Zhongping Lee and Tim Moore and Heidi M. Sosik and Dimitry {Van der Zande}},
keywords = {Water class, Optical water type, Remote sensing reflectance, Spectral similarity, VIIRS, Hyperspectral},
abstract = {Satellites have generated extensive data of remote sensing reflectance spectra (Rrs(λ)) covering diverse water classes or types across global waters. Spectral classification of satellite Rrs(λ) data allows for the distinguishing and grouping of waters with characteristic bio-optical/biogeochemical features that may influence the productivity of a given water body. This study reports new satellite water class products (Level-2 and Level-3) from the Visible Infrared Imaging Radiometer Suite (VIIRS). We developed and implemented a hyperspectral scheme that accounts for the Rrs(λ) spectral shapes and globally resolves oceanic, coastal, and inland waters into 23 water classes. We characterized the light absorption and scattering coefficients, chlorophyll-a concentration, diffuse attenuation coefficient, and suspended particulate matter for individual water classes. It is shown that the water classes are separable by their distinct bio-optical and biogeochemical properties. Furthermore, validation result suggests that the VIIRS water class products are accurate globally. Finally, we examined the spatial and temporal variability of the water classes in case studies for a demonstration of applications. The water class data in open oceans reveal that the subtropical ocean gyres have experienced dramatic expansion over the last decade. In addition, the water class data appear to be a valuable (and qualitative) indicator for water quality in coastal and inland waters with compelling evidence. We stress that this new satellite product is an excellent addition to the aquatic science database, despite the need for continuous improvement toward perfection.}
}
@article{FATIMA2022101641,
title = {Integration of multi access edge computing with unmanned aerial vehicles: Current techniques, open issues and research directions},
journal = {Physical Communication},
volume = {52},
pages = {101641},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2022.101641},
url = {https://www.sciencedirect.com/science/article/pii/S1874490722000271},
author = {Nida Fatima and Paresh Saxena and Manik Gupta},
keywords = {Unmanned aerial vehicle, Multi-access edge computing, 5th generation wireless communication system (5G), Beyond 5G},
abstract = {During the last decade, research and development in the field of multi access edge computing (MEC) has rapidly risen to prominence. One of the factors propelling MEC’s evolution is the ability to deploy edge servers capable of providing both communication and computational services in close proximity to the mobile user terminal. MEC has been regarded as a potentially transformative technique for fifth-generation (5G) and beyond 5G (B5G) wireless communication systems, as well as a possible complement to traditional cloud computing. Additionally, unmanned aerial vehicles (UAVs) integrated with MEC will play a critical role by introducing an additional mobility based computational layer to provide more secure, efficient and faster services. UAV enabled MEC offers seamless connectivity, fulfilling the promise of 5G’s ubiquitous connectivity. Due to the enormous interest in UAV enabled MEC, there has been a tremendous increase in the number of published research articles in this domain; however, the research area still lacks a systematic study and categorization. We present a systematic literature review (SLR) on UAV enabled MEC, examining and analyzing data on the current state of the art using preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines. To streamline our assessment, this study analyzes several research papers carefully selected through a multi-stage process satisfying the eligibility criteria defined in the paper. One of the SLR’s primary contributions is to broadly classify the research in the UAV enabled MEC domain into different categories including energy efficiency, resource allocation, security, architecture, and latency. We have identified key findings, technology, and pros and cons for the selected articles under each category. Additionally, we discuss the key open issues related to scalability and fairness, resource allocation and offloading optimization, service delivery with a focus on quality of experience (QoE) and quality of service (QoS), and standardization. Finally, we discuss several future research directions that would address the aforementioned issues and emerging use cases for UAV enabled MEC.}
}
@article{LI2022152935,
title = {Effects of warming, eutrophication and climate variability on acidification of the seasonally stratified North Yellow Sea over the past 40 years},
journal = {Science of The Total Environment},
volume = {815},
pages = {152935},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2022.152935},
url = {https://www.sciencedirect.com/science/article/pii/S0048969722000249},
author = {Cheng-long Li and De-zhou Yang and Wei-dong Zhai},
keywords = {Coastal acidification, Aragonite saturation state, Pacific decadal oscillation, North Yellow Sea},
abstract = {The North Yellow Sea (NYS) is a productive marginal sea of the western North Pacific. In summer and autumn, CaCO3 saturation states beneath the seasonal thermocline in the NYS have frequently fallen below critical levels, indicating that marine calcifying organisms are under threat. To explore the long-term evolution of the acidification of the NYS, we reconstructed seasonal variations in subsurface aragonite saturation state (Ωarag) and pH during 1976–2017, using wintertime and summertime temperature, salinity, dissolved oxygen and pH data mainly from a quality-controlled oceanographic database. Over the past 40 years, the wintertime warming rate in the NYS was twice the rate of global ocean surface warming. Warming-induced decrease in CO2 solubility canceled out a part of the wintertime Ωarag decrease caused by atmospheric CO2 increase, and also had minor effect on pH changes in winter. Although the NYS is a semi-enclosed marginal sea, its interannual variations of wintertime temperature, salinity, pH and Ωarag were correlated to Pacific Decadal Oscillation with a lag of 2–3 years. Due to the eutrophication-induced enhancement of net community respiration beneath the seasonal thermocline, long-term declines of bottom-water Ωarag and pH in summer were substantially faster than the declines of assumed air-equilibrated Ωarag and pH in spring. Over the past 40 years, the amplitudes of seasonal variations of bottom-water Ωarag and pH from spring to summer/autumn have increased by 4–7 times. This amplification has pushed the NYS towards the critical threshold of net community CaCO3 dissolution at a pace faster than that forecast under scenarios of atmospheric CO2 increase. In summary, our results provide insights into the combined effects of ocean warming, eutrophication, atmospheric CO2 rise and climate variability on coastal hydrochemistry, explaining how the environmental stresses on local marine calcifying organisms and the benthic ecosystem increased over the past 40 years.}
}
@article{JIN2022171,
title = {Fusion of optical, radar and waveform LiDAR observations for land cover classification},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {187},
pages = {171-190},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2022.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271622000752},
author = {Huiran Jin and Giorgos Mountrakis},
keywords = {Fusion, Land cover classification, Optical, SAR, Waveform LiDAR, Accuracy},
abstract = {Land cover is an integral component for characterizing anthropogenic activity and promoting sustainable land use. Mapping distribution and coverage of land cover at broad spatiotemporal scales largely relies on classification of remotely sensed data. Although recently multi-source data fusion has been playing an increasingly active role in land cover classification, our intensive review of current studies shows that the integration of optical, synthetic aperture radar (SAR) and light detection and ranging (LiDAR) observations has not been thoroughly evaluated. In this research, we bridged this gap by i) summarizing related fusion studies and assessing their reported accuracy improvements, and ii) conducting our own case study where for the first time fusion of optical, radar and waveform LiDAR observations and the associated improvements in classification accuracy are assessed using data collected by spaceborne or appropriately simulated platforms in the LiDAR case. Multitemporal Landsat-5/Thematic Mapper (TM) and Advanced Land Observing Satellite-1/ Phased Array type L-band SAR (ALOS-1/PALSAR) imagery acquired in the Central New York (CNY) region close to the collection of airborne waveform LVIS (Land, Vegetation, and Ice Sensor) data were examined. Classification was conducted using a random forest algorithm and different feature sets in terms of sensor and seasonality as input variables. Results indicate that the combined spectral, scattering and vertical structural information provided the maximum discriminative capability among different land cover types, giving rise to the highest overall accuracy of 83% (2–19% and 9–35% superior to the two-sensor and single-sensor scenarios with overall accuracies of 64–81% and 48–74%, respectively). Greater improvement was achieved when combining multitemporal Landsat images with LVIS-derived canopy height metrics as opposed to PALSAR features, suggesting that LVIS contributed more useful thematic information complementary to spectral data and beneficial to the classification task, especially for vegetation classes. With the Global Ecosystem Dynamics Investigation (GEDI), a recently launched LiDAR instrument of similar properties to the LVIS sensor now operating onboard the International Space Station (ISS), it is our hope that this research will act as a literature summary and offer guidelines for further applications of multi-date and multi-type remotely sensed data fusion for improved land cover classification.}
}
@article{LYU2022102850,
title = {Car restriction policies and housing markets},
journal = {Journal of Development Economics},
volume = {156},
pages = {102850},
year = {2022},
issn = {0304-3878},
doi = {https://doi.org/10.1016/j.jdeveco.2022.102850},
url = {https://www.sciencedirect.com/science/article/pii/S0304387822000268},
author = {Xueying Lyu},
keywords = {Car restriction policies, Housing prices, Capitalization, Wealth redistribution},
abstract = {This paper investigates the differential impacts of a unique car restriction policy – the car purchase lottery in Beijing – on the housing markets across locations within the city. I use a difference-in-differences approach to compare heterogeneous neighborhoods before and after the implementation of the policy. Housing prices experience a relative increase at locations closer to common destinations (employment centers: 0.7% per kilometer; primary schools: 3.3% per kilometer) and with better access to public transit (subways: 1.2% per kilometer; buses: 0.08% per line). These changes reflect capitalization of the car restriction policy and imply a large wealth redistribution as large as 6 years of average disposable income across homeowners. The results are relevant to policy, both in the context of unintended consequences and for efforts to develop offsetting measures.}
}
@article{ROCHERT2022101866,
title = {Caught in a networked collusion? Homogeneity in conspiracy-related discussion networks on YouTube},
journal = {Information Systems},
volume = {103},
pages = {101866},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101866},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921000946},
author = {Daniel Röchert and German Neubaum and Björn Ross and Stefan Stieglitz},
keywords = {Machine learning, Social network analysis, YouTube, Conspiracy theories, Opinion- based homogeneity},
abstract = {In many instances, misinformation among the population manifests itself in the form of conspiracy theories. Services such as YouTube, which allow the publication of audiovisual material in juxtaposition with peer responses (e.g., comments), function as ideal forums to disseminate such conspiracy theories and reach a massive audience. While previous research provided initial evidence about the prevalence of conspiracy theories in social media, it remains unclear how online networks discussing conspiracist content are structured. Knowledge about the network structure, however, could indicate to what extent people discussing conspiracist ideas face the risk of becoming caught in homogeneous communication cocoons. This work presents an approach combining natural language processing and network analysis to measure opinion-based homogeneity of discussion networks of three conspiracy theories (Hollow Earth, Chemtrails, and New World Order) on YouTube. A classification model was used to identify conspiracy and counter-conspiracy videos and associated user-generated comments (N = 123,642), as well as the interconnections between them. Although classification accuracy varied between the investigated conspiracy theories, our results indicated that people who expressed a favorable stance toward the conspiracy theory tended to respond to content or interact with users that shared the same opinion. In contrast, for two out of three conspiracy theories, people who advocated against the theory in their comments were more willing to engage in cross-cutting interactions. Findings are interpreted in light of the widely discussed fragmentation of homogeneous online networks.}
}
@article{ZHANG2022201,
title = {Deep-learning generation of POI data with scene images},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {188},
pages = {201-219},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2022.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0924271622000995},
author = {Jinbao Zhang and Xiaojuan Liu and Weilin Liao and Xia Li},
keywords = {Automatic POI-generation, Deep learning framework, Scene images, Visual-linguistic multimodal model},
abstract = {Point of interest (POI) is essential to urban scene understanding and location-based services. However, most of the POI data sets are collected manually on the spot, which is time-consuming and laborious. In this study, we propose a deep learning-based three-stage framework to automatically generate POI data sets from scene images by integrating instance segmentation, scene text recognition (STR), and multimodal technology. Firstly, we utilize an instance segmentation model to extract the region of interest (ROI) that contains POI text information from the scene images. Secondly, a STR method is used to locate and identify the text lines from the ROI. Thirdly, we develop a novel visual-linguistic multi-task classification model (VLMC) to classify ROIs and text lines through fusing text and image information. It is the first deep learning-based framework that allows generating POI information with different attributes (such as title, address, and tag) from the text lines of scene images and updating with high-performance models in the three-stage technique. In the experiments, we employ multiple STR data sets and annotated street view images for model training. The result shows that the deep learning-based framework can generate POI records from scene images with high accuracy (F1-score = 52.62%). Moreover, we find that the multi-modal VLMC model integrating the linguistic and visual embeddings has a higher accuracy in POI-generation than single-modal methods. We further use a trained framework to generate POI from Baidu Street View (BSV) images and Tencent Street View (TSV) images in Shenzhen, China, and ultimately obtain a long-term POI data set during 2013 – 2020 with 2,699,895 street view images. Of 815,616 records in the generated POI data set in 2020, 70.94% are covered by the existing Baidu POI data set of Shenzhen in 2013. This confirms the validity of the newly generated POI data set. These results demonstrate that the proposed deep-learning POI-generation framework and dataset can provide new insights for geographic data updating and urban scene understanding for fast growing cities. To facilitate future research, an implementation is made available at https://github.com/KampauCheung/scene-image-poi-generation.}
}
@article{GONZALEZGONZALO2022101034,
title = {Trustworthy AI: Closing the gap between development and integration of AI systems in ophthalmic practice},
journal = {Progress in Retinal and Eye Research},
volume = {90},
pages = {101034},
year = {2022},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2021.101034},
url = {https://www.sciencedirect.com/science/article/pii/S1350946221000951},
author = {Cristina González-Gonzalo and Eric F. Thee and Caroline C.W. Klaver and Aaron Y. Lee and Reinier O. Schlingemann and Adnan Tufail and Frank Verbraak and Clara I. Sánchez},
keywords = {Artificial intelligence, Deep learning, Machine learning, Trustworthiness, Integration, Ophthalmic care},
abstract = {An increasing number of artificial intelligence (AI) systems are being proposed in ophthalmology, motivated by the variety and amount of clinical and imaging data, as well as their potential benefits at the different stages of patient care. Despite achieving close or even superior performance to that of experts, there is a critical gap between development and integration of AI systems in ophthalmic practice. This work focuses on the importance of trustworthy AI to close that gap. We identify the main aspects or challenges that need to be considered along the AI design pipeline so as to generate systems that meet the requirements to be deemed trustworthy, including those concerning accuracy, resiliency, reliability, safety, and accountability. We elaborate on mechanisms and considerations to address those aspects or challenges, and define the roles and responsibilities of the different stakeholders involved in AI for ophthalmic care, i.e., AI developers, reading centers, healthcare providers, healthcare institutions, ophthalmological societies and working groups or committees, patients, regulatory bodies, and payers. Generating trustworthy AI is not a responsibility of a sole stakeholder. There is an impending necessity for a collaborative approach where the different stakeholders are represented along the AI design pipeline, from the definition of the intended use to post-market surveillance after regulatory approval. This work contributes to establish such multi-stakeholder interaction and the main action points to be taken so that the potential benefits of AI reach real-world ophthalmic settings.}
}
@article{WONG2022108129,
title = {Computational intelligence for preventive maintenance of power transformers},
journal = {Applied Soft Computing},
volume = {114},
pages = {108129},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108129},
url = {https://www.sciencedirect.com/science/article/pii/S156849462101005X},
author = {Shen Yuong Wong and Xiaofeng Ye and Fengkai Guo and Hui Hwang Goh},
keywords = {Power transformer, Computational Intelligence, Preventive maintenance, Fault detection and diagnosis},
abstract = {Power transformers are an indispensable equipment in power transmission and distribution systems, and failures or hidden defects in power transformers can cause operational and downtime issues in power supply, resulting in economic and resource losses. Therefore, it is highly desirable to put in place intelligent preventive maintenance measures to diagnose and evaluate the condition of power transformers. Although conventional methods have achieved success in detecting problems associated with power transformers, their adoption rate in practical environments is still far from universal. The advent of Computational Intelligence (CI) models offers useful potential to complement the existing diagnostic practices of power transformers. In this paper, we provide a review on various computational intelligence techniques for fault detection and diagnosis pertaining to preventive maintenance of power transformers. An overview of each representative CI approach is presented to facilitate researchers in selecting an appropriate method for a specific problem at hand. We carry out a broad discussion on numerous concerns and challenges that are missing from the current literature, which, nevertheless, need to be addressed seriously. We identify the research gaps in the literature, and suggest the way forward in research that will in the long run enhance power system reliability by embracing CI approaches into business operations in an effort to realize the Sustainable Development Goal (SDGs) advocated by the United Nation, primarily SDG7: Clean and Affordable Energy and SDG9: Industry, Innovation and Infrastructure.}
}
@article{GIOVANELLI2022101957,
title = {Data pre-processing pipeline generation for AutoETL},
journal = {Information Systems},
volume = {108},
pages = {101957},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101957},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921001514},
author = {Joseph Giovanelli and Besim Bilalli and Alberto Abelló},
keywords = {Data pre-processing pipelines, Data analytics},
abstract = {Data pre-processing plays a key role in a data analytics process (e.g., applying a classification algorithm on a predictive task). It encompasses a broad range of activities that span from correcting errors to selecting the most relevant features for the analysis phase. There is no clear evidence, or rules defined, on how pre-processing transformations impact the final results of the analysis. The problem is exacerbated when transformations are combined into pre-processing pipeline prototypes. Data scientists cannot easily foresee the impact of pipeline prototypes and hence require a method to discriminate between them and find the most relevant ones (e.g., with highest positive impact) for their study at hand. Once found, these prototypes can be instantiated and optimized e.g., using Bayesian Optimization. In this work, we study the impact of transformations when chained together into prototypes, and the impact of transformations when instantiated via various operators. We develop and scrutinize a generic method that allows to generate pre-processing pipelines, as a step towards AutoETL. We make use of rules that enable the construction of prototypes (i.e., define the order of transformations), and rules that guide the instantiation of the transformations inside the prototypes (i.e., define the operator for each transformation). The optimization of our effective pipeline prototypes provide results that compared to an exhaustive search, get 90% of the predictive accuracy in the median, but with a time cost that is 24 times smaller.}
}
@article{YUAN2022100217,
title = {Using traffic flow characteristics to predict real-time conflict risk: A novel method for trajectory data analysis},
journal = {Analytic Methods in Accident Research},
volume = {35},
pages = {100217},
year = {2022},
issn = {2213-6657},
doi = {https://doi.org/10.1016/j.amar.2022.100217},
url = {https://www.sciencedirect.com/science/article/pii/S2213665722000069},
author = {Chen Yuan and Ye Li and Helai Huang and Shiqi Wang and Zhenhao Sun and Yan Li},
keywords = {Real-time conflict risk, Heterogeneity, Random parameter, Machine learning},
abstract = {The real-time conflict prediction model using traffic flow characteristics is much less studied than the crash-based model. This study aims at exploring the relationship between conflicts and traffic flow features with the consideration of heterogeneity and developing predictive models to identify conflict-prone conditions in a real-time manner. The high-resolution trajectory data from the HighD dataset is used as empirical data. A novel method with the virtual detector approach for traffic feature extraction and a two-step framework is proposed for the trajectory data analysis. The framework consists of an exploratory study by random parameter logit model with heterogeneity in means and variances and a comparative study on several machine learning methods, including eXtreme Gradient Boosting (Boosting), Random Forest (Bagging), Support Vector Machine (Single-classifier), and Multilayer-Perceptron (Deep neural network). Results indicate that (1) traffic flow characteristics have significant impacts on the probability of conflict occurrence; (2) the statistical model considering mean heterogeneity outperforms the counterpart and lane differences variables are found to significantly impact the means of random parameters for both lane variables and lane differences variables; (3) eXtreme Gradient Boosting trained on an under-sampled dataset turns out to be the best model with the highest AUC of 0.871 and precision of 0.867, showing that re-sampling techniques can significantly improve the model performance. The proposed model is found to be sensitive to the conflict threshold. Sensitivity analysis on feature selection further confirms that the conflict risk prediction should consider both subject lane features and lane difference features, which verifies the consistency with exploratory analysis based on the statistical model. The consistency between statistical models and machine learning methods improves the interpretability of results for the latter one.}
}
@article{CASTANO2022101842,
title = {A knowledge-centered framework for exploration and retrieval of legal documents},
journal = {Information Systems},
volume = {106},
pages = {101842},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101842},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921000788},
author = {Silvana Castano and Mattia Falduti and Alfio Ferrara and Stefano Montanelli},
keywords = {Legal knowledge model, Legal knowledge extraction, Legal document retrieval and exploration},
abstract = {Automated legal knowledge extraction systems are strongly demanded, to support annotation of legal documents as well as knowledge extraction from them, to provide useful and relevant suggestions to legal actors (e.g., judges, lawyers) for managing incoming new cases. In this paper, we propose CRIKE (CRIme Knowledge Extraction), a knowledge-based framework conceived to support legal knowledge extraction from a collection of legal documents, based on a reference legal ontology called LATO (Legal Abstract Term Ontology). We first introduce LATO-KM, the knowledge model of LATO where legal knowledge featuring documents in the collection is properly formalized as conceptual knowledge, in form of legal concepts and relationships, and terminological knowledge, in form of term-sets associated with legal concepts. Then, we present the bootstrapping cycle of CRIKE that aims to progressively enrich the terminological knowledge layer of LATO by extracting new terms from legal documents to be used for enriching the term-set associated with a corresponding legal concept. Finally, to evaluate the results obtained through CRIKE, we discuss experimental results on a real dataset of 180,000 court decisions of the State of Illinois taken from the Caselaw Access Project (CAP).}
}
@article{KANNISTO2022100253,
title = {Plant-wide interoperability and decoupled, data-driven process control with message bus communication},
journal = {Journal of Industrial Information Integration},
volume = {26},
pages = {100253},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100253},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000522},
author = {Petri Kannisto and David Hästbacka and Teresa Gutiérrez and Olli Suominen and Matti Vilkko and Peter Craamer},
keywords = {Systems integration, Service-oriented architecture, Industrial cyber–physical systems, Industry 4.0, Publish–subscribe communication pattern},
abstract = {Conventional industrial communication systems suffer from rigidness, inflexibility and lack of scalability. The environment is heterogeneous as the systems exchange data with a variety communication protocols, some of which are proprietary. This makes it laborious and expensive to reconfigure or upgrade the systems. As the solution, this article proposes a message-bus-based communication architecture to enable information exchange between systems regardless of their geographical location and position within the functional hierarchy of the plant. The architecture not only enables communication to cross the conventional physical borders but also provides scalability to growing data volumes and network sizes. As proofs of concept, the article presents a prototype in three environments: a copper smelter, a steel plant and a distillation column. The results suggest that the message-bus-based approach has potential to renew industrial communications, a core part of the fourth industrial revolution.}
}
@article{GOERLANDT2022189,
title = {The landscape of safety management systems research: A scientometric analysis},
journal = {Journal of Safety Science and Resilience},
volume = {3},
number = {3},
pages = {189-208},
year = {2022},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2022.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2666449622000159},
author = {Floris Goerlandt and Jie Li and Genserik Reniers},
keywords = {Safety management system, Bibliometrics, Scientometrics, VOSviewer, CiteSpace},
abstract = {Safety management systems (SMSs) are widely applied across many industrial sectors, and a large body of literature has been published addressing their design, implementation, effectiveness, and associated challenges. This article presents a high-level analysis of the SMS research domain, guided by a set of questions addressing the contents, structure, and evolution the research domain, its dominant themes and focus topics, the key scientific domains and journals contributing to its development, and the key publications serving as an intellectual basis for SMS related research. The results show a rapidly increasing volume of research outputs and a shift from research based in North America and Europe to Asia and Australia. There is only a limited number of institutions enduringly contributing to the field, and there are relatively few stable research collaborations, with the number of Chinese institutions publishing SMS related research fast expanding in recent years. The domain is strongly interdisciplinary and embedded in applied domains of science, with industrial engineering the most contributing category, as well as categories focusing on the industrial application domains. A temporal evolution of the research activity in different application domains is apparent, with an initial focus on occupational health and safety, followed by process safety, patient safety, food safety, and construction safety. SMS research has a strong relation to safety culture and safety climate research, and while safety and risk management concepts and theories form an important knowledge base for most application domains, the dominant views on accident causation differ between these. Research on SMS in the food industry is relatively separated from the other application domains. Based on the findings, various future research directions are discussed.}
}
@article{YANG2022101802,
title = {Broadband internet and enterprise innovation},
journal = {China Economic Review},
volume = {74},
pages = {101802},
year = {2022},
issn = {1043-951X},
doi = {https://doi.org/10.1016/j.chieco.2022.101802},
url = {https://www.sciencedirect.com/science/article/pii/S1043951X22000608},
author = {Mengjun Yang and Shilin Zheng and Lin Zhou},
keywords = {Broadband internet, Innovation, Instrumental variable, Knowledge spillover, Financing constraints},
abstract = {Based on microdata from China's listed companies and macrodata for broadband internet access in prefecture-level cities, this paper explores the relationship between broadband internet and enterprise innovation. Using the change in market concentration caused by the North–South separation reform of China Telecom in 2002 as an instrumental variable, the results show that in general, a 1% increase in broadband internet access results in a 1.395% increase in the number of corporate patents. Specifically, the number of valid patents, patent citations and valid patent citations, reflecting patent quality, increases by 1.499%, 0.920% and 0.763%, respectively. The mechanistic analysis shows that broadband internet access contributes to increasing the number of R&D personnel and personal innovation efficiency, enhancing enterprises' willingness to innovate, and easing financing constraints. Further analysis suggests that broadband internet access mainly promotes invention patents rather than design patents. The innovation effect is more evident among high-tech, inventor-intensive, state-owned enterprises and enterprises located in the non-southeastern coastal region of China.}
}
@article{ROSTAMI2022412,
title = {Comparative sustainability study of energy storage technologies using data envelopment analysis},
journal = {Energy Storage Materials},
volume = {48},
pages = {412-438},
year = {2022},
issn = {2405-8297},
doi = {https://doi.org/10.1016/j.ensm.2022.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S2405829722001635},
author = {Fatemeh Rostami and Zoltán Kis and Rembrandt Koppelaar and Laureano Jiménez and Carlos Pozo},
keywords = {Data envelopment analysis (DEA), Energy storage, Hydrogen, Power systems flexibility, Sustainable energy},
abstract = {The transition to energy systems with a high share of renewable energy depends on the availability of technologies that can connect the physical distances or bridge the time differences between the energy supply and demand points. This study focuses on energy storage technologies due to their expected role in liberating the energy sector from fossil fuels and facilitating the penetration of intermittent renewable sources. The performance of 27 energy storage alternatives is compared considering sustainability aspects by means of data envelopment analysis. To this end, storage alternatives are first classified into two clusters: fast-response and long-term. The levelized cost of energy, energy and water consumption, global warming potential, and employment are common indicators considered for both clusters, while energy density is used only for fast-response technologies, where it plays a key role in technology selection. Flywheel reveals the highest efficiency between all the fast-response technologies, while green ammonia powered with solar energy ranks first for long-term energy storage. An uncertainty analysis is incorporated to discuss the reliability of the results. Overall, results obtained, and guidelines provided can be helpful for both decision-making and research and development purposes. For the former, we identify the most appealing energy storage options to be promoted, while for the latter, we report quantitative improvement targets that would make inefficient technologies competitive if attained. This contribution paves the way for more comprehensive studies in the context of energy storage by presenting a powerful framework for comparing options according to multiple sustainability indicators.}
}
@article{LIU2022106260,
title = {Rural typology dynamics and drivers in peripheral areas: A case of Northeast China},
journal = {Land Use Policy},
volume = {120},
pages = {106260},
year = {2022},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2022.106260},
url = {https://www.sciencedirect.com/science/article/pii/S0264837722002873},
author = {Jianzhi Liu and Yangang Fang and Ruru Wang and Cunming Zou},
keywords = {Rural typology, Rural change, Regional development, Peripheral areas, Eastern Europe},
abstract = {Socioeconomic developments in rural areas are characterized by heterogeneity and diversity rather than evolving along 'parallel linear paths'. To date, our understanding of rural heterogeneity and evolution remains limited, especially in institutionally transitional countries. Eastern Europe and Northeast China have both experienced economic recessions, industrial restructuring and urban shrinkage over the past decades and have become rust, peripheral and even stigmatized areas. However, the backdrop of rural evolution in Northeast China is different from that of Eastern Europe, since its institutional transition has been gradual rather than a 'shock therapy'. This paper proposes a conceptual framework for rural typology and uses cluster analysis and random forest to explore the rural typological evolution and drivers in Northeast China from 2000 to 2017. The results show that the modernizing grain agriculture leading type currently occupies the main position in Northeast China, while the urbanizing type and industry diversification type only account for 18.6 %. Regarding rural typological dynamics from 2000 to 2017, the modernizing grain agriculture leading type expanded and intensified in more peripheral areas with abundant arable land resources or high potential for arable land reclamation, driven by increasing national grain demand, widening regional economic disparities and division of labor, and agricultural policies. Meanwhile, the transformation mode from the modernizing grain agriculture leading type to the industry diversification type (5.81 %) developed in areas with relatively developed economies, proximity to markets, and dense populations. Finally, we discuss the similarities and differences in rural development between Northeast China and Eastern Europe and propose related policy implications for rural development.}
}
@article{BOGDANOVA2022190,
title = {Prediction of the Air Pollution by Geo-locations in Sofia},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {11},
pages = {190-195},
year = {2022},
note = {IFAC Workshop on Control for Smart Cities CSC 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.08.071},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322011612},
author = {Boryana Bogdanova and Jr. Angel Marchev and Vladimir Zakov and Denis Stefanov and Kiril Genov},
keywords = {PM10 air pollution, citizen measurement network, bias correction, meteorological indicators, ARIMAX, random forest, feature engineering, next day prediction},
abstract = {We develop a general framework for analysis and prediction of air pollution in the city of Sofia, Bulgaria, as measured by the level of the PM10 air pollutant indicator. As a starting point in our analysis, we consider earlier findings documented in the literature. We focus on utilized methodology so as to support the process of defining proper predictive approach that is adopted in our methodological framework.}
}
@article{ZHIFEI2022,
title = {Air combat target maneuver trajectory prediction based on robust regularized Volterra series and adaptive ensemble online transfer learning},
journal = {Defence Technology},
year = {2022},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2022.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S2214914722001349},
author = {Xi Zhi-fei and Kou Ying-xin and Li Zhan-wu and Lv Yue and Xu An and Li You and Li Shuang-qing},
keywords = {Maneuver trajectory prediction, Volterra series, Transfer learning, Online learning, Ensemble learning, Robust regularization},
abstract = {Target maneuver trajectory prediction is an important prerequisite for air combat situation awareness and maneuver decision-making. However, how to use a large amount of trajectory data generated by air combat confrontation training to achieve real-time and accurate prediction of target maneuver trajectory is an urgent problem to be solved. To solve this problem, in this paper, a hybrid algorithm based on transfer learning, online learning, ensemble learning, regularization technology, target maneuvering segmentation point recognition algorithm, and Volterra series, abbreviated as AERTrOS-Volterra is proposed. Firstly, the model makes full use of a large number of trajectory sample data generated by air combat confrontation training, and constructs a Tr-Volterra algorithm framework suitable for air combat target maneuver trajectory prediction, which realizes the extraction of effective information from the historical trajectory data. Secondly, in order to improve the real-time online prediction accuracy and robustness of the prediction model in complex electromagnetic environments, on the basis of the Tr-Volterra algorithm framework, a robust regularized online Sequential Volterra prediction model is proposed by integrating online learning method, regularization technology and inverse weighting calculation method based on the priori error. Finally, inspired by the preferable performance of models ensemble, ensemble learning scheme is also incorporated into our proposed algorithm, which adaptively updates the ensemble prediction model according to the performance of the model on real-time samples and the recognition results of target maneuvering segmentation points, including the adaptation of model weights; adaptation of parameters; and dynamic inclusion and removal of models. Compared with many existing time series prediction methods, the newly proposed target maneuver trajectory prediction algorithm can fully mine the prior knowledge contained in the historical data to assist the current prediction. The rationality and effectiveness of the proposed algorithm are verified by simulation on three sets of chaotic time series data sets and a set of real target maneuver trajectory data sets.}
}
@article{ABUTALIB2022102875,
title = {APT beaconing detection: A systematic review},
journal = {Computers & Security},
volume = {122},
pages = {102875},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2022.102875},
url = {https://www.sciencedirect.com/science/article/pii/S0167404822002693},
author = {Manar {Abu Talib} and Qassim Nasir and Ali {Bou Nassif} and Takua Mokhamed and Nafisa Ahmed and Bayan Mahfood},
keywords = {APT, Beaconing, Attack, Security breach, Detection, AI, C&C},
abstract = {Advanced Persistent Threat (APT) is a type of threat that has grabbed the attention of researchers, particularly in the industrial security field. APTs are cyber intrusions carried out by skilled and well-resourced adversaries who target specific information in high-profile organizations and governments, frequently as part of a multi-phase long-term operation. One of the phases of the APT process is the command-and-control (C&C) phase, also known as beaconing. Beaconing is an important part of an APT lifecycle, where the adversaries establish channels with the compromised hosts in the targeted system, allowing them to launch additional attacks. Detecting and predicting this stage is therefore a practical way to guard against APTs. This paper discusses the techniques and methods used to detect APTs and also specifically to identify beaconing, either during the APT lifecycle or not. In it, we determine various artificial intelligence algorithms used for detecting, analyzing and comparing characteristics of datasets and data sources used to implement these detection techniques. Moreover, we present the strengths and challenges of various APT/beaconing detection methods. Finally, this study outlines many cybersecurity vendor projects that have been created to identify APT or beaconing operations, categorized according to the detection approach utilized.}
}
@article{XIE2022382,
title = {Carbon price prediction considering climate change: A text-based framework},
journal = {Economic Analysis and Policy},
volume = {74},
pages = {382-401},
year = {2022},
issn = {0313-5926},
doi = {https://doi.org/10.1016/j.eap.2022.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0313592622000297},
author = {Qiwei Xie and Jingjing Hao and Jingyu Li and Xiaolong Zheng},
keywords = {Carbon price prediction, Text mining, Climate change, Long short-term memory (LSTM), Random forest (RF)},
abstract = {Carbon trading is a vital market mechanism to achieve carbon emission reduction. The accurate prediction of the carbon price is conducive to the effective management and decision-making of the carbon trading market. However, existing research on carbon price forecasting has ignored the impacts of multiple factors on the carbon price, especially climate change. This study proposes a text-based framework for carbon price prediction that considers the impact of climate change. Textual online news is innovatively employed to construct a climate-related variable. The information is combined with other variables affecting the carbon price to forecast the carbon price, using a long short-term memory network and random forest model. The results demonstrate that the prediction accuracy of the carbon price in the Hubei and Guangdong carbon markets is enhanced by adding the textual variable that measures climate change.}
}
@article{ALIRAMEZANI2022100967,
title = {Modeling, diagnostics, optimization, and control of internal combustion engines via modern machine learning techniques: A review and future directions},
journal = {Progress in Energy and Combustion Science},
volume = {88},
pages = {100967},
year = {2022},
issn = {0360-1285},
doi = {https://doi.org/10.1016/j.pecs.2021.100967},
url = {https://www.sciencedirect.com/science/article/pii/S0360128521000654},
author = {Masoud Aliramezani and Charles Robert Koch and Mahdi Shahbakhti},
keywords = {Internal combustion engines, Combustion control, Optimization, Artificial intelligence, Machine learning, Emissions, Energy},
abstract = {A critical review of the existing Internal Combustion Engine (ICE) modeling, optimization, diagnosis, and control challenges and the promising state-of-the-art Machine Learning (ML) solutions for them is provided in this paper. Some of the major challenges include Real Driving Emission (RDE) modeling and control, combustion knock detection and control, combustion mode transition in multi-mode engines, combustion noise modeling and control, combustion instability and cyclic variability control, costly and time-consuming engine calibration, and fault diagnostics of some ICE components. In this paper, conventional ICE modeling approaches are discussed along with their limitations for realtime ICE optimization and control. Promising ML approaches to address ICE challenges are then classified into three main groups of unsupervised learning, supervised learning, and reinforcement learning. The working principles of each approach along with their advantages and disadvantages in addressing ICE challenges are discussed. ML-based grey-box approach is proposed as a solution that combines the benefits from physics-based and ML-based models to provide robust and high fidelity solutions for ICE modeling and control challenges. This review provides in-depth insight into the applications of ML for ICEs and provides recommendations for future directions to address ICE challenges.}
}
@article{LO2022111357,
title = {Architectural patterns for the design of federated learning systems},
journal = {Journal of Systems and Software},
volume = {191},
pages = {111357},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111357},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000899},
author = {Sin Kit Lo and Qinghua Lu and Liming Zhu and Hye-Young Paik and Xiwei Xu and Chen Wang},
keywords = {Federated learning, Pattern, Software architecture, Machine learning, Artificial intelligence},
abstract = {Federated learning has received fast-growing interests from academia and industry to tackle the challenges of data hungriness and privacy in machine learning. A federated learning system can be viewed as a large-scale distributed system with different components and stakeholders as numerous client devices participate in federated learning. Designing a federated learning system requires software system design thinking apart from the machine learning knowledge. Although much effort has been put into federated learning from the machine learning technique aspects, the software architecture design concerns in building federated learning systems have been largely ignored. Therefore, in this paper, we present a collection of architectural patterns to deal with the design challenges of federated learning systems. Architectural patterns present reusable solutions to a commonly occurring problem within a given context during software architecture design. The presented patterns are based on the results of a systematic literature review and include three client management patterns, four model management patterns, three model training patterns, four model aggregation patterns, and one configuration pattern. The patterns are associated to the particular state transitions in a federated learning model lifecycle, serving as a guidance for effective use of the patterns in the design of federated learning systems.}
}
@article{BACKES2022102056,
title = {Lattice-based progressive author disambiguation},
journal = {Information Systems},
volume = {109},
pages = {102056},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2022.102056},
url = {https://www.sciencedirect.com/science/article/pii/S0306437922000473},
author = {Tobias Backes and Stefan Dietze},
keywords = {Author name disambiguation, Progressive entity resolution, Blocking, Formal concept analysis, Association rule learning},
abstract = {Different use cases have acknowledged the importance of author identities and the non-triviality of determining them. Author disambiguation (AD) is a special case of entity resolution resolving author mentions to actual real-world authors. Like in other entity resolution tasks, AD methods are strongly restricted by scale and person name conventions. So far, this has been addressed by static blocking methods which cannot adapt to such collection-dependent properties. We address this gap by presenting the first progressive method of author disambiguation. Progressive entity resolution tackles large-scale conflation problems by repeatedly increasing the number of pairs compared for potential equivalence. Our method uses lattice structures to model name inclusion in an adaptive and more efficient way than traditional blocking techniques based on alphabetical order or fixed-level generalization. Our work offers additional insights into the relationship between name-matching, different blocking schemes, blocking and clustering as well as cost and benefit. Using the Web of Science as large-scale annotated test data, we observe and compare our model’s performance over time and compare it with various configurations and baselines. Our approach consistently outperforms state-of-the-art blocking methods, underlining its contribution to the field of author disambiguation. Our approach offers a novel alternative for tackling ambiguity in entity resolution, which is a major challenge for many information systems.}
}
@article{YUAN2022105647,
title = {Safety barriers in the chemical process industries: A state-of-the-art review on their classification, assessment, and management},
journal = {Safety Science},
volume = {148},
pages = {105647},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105647},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521004872},
author = {Shuaiqi Yuan and Ming Yang and Genserik Reniers and Chao Chen and Jiansong Wu},
keywords = {Safety barrier, Barrier management, Barrier performance assessment, Process industry, Resilience},
abstract = {Barriers are used in various forms to assure the safety of chemical plants. A deep understanding of the literature related to safety barriers is essential to tackle the challenges in improving their design and management. This paper first provides an overview of the history of the development of the safety barrier concept. Subsequently, this paper elaborates a systematic review of the definition, classification, evaluation, performance assessment, and management of safety barriers in the chemical process industries. Based on the literature review, this study proposes a practical classification of safety barriers benefiting the identification of performance indicators and the collection of indicator-related data for safety barriers. The safety barrier functions are extended and illustrated by involving the resilience concept. Performance assessment criteria are proposed corresponding to the adaptability and recoverability of the safety barriers. Finally, the management of safety barriers is discussed. The roadmap for future studies to develop integrated management of safety and security barriers to ensure the resilience of chemical plants is suggested.}
}
@article{PAPANDREOU2022110321,
title = {Predicting VLCC fuel consumption with machine learning using operationally available sensor data},
journal = {Ocean Engineering},
volume = {243},
pages = {110321},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.110321},
url = {https://www.sciencedirect.com/science/article/pii/S002980182101622X},
author = {Christos Papandreou and Apostolos Ziakopoulos},
keywords = {Fuel oil consumption prediction, VLCC sensor Data, Machine learning, Polynomial regression, Artificial neural network, XGBoost regression},
abstract = {In the maritime industry, more accurate predictions of fuel oil consumption (FOC) could yield multidimensional results including more precise bunker calculations, emission reductions, more informed planning and limiting operational costs. However, models often require sophisticated data that may be partially unavailable to operators beforehand. The present research aims to develop accurate main engine FOC forecasting models that utilize exclusively data from sensors and simple weather data readily available in operational practice. Commonly available sensor data from a Very Large Crude Oil Carrier (VLCC) were used, comprising speed through water, relative wind direction, relative wind speed, mean draft, trim, days since last drydock and laden or ballast vessel state. Multivariate Polynomial Regression (MPR), Artificial Neural Networks (ANNs) and eXtreme Gradient Boosting (XGBoost) regression models were developed and evaluated based on their predictive accuracy for VLCC FOC. Results indicated that XGBoost had the best performance, yielding predictions within 5% of the true value more than 86% of the total cases, followed by MPR and ANN. In addition, accurate aggregate FOC forecasting was conducted with XGBoost for a laden voyage and a ballast voyage of a VLCC.}
}
@article{PASZKIEWICZ2022116671,
title = {Advances in suspect screening and non-target analysis of polar emerging contaminants in the environmental monitoring},
journal = {TrAC Trends in Analytical Chemistry},
volume = {154},
pages = {116671},
year = {2022},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2022.116671},
url = {https://www.sciencedirect.com/science/article/pii/S0165993622001546},
author = {Monika Paszkiewicz and Klaudia Godlewska and Hanna Lis and Magda Caban and Anna Białk-Bielińska and Piotr Stepnowski},
abstract = {The production and use of chemicals worldwide, and thus the number of those that can potentially leach into the environment, is constantly increasing. Recent advances in analytical techniques provide the opportunity to detect a wide range of contaminants in water that would not be detected by traditional targeted analysis (TA) methods. These advanced techniques include the use of high-resolution mass spectrometry (HRMS) or tandem HRMS in suspect screening analysis (SSA) or non-target analysis (NTA). This review presents the advances of the last five years for SSA and NTA of polar emerging contaminants (ECs) in various matrices, including drinking water, surface water, wastewater, and soil/sediment. We discuss all steps in the analytical procedure, including novel sampling and extraction approaches, GC or LC-HRMS analysis, (pre)data processing, evaluation, and reporting. We also identify challenges and future trends in SSA and NTA monitoring of polar ECs.}
}
@article{TRUONGHONG2022101490,
title = {Extracting structural components of concrete buildings from laser scanning point clouds from construction sites},
journal = {Advanced Engineering Informatics},
volume = {51},
pages = {101490},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101490},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621002391},
author = {L. Truong-Hong and Roderik Lindenbergh},
keywords = {Point cloud, Object extraction, Structure extraction, Segmentation, Inspection, Scan to BIM},
abstract = {In construction projects, inspection of structural components mostly relies on classical measurements obtained by measuring tapes, levelling, or total stations. With those methods, only a few points on the structure can be measured, and the resulting inspection may not fully reflect the actual, detailed condition of the complete object. Laser scanning is an emerging remote sensing technology to accurately and quickly capture surfaces of structures in high details. However, because of the complex, massive point cloud data acquired at a construction project, in practice, data processing is still manual work with computer aided programs. To improve upon current workflows, this paper proposes a method to automatically extract point clouds of individual surfaces of structural components of a concrete building, which subsequently can be used to inspect construction quality based on geometric information of the surfaces. The proposed method explores both spatial point cloud information and contextual knowledge of structures (e.g., orientation or shape) derived from building design specifications and practice. For extracting point clouds of surfaces of each structural component, the proposed method consists of 4 consecutive steps for extracting: (1) floors, ceiling slabs, and walls, (2) columns, and (3) primary and (4) secondary beams. Each step consists of two ingredients: (i) rough extracting the candidate points of the component and (ii) fine filtering of the surface points of the components via cell-based and voxel-based region growing segmentation (CRG and VRG) incorporating contextual knowledge of the structural members. Experimental tests on two different types of concrete buildings showed that the proposed method successfully extracts the structural elements, in which the completeness, correctness, and quality from the point-based evaluation are larger than 96.0%, 96.9%, and 92.0%, respectively. Moreover, the evaluation based on a shape similarity showed that the extracted floor, ceiling slab and wall overlap to the ground truth more than 92.5%.}
}
@article{MOSTAFAEI2022100974,
title = {Defects and anomalies in powder bed fusion metal additive manufacturing},
journal = {Current Opinion in Solid State and Materials Science},
volume = {26},
number = {2},
pages = {100974},
year = {2022},
issn = {1359-0286},
doi = {https://doi.org/10.1016/j.cossms.2021.100974},
url = {https://www.sciencedirect.com/science/article/pii/S1359028621000772},
author = {Amir Mostafaei and Cang Zhao and Yining He and Seyed {Reza Ghiaasiaan} and Bo Shi and Shuai Shao and Nima Shamsaei and Ziheng Wu and Nadia Kouraytem and Tao Sun and Joseph Pauza and Jerard V. Gordon and Bryan Webler and Niranjan D. Parab and Mohammadreza Asherloo and Qilin Guo and Lianyi Chen and Anthony D. Rollett},
keywords = {Additive manufacturing, Powder-related defects, Processing-related defects, Post-processing-related defects, Defect mitigation, Process-structure–property relationship},
abstract = {Metal additive manufacturing is a disruptive technology that is revolutionizing the manufacturing industry. Despite its unrivaled capability for directly fabricating metal parts with complex geometries, the wide realization of the technology is currently limited by microstructural defects and anomalies, which could significantly degrade the structural integrity and service performance of the product. Accurate detection, characterization, and prediction of these defects and anomalies have an important and immediate impact in manufacturing fully-dense and defect-free builds. This review seeks to elucidate common defects/anomalies and their formation mechanisms in powder bed fusion additive manufacturing processes. They could arise from raw materials, processing conditions, and post-processing. While defects/anomalies in laser welding have been studied extensively, their formation and evolution remain unclear. Additionally, the existence of powder in powder bed fusion techniques may generate new types of defects, e.g., porosity transferring from powder to builds. Practical strategies to mitigate defects are also addressed through fundamental understanding of their formation. Such explorations enable the validation and calibration of models and ease the process qualification without costly trial-and-error experimentation.}
}
@article{DEWULF2022693,
title = {Advances in the metrological traceability and performance of X-ray computed tomography},
journal = {CIRP Annals},
volume = {71},
number = {2},
pages = {693-716},
year = {2022},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2022.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007850622001275},
author = {Wim Dewulf and Harald Bosse and Simone Carmignato and Richard Leach},
keywords = {X-ray, Metrology, Traceability},
abstract = {X-ray computed tomography (XCT) is increasingly being used for evaluating quality and conformance of complex products, including assemblies and additively manufactured parts. The metrological performance and traceability of XCT nevertheless remains an important research area that is reviewed in this paper. The error sources influencing XCT measurement results are discussed, along with related qualification, calibration and optimization procedures. Moreover, progress on performance verification testing and on the determination of task-specific measurement uncertainty is covered. Results of interlaboratory comparisons are summarized and performance in various dimensional measurement fields is illustrated. Conclusions and an outlook for future research activities are also provided.}
}
@article{KONOVALENKO2022116208,
title = {Generating decision support for alarm processing in cold supply chains using a hybrid k-NN algorithm},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116208},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116208},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015220},
author = {Iurii Konovalenko and André Ludwig},
keywords = {k-nearest neighbors, Fuzzy set, Recommendation, Decision Support, Pharmaceutical supply chain, Temperature deviation},
abstract = {Real-time temperature monitoring is necessary in cold pharmaceutical supply chains (SCs), where exposures to extreme temperatures can lead to product quality deterioration. Temperature alarms (TAs) triggered by the current rule-based systems still require lengthy examinations before a suitable corrective measure (CM) can be chosen. However, provision of additional information relevant to TAs can expedite the examination process. In the related areas of recommender systems and false alarm/anomaly detection, k-nearest neighbors (k-NN) algorithm has proven to be successful because of its interpretability and ease of use. However, in the context of TA processing, it may suffer from some inherent limitations (i.e., varying neighborhood radius, unreliable classifications in sparse and noisy regions, and blindness to natural class boundaries). To overcome these limitations, we propose a hybrid k-NN (Hk-NN) algorithm based on the principles of local similarity and neighborhood homogeneity. It incorporates a two-step voting procedure with an entropy-optimized k-NN radius, decision trees with k-constrained leaves, and nearest neighbor predictions. We investigate 16,525 comments by alarm personnel for TAs in a pharmaceutical SC and encode them in terms of deviation causes and CMs (target features). We use SC data on cargo location, SC phase, sensor role, and temperature characteristics as predictor features for TA similarity estimation. In eight experimental setups, Hk-NN consistently outperforms k-NN with an optimized k in terms of accuracy, balanced accuracy, macro-average precision, recall, and specificity. At the same time, Hk-NN refrains from predicting observations, for which k-NN’s accuracy is close to a random guess.}
}
@article{BISWAS2022,
title = {Traceability vs. sustainability in supply chains: The implications of blockchain},
journal = {European Journal of Operational Research},
year = {2022},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2022.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0377221722004076},
author = {Debajyoti Biswas and Hamed Jalali and Amir H. Ansaripoor and Pietro {De Giovanni}},
keywords = {Quality management, Blockchain, Supply chain, Sustainability, Game theory},
abstract = {This research proposes a game theory model in a supply chain (SC) involving one manufacturer and one retailer. The SC works in a global market in which consumers are located worldwide and subject to traceability issues that can create distrust of the product quality. This issue can be resolved by implementing blockchain technology which provides benefits in terms of high traceability along with low transaction costs. However, blockchain negatively impacts the environment because of their high energy consumption. Therefore, in this study, we capture the trade-offs between traceability and sustainability for blockchain adoption by characterizing a game theory model. Our findings show that high levels of distrust pushes firms to avoid the implementation of blockchain. In such circumstances, blockchain is not sufficient to make consumers recognize the product quality and trust the firms’ practices. In contrast, low levels of distrust can make blockchain an economically suitable technology conditioned to minimal environmental damages; otherwise, firms need to carefully evaluate the trade-offs between distrust and sustainability. Since the adoption of blockchain leads to an increase in prices and decrease of distrust, two factors determine whether to pursue this technology or not: low consumer sensitivity to price and high sensitivity to quality. In this study, we develop three specific cases where we model: 1) the direct impact of blockchain on distrust, 2) a stochastic distrust term, and 3) a Stackelberg game. Each case confirms our results and strengthens the robustness of our findings.}
}
@article{MISHRA2022133595,
title = {Internet of Things (IoT) adoption challenges in renewable energy: A case study from a developing economy},
journal = {Journal of Cleaner Production},
volume = {371},
pages = {133595},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.133595},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622031742},
author = {Rahul Mishra and B. Koteswara Rao Naik and Rakesh D. Raut and Mukesh Kumar},
keywords = {IoT, Digitalization of renewable energy(DRE), Renewable energy (RE), Fuzzy-DEMATEL, Exploratory factor analysis (EFA), Energy transition},
abstract = {Digitalization of Renewable Energy (RE) systems will play a decisive role in integrating clean energy sources and optimizing energy use. While energy digitalization is mainly governed by technological progress, the societal acceptance of such emerging technologies is essential for a successful energy transition. This study aims to identify critical challenges to IoT-enabled renewable energy use through the lens of the consumers. It attempts to analyze the challenges to implementing IoT effectively in emerging economies like India. The present study employs Exploratory Factor Analysis (EFA) to classify 16 critical challenges into five main dimensions, using the responses obtained from 95 participants. Subsequently, the fuzzy decision-making trial and evaluation laboratory (DEMATEL) prioritizes the identified challenges and organizes them into cause-and-effect groups based on their interactions. The findings indicate that technological challenges constitute the most critical cause barrier that affects other category barriers. Besides technology, challenges reflecting the social infrastructure have emerged prominently in this study. Thereafter, the analysis suggests that modifications to the structure, procedures, and technology are required to create capabilities and enhance the compatibility of IoT with RE applications. Further, proactive governance and reorienting market design are highlighted to foster emerging technologies and develop a robust regulatory framework. The insights from this study are pertinent for policymakers, regulatory bodies, and practitioners seeking to capitalize on the immense potential of this sector and expedite energy transactivity.}
}
@article{ERYARSOY2022108,
title = {Assessing IoT challenges in supply chain: A comparative study before and during- COVID-19 using interval valued neutrosophic analytical hierarchy process},
journal = {Journal of Business Research},
volume = {147},
pages = {108-123},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322002703},
author = {Enes Eryarsoy and Huseyin Selcuk Kilic and Selim Zaim and Marzhan Doszhanova},
keywords = {Internet of Things, IoT, Industrial internet of things, IIoT, Industry 4.0, i4.0, Supply chain management, COVID-19, Analytical hierarchy process (AHP), Multi-criteria decision analysis (MCDA), Interval-valued neutrosophic sets},
abstract = {Although the Internet of Things (IoT) has spawned a new breed of smart factories within supply chains, the latest pandemic has ushered in unparalleled supply chain disturbances. Following the challenges identified in the literature, we interview top experts to evaluate the significance of these challenges. We apply a multi-criteria decision analysis (MCDA) tool, analytical hierarchy process (AHP) in combination with interval-valued neutrosophic numbers (IVN). The critical part of this research is that we also perform a comparative analysis by focusing on before- and during- the pandemic periods individually to better assess the impact of the latest pandemic on the IoT challenges. Our study also includes a comprehensive, systematic literature review to bring the readers up-to-date.}
}
@article{PLEKHANOV2022,
title = {Digital transformation: A review and research agenda},
journal = {European Management Journal},
year = {2022},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2022.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0263237322001219},
author = {Dmitry Plekhanov and Henrik Franke and Torbjørn H. Netland},
keywords = {Digital transformation, Digitalization, Digital ecosystems, Organizational change, Literature review},
abstract = {The ongoing and ubiquitous digital transformation challenges the raison d'être of firms and forces managers to rethink business strategies and operations and academics to reconsider related theories. To aid these efforts, we conduct a systematic review of research on firms' digital transformation, generating a database of 537 peer-reviewed academic articles and analyzing it using a novel multi-layered framework. The framework separates three layers: an organization's core activities, its peripheral activities, and its external environment. We find that firms that have come far in their transformations are more embedded in platform ecosystems with unclear business boundaries. Relatedly, we identify a tension between decentralizing versus centralizing power across organizational layers during a firm's digital transformation and how this dynamic affects corporate strategies and firms' internal and external boundaries.}
}
@article{NGWA2022e251,
title = {Cancer in sub-Saharan Africa: a Lancet Oncology Commission},
journal = {The Lancet Oncology},
volume = {23},
number = {6},
pages = {e251-e312},
year = {2022},
issn = {1470-2045},
doi = {https://doi.org/10.1016/S1470-2045(21)00720-8},
url = {https://www.sciencedirect.com/science/article/pii/S1470204521007208},
author = {Wilfred Ngwa and Beatrice W Addai and Isaac Adewole and Victoria Ainsworth and James Alaro and Olusegun I Alatise and Zipporah Ali and Benjamin O Anderson and Rose Anorlu and Stephen Avery and Prebo Barango and Noella Bih and Christopher M Booth and Otis W Brawley and Jean-Marie Dangou and Lynette Denny and Jennifer Dent and Shekinah N C Elmore and Ahmed Elzawawy and Diane Gashumba and Jennifer Geel and Katy Graef and Sumit Gupta and Serigne-Magueye Gueye and Nazik Hammad and Laila Hessissen and Andre M Ilbawi and Joyce Kambugu and Zisis Kozlakidis and Simon Manga and Lize Maree and Sulma I Mohammed and Susan Msadabwe and Miriam Mutebi and Annet Nakaganda and Ntokozo Ndlovu and Kingsley Ndoh and Jerry Ndumbalo and Mamsau Ngoma and Twalib Ngoma and Christian Ntizimira and Timothy R Rebbeck and Lorna Renner and Anya Romanoff and Fidel Rubagumya and Shahin Sayed and Shivani Sud and Hannah Simonds and Richard Sullivan and William Swanson and Verna Vanderpuye and Boateng Wiafe and David Kerr},
abstract = {Summary
In sub-Saharan Africa (SSA), urgent action is needed to curb a growing crisis in cancer incidence and mortality. Without rapid interventions, data estimates show a major increase in cancer mortality from 520 348 in 2020 to about 1 million deaths per year by 2030. Here, we detail the state of cancer in SSA, recommend key actions on the basis of analysis, and highlight case studies and successful models that can be emulated, adapted, or improved across the region to reduce the growing cancer crises. Recommended actions begin with the need to develop or update national cancer control plans in each country. Plans must include childhood cancer plans, managing comorbidities such as HIV and malnutrition, a reliable and predictable supply of medication, and the provision of psychosocial, supportive, and palliative care. Plans should also engage traditional, complementary, and alternative medical practices employed by more than 80% of SSA populations and pathways to reduce missed diagnoses and late referrals. More substantial investment is needed in developing cancer registries and cancer diagnostics for core cancer tests. We show that investments in, and increased adoption of, some approaches used during the COVID-19 pandemic, such as hypofractionated radiotherapy and telehealth, can substantially increase access to cancer care in Africa, accelerate cancer prevention and control efforts, increase survival, and save billions of US dollars over the next decade. The involvement of African First Ladies in cancer prevention efforts represents one practical approach that should be amplified across SSA. Moreover, investments in workforce training are crucial to prevent millions of avoidable deaths by 2030. We present a framework that can be used to strategically plan cancer research enhancement in SSA, with investments in research that can produce a return on investment and help drive policy and effective collaborations. Expansion of universal health coverage to incorporate cancer into essential benefits packages is also vital. Implementation of the recommended actions in this Commission will be crucial for reducing the growing cancer crises in SSA and achieving political commitments to the UN Sustainable Development Goals to reduce premature mortality from non-communicable diseases by a third by 2030.}
}
@article{GRUBEL2022101640,
title = {Dense Indoor Sensor Networks: Towards passively sensing human presence with LoRaWAN},
journal = {Pervasive and Mobile Computing},
volume = {84},
pages = {101640},
year = {2022},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2022.101640},
url = {https://www.sciencedirect.com/science/article/pii/S1574119222000700},
author = {Jascha Grübel and Tyler Thrash and Leonel Aguilar and Michal Gath-Morad and Didier Hélal and Robert W. Sumner and Christph Hölscher and Victor R. Schinazi},
keywords = {Dense Indoor Sensor Network, , Fused Twins, Human presence, Effective Signal Power},
abstract = {Sensors have become ubiquitous in buildings but are rarely connected to a network, and their potential to analyse the performance, use, and interaction with a building is not yet fully realised. In the coming years, we expect sensors in buildings to become part of the Internet of Things (IoT) and grow in numbers to form a Dense Indoor Sensor Network (DISN) that allows for unprecedented analysis of the performance, use, and interaction with buildings. Multiple technologies vie for leading this transformation. We explore Long Range Wide Area Network (LoRaWAN) as an alternative for creating indoor sensor networks that extends beyond its original long-distance communication purpose. For the present paper, we developed a DISN with 390 sensor nodes and four gateways and empirically evaluated its performance for two years. Our analysis of more than 86 million transmissions revealed that DISNs achieve a much lower distance coverage compared to estimations from previous research indicating that more gateways are required. In addition, the deployment of multiple gateways decreased the loss of transmissions due to environmental and network factors. Given the complexity of our system, we received few colliding concurrent messages, which demonstrates a gap between the projected requirements of LoRaWAN systems and the actual requirements of real-world applications given sufficient gateways. We also contribute to the modelling of transmissions with our comparison of attenuation models derived from multiple methodologies. Across all models, we find that robust coverage in an indoor environment can be maintained by placing a gateway every 30 m and every 5 floors. Finally, we also investigate the application of DISNs for the passive sensing and visualisation of human presence using a Digital Twin (DT) and a Fused Twins (FT) representation in Augmented Reality (AR). A passive sensing approach allows us to gather relevant data on human use of a building while still preserving privacy via the aggregation process. Immersive in situ visualisations in FT allow for new interactions and new forms of participation. We conclude that DISNs are already technologically feasible today and basing them on Low Power Wide Area Network (LPWAN) offers intriguing possibilities to reduce energy consumption, maintenance cost, and bandwidth use while also enabling new forms of human-building interaction.}
}
@article{KHAN2022100476,
title = {A journey towards fully autonomous driving - fueled by a smart communication system},
journal = {Vehicular Communications},
volume = {36},
pages = {100476},
year = {2022},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2022.100476},
url = {https://www.sciencedirect.com/science/article/pii/S2214209622000237},
author = {Manzoor Ahmed Khan and Hesham {El Sayed} and Sumbal Malik and Muhammad Talha Zia and Najla Alkaabi and Jalal Khan},
keywords = {Autonomous driving, 5G, Communication, Smart edges, Mobility trials},
abstract = {Autonomous driving solutions stretch over different disciplines and technologies e.g., sensors, communication, computation, machine learning, data analytic, etc., that need to be smartly stitched together for achieving end-to-end solutions. In this paper, we discuss the vision of level 5 autonomous vehicles (AV), relevant challenges, and analysis of the research literature. The paper focuses on the role of communication for connected and automated vehicles. Furthermore, the need for implanting intelligence in different architectural components and for various Autonomous Driving relevant operations is discussed. Challenges specific to communication, perception, service orchestration, service mobility, etc. are highlighted, relevant research literature analyzed, and potential solutions sketch is provided. We have also provided an overview of the large-scale proof-of-concepts around the globe that guide the readers towards studying different aspects of the autonomous driving and perspectives of stakeholders therein. The potential of Satellite-Air-Ground-Integrated-Networks (SAGINs) is studied for realizing the objectives of envisioned higher level autonomous driving. Based on the exhaustive analysis of the research work, this work concludes that there is a need for zooming out strategy, where the novel architectural, technological, and AI-based solution approaches are crafted by capturing the end-to-end system with the focus on most (if not all) stakeholders and their objectives.}
}
@article{WANG2022108870,
title = {Data-attention-YOLO (DAY): A comprehensive framework for mesoscale eddy identification},
journal = {Pattern Recognition},
volume = {131},
pages = {108870},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2022.108870},
url = {https://www.sciencedirect.com/science/article/pii/S003132032200351X},
author = {Xinning Wang and Xuegong Wang and Chong Li and Yuben Zhao and Peng Ren},
keywords = {Mesoscale eddy identification, Attention mechanism, Data-attention-based YOLO, One-stage detection},
abstract = {The accurate mesoscale eddy identification methods with deep learning framework depend on either single eddy characteristic from altimeter missions or multi-step eddy examination strategies, disregarding those indistinguishable features from multiple eddy data integration. In this article, we first propose a data-attention-based YOLO (DAY) to precisely recognize mesoscale eddies in the South China Sea (SCS), which can hierarchically unite multiple eddy attributes and efficiently predict eddies with one-step strategy involving detection and classification. It consists of two main components: heterogeneous eddy data integration module and dynamic attention detecting module for eddy identification. The data integration component empirically transforms the field of multi-source eddy data and propagates eddy labels through automatic labeling method, which sustains a good supply for our dynamic attention-base detecting network. To thoroughly identify mesoscale eddies based on spatio-temporal patterns, DAY efficiently learns the characteristics of mesoscale eddies with an improved one-step identification YOLO network. The comparative evaluation results demonstrate that DAY achieves 54% performance improvement over the state-of-the-art methods on single gray SLA data and outperforms two-stage detecting technique Faster R-CNN by 51%.}
}
@article{CRAMPON2022151,
title = {Machine-learning methods for ligand–protein molecular docking},
journal = {Drug Discovery Today},
volume = {27},
number = {1},
pages = {151-164},
year = {2022},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2021.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1359644621003974},
author = {Kevin Crampon and Alexis Giorkallos and Myrtille Deldossi and Stéphanie Baud and Luiz Angelo Steffenel},
keywords = {Molecular docking, Sampling, Scoring, Machine learning, Deep learning, Data representation},
abstract = {Artificial intelligence (AI) is often presented as a new Industrial Revolution. Many domains use AI, including molecular simulation for drug discovery. In this review, we provide an overview of ligand–protein molecular docking and how machine learning (ML), especially deep learning (DL), a subset of ML, is transforming the field by tackling the associated challenges.}
}
@article{LI2022131944,
title = {Investigating the spatiotemporal changes and driving factors of nighttime light patterns in RCEP Countries based on remote sensed satellite images},
journal = {Journal of Cleaner Production},
volume = {359},
pages = {131944},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.131944},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622015530},
author = {Jie Li and Suling He and Jinliang Wang and Weifeng Ma and Hui Ye},
keywords = {Nighttime light (NTL), Carbon emission, Mann-Kendall test, Hurst analysis, The regional comprehensive economic partnership (RCEP)},
abstract = {The Regional Comprehensive Economic Partnership (RCEP) agreement signed in November 2020 is the world's largest and greatest potential free trade area. It was officially enforced on January 1, 2022, which attracted great worldwide attention. The RCEP advocates for the development of the low-carbon economy but lacks effective monitoring methods for socioeconomic conditions and carbon emissions. Nighttime light (NTL) images can objectively reflect socioeconomic status and carbon emission potential. However, most studies focused only on consistency correction for multi-source NTL data without deeply analyzing NTL dynamics. An in-depth analysis of the NTL change in the RCEP region is necessary and will strongly facilitate the strategic deployment of a low-carbon economy in RCEP countries. Sen's slope estimator, the Mann-Kendall trend test, the Mann-Kendall mutation test, and Hurst analysis were adopted to analyze the spatiotemporal changes of NTL in the past and future, and gray relational analysis was applied to explore driving factors. The results showed that (1) RCEP's NTL became brighter from 2000 to 2018, and the total NTL amount in 2018 was 3.27 times that in 2000. NTL in all countries except Japan showed an increasing trend to varying degrees, and this trend was more pronounced in developing countries. The maximum increase amount and growth rate were in China and Vietnam, respectively. (2) Areas where NTL showed an increasing trend in the past accounted for 76.67% of the NTL zones, and the areas where predicted to be brighter in the future accounted for 63.87%. These regions were generally clustered in developed urban zones. However, most Japanese cities have observed darkening trends. (3) The relational grade between NTL and all socioeconomic factors in the RECP region was greater than 0.6, and construction land expansion was the most direct and profound driver. Compared with that in developed countries, NTL in developing countries was more closely related to socioeconomic factors.}
}
@article{ALASSAF20222849,
title = {Improving Sentiment Analysis of Arabic Tweets by One-way ANOVA},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {6, Part A},
pages = {2849-2859},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S1319157820305176},
author = {Manar Alassaf and Ali Mustafa Qamar},
keywords = {Sentiment analysis, One-way ANOVA, Arabic tweets, Feature selection, Machine learning, High dimensionality},
abstract = {Social media is an indispensable necessity for modern life. As a result, it is full of people’s opinions, emotions, ideas, and attitudes, whether positive or negative. This abundance of views creates many opportunities for applying sentiment analysis to the education sector, which reflects how countries and cultures develop. In this research, a real-world Twitter dataset was collected, containing approximately 8144 tweets related to Qassim University, Saudi Arabia. The main aim of this experimental study was to explore the possibility of using a one-way analysis of variance (ANOVA) as a feature selection method to considerably reduce the number of features when classifying opinions conveyed through Arabic tweets. The primary motivation for this research was that no previous studies had examined one-way ANOVA comprehensively to tackle the curse of dimensionality and to enhance classification performance in sentiment analysis for Arabic tweets. Therefore, various experiments were conducted to investigate the effects of one-way ANOVA and to select important features concerning the performance of different supervised machine learning classifiers. Support Vector Machine and Naïve Bayes achieved the best results with one-way ANOVA as compared to the baseline experimental results in the collected dataset. Furthermore, the differences between all results have been statistically analyzed in this study. As further evidence, one-way ANOVA with Support Vector Machine represented an excellent combination across different Arabic benchmark datasets, with its results outperforming other studies.}
}
@article{KIM2022103315,
title = {Privacy-preserving mechanisms for location privacy in mobile crowdsensing: A survey},
journal = {Journal of Network and Computer Applications},
volume = {200},
pages = {103315},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103315},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521003039},
author = {Jong Wook Kim and Kennedy Edemacu and Beakcheol Jang},
keywords = {Mobile crowdsensing, Location privacy, Privacy, Security},
abstract = {With the advancement in communication techniques and sensor technologies, mobile crowdsensing (MCS)—one of the most successful applications of crowdsourcing—has recently become a powerful tool to solve complex and scalable sensing problems. Generally, MCS is a location-aware crowdsourcing technique in which participating workers must physically move to a specific location to complete tasks. Hence, workers must disclose information regarding their current true location to service providers. However, location information may contain sensitive data; therefore, most workers are not comfortable—or are even reluctant—to provide their exact location information to service providers because of privacy concerns. This is perceived as the most significant challenge faced in MCS. Thus, guaranteeing location privacy is essential for attracting more participants to actively participate in MCS. Accordingly, extensive studies have been conducted in the past few years to protect the location privacy of participating workers in MCS. In this study, we comprehensively survey the state-of-the-art mechanisms for protecting the location privacy of workers in MCS. We divide the location protection mechanisms into three categories depending on the nature of their algorithm and compare them from the viewpoints of architecture, privacy, computational overhead, and utility. Moreover, we discuss certain promising future research directions to spur further research in this area.}
}
@article{WAGELE2022105,
title = {Towards a multisensor station for automated biodiversity monitoring},
journal = {Basic and Applied Ecology},
volume = {59},
pages = {105-138},
year = {2022},
issn = {1439-1791},
doi = {https://doi.org/10.1016/j.baae.2022.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1439179122000032},
author = {J.Wolfgang Wägele and Paul Bodesheim and Sarah J. Bourlat and Joachim Denzler and Michael Diepenbroek and Vera Fonseca and Karl-Heinz Frommolt and Matthias F. Geiger and Birgit Gemeinholzer and Frank Oliver Glöckner and Timm Haucke and Ameli Kirse and Alexander Kölpin and Ivaylo Kostadinov and Hjalmar S. Kühl and Frank Kurth and Mario Lasseck and Sascha Liedke and Florian Losch and Sandra Müller and Natalia Petrovskaya and Krzysztof Piotrowski and Bernd Radig and Christoph Scherber and Lukas Schoppmann and Jan Schulz and Volker Steinhage and Georg F. Tschan and Wolfgang Vautz and Domenico Velotto and Maximilian Weigend and Stefan Wildermann},
keywords = {Biodiversity monitoring, AMMOD, Bioacoustic monitoring, Visual monitoring, Computer vision, Metabarcoding, Volatile organic compounds, Pattern recognition, Computer science, Artificial intelligence},
abstract = {Rapid changes of the biosphere observed in recent years are caused by both small and large scale drivers, like shifts in temperature, transformations in land-use, or changes in the energy budget of systems. While the latter processes are easily quantifiable, documentation of the loss of biodiversity and community structure is more difficult. Changes in organismal abundance and diversity are barely documented. Censuses of species are usually fragmentary and inferred by often spatially, temporally and ecologically unsatisfactory simple species lists for individual study sites. Thus, detrimental global processes and their drivers often remain unrevealed. A major impediment to monitoring species diversity is the lack of human taxonomic expertise that is implicitly required for large-scale and fine-grained assessments. Another is the large amount of personnel and associated costs needed to cover large scales, or the inaccessibility of remote but nonetheless affected areas. To overcome these limitations we propose a network of Automated Multisensor stations for Monitoring of species Diversity (AMMODs) to pave the way for a new generation of biodiversity assessment centers. This network combines cutting-edge technologies with biodiversity informatics and expert systems that conserve expert knowledge. Each AMMOD station combines autonomous samplers for insects, pollen and spores, audio recorders for vocalizing animals, sensors for volatile organic compounds emitted by plants (pVOCs) and camera traps for mammals and small invertebrates. AMMODs are largely self-containing and have the ability to pre-process data (e.g. for noise filtering) prior to transmission to receiver stations for storage, integration and analyses. Installation on sites that are difficult to access require a sophisticated and challenging system design with optimum balance between power requirements, bandwidth for data transmission, required service, and operation under all environmental conditions for years. An important prerequisite for automated species identification are databases of DNA barcodes, animal sounds, for pVOCs, and images used as training data for automated species identification. AMMOD stations thus become a key component to advance the field of biodiversity monitoring for research and policy by delivering biodiversity data at an unprecedented spatial and temporal resolution.}
}
@article{WERLE2022102507,
title = {Competitor identification: A review of use cases, data sources, and algorithms},
journal = {International Journal of Information Management},
volume = {65},
pages = {102507},
year = {2022},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2022.102507},
url = {https://www.sciencedirect.com/science/article/pii/S026840122200038X},
author = {Marcel Werle and Sven Laumer},
keywords = {Competitor Identification, Decision Support Systems, Strategic Management, Data mining, Artificial Intelligence},
abstract = {Businesses have to deal with and survive in competitive, constantly changing landscapes due to new entrants and exogenous shocks like the COVID-19 pandemic. Furthermore, decision-makers have to deal with staggering amounts of data produced in their corporate environment. Hence, research and practice have developed hybrid socio-technical systems of data mining and expert knowledge to identify competitors early on. To better understand the ergonomic design of such systems and how to integrate them in strategic management driven by artificial intelligence, we engaged in a systematic literature review to summarize the field and guide future research. We identified use cases, data source types, and algorithms that have been developed in 40 publications between 2002 and 2019. We found that existing approaches neglect to identify indirect and potential competitors at the periphery of a company’s vision. Such a blind spot exposes companies to increased risks of disruption, given that disruptive change often starts in the form of weak signals. Furthermore, we recommend using artificial intelligence to advance search strategies, allow document collection updates, and harmonize multiple data source types.}
}
@article{RAY20226949,
title = {A review on 6G for space-air-ground integrated network: Key enablers, open challenges, and future direction},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {9},
pages = {6949-6976},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002172},
author = {Partha Pratim Ray},
keywords = {6G, Space-air-ground integrated network, Next-generation network augmentation, New network design},
abstract = {Space-air-ground integrated network (SAGIN) is still in nascent stage of design. Despite of several key insights onto the augmentation of terrestrial, aerial and satellite systems, SAGIN ecosystem is yet not mature enough to survive into the realty. More agility, robustness, flexibility, and scalability are required to conform to optimum standard of abstraction. As 5G is at the verge of technology domain, this is high time when we should keep our focus on the next-generation advanced 6G technology to cater the issues of existing SAGIN ecosystem. In this article, we envisage a clear vision on how 6G can improve the current scenario of the SAGIN infrastructure will some value-added services. We firstly, present basics behind the SAGIN and discuss key concepts of the 6G. Secondly, we review key technologies related to the unmanned aerial vehicle (UAV) and satellite-based communications. Thirdly, we describe key enablers of the 6G-enbled SAGIN i.e., 6G-SAGIN. Fourthly, we present the UAV-as-a-service to augment the comprehension of 6G-SAGIN. Fifthly, we extend the orientation of 6G-SAGIN toward elemental design aspects. Finally, we depict key open research challenges and prescribe some future direction.}
}
@article{BEHERA2022685,
title = {Cognitive computing based ethical principles for improving organisational reputation: A B2B digital marketing perspective},
journal = {Journal of Business Research},
volume = {141},
pages = {685-701},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.11.070},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321008778},
author = {Rajat Kumar Behera and Pradip Kumar Bala and Nripendra P. Rana and Hatice Kizgin},
keywords = {Cognitive computing, B2B digital marketing, Organisational effectiveness, Organisational reputation, Ethics},
abstract = {Cognitive computing is ushering in the fourth industrial revolution through its promises of improved accuracy, scalability and personalisation. Therefore, business-to-business (B2B) organisations are wavering in the decision for adoption into their digital marketing initiatives. However, embracing moral rules and/or moral judgments in their digital marketing innovation can be challenging, since making mistakes could damage reputations. Therefore, this study applies the ethical principles of cognitive computing in B2B digital marketing business-centric ethical challenges. An integrated theoretical framework grounded on multidisciplinary studies is proposed. The primary data were collected from 300 respondents within B2B businesses. The results of this research led to the conclusion that good ethical practices are essential for the improvement of both organisational effectiveness and organisational reputation. Increased organisational reputation delivers a competitive edge in fast-growing marketplaces. B2B businesses need to look for proactive ways to achieve continuous improvement.}
}
@article{WANG20229,
title = {A comprehensive review for wind, solar, and electrical load forecasting methods},
journal = {Global Energy Interconnection},
volume = {5},
number = {1},
pages = {9-30},
year = {2022},
issn = {2096-5117},
doi = {https://doi.org/10.1016/j.gloei.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2096511722000226},
author = {Han Wang and Ning Zhang and Ershun Du and Jie Yan and Shuang Han and Yongqian Liu},
keywords = {Wind power, Solar power, Electrical load, Forecasting, Numerical Weather Prediction, Correlation},
abstract = {Wind power, solar power, and electrical load forecasting are essential works to ensure the safe and stable operation of the electric power system. With the increasing permeability of new energy and the rising demand response load, the uncertainty on the production and load sides are both increased, bringing new challenges to the forecasting work and putting forward higher requirements to the forecasting accuracy. Most review/survey papers focus on one specific forecasting object (wind, solar, or load), a few involve the above two or three objects, but the forecasting objects are surveyed separately. Some papers predict at least two kinds of objects simultaneously to cope with the increasing uncertainty at both production and load sides. However, there is no corresponding review at present. Hence, our study provides a comprehensive review of wind, solar, and electrical load forecasting methods. Furthermore, the survey of Numerical Weather Prediction wind speed/irradiance correction methods is also included in this manuscript. Challenges and future research directions are discussed at last.}
}
@article{HOUWEN2022,
title = {Comprehensive review of publicly available colonoscopic imaging databases for artificial intelligence research: availability, accessibility and usability},
journal = {Gastrointestinal Endoscopy},
year = {2022},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2022.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S0016510722019526},
author = {Britt B.S.L. Houwen and Karlijn J. Nass and Jasper L.A. Vleugels and Paul Fockens and Yark Hazewinkel and Evelien Dekker},
keywords = {artificial intelligence, machine learning, colonoscopy, colorectal cancer, colorectal polyps},
abstract = {ABSTRACT
Background and aims
Publicly available databases containing colonoscopic imaging data are valuable resources for artificial intelligence (AI) research. Currently, little is known regarding the available number and content of these databases. This review aimed to describe the availability, accessibility and usability of publicly available colonoscopic imaging databases, focusing on polyp detection, polyp characterization and quality of colonoscopy.
Methods
A systematic literature search was performed in MEDLINE and Embase to identify AI-studies describing publicly available colonoscopic imaging datasets published after 2010. Second, a targeted search using Google’s Dataset Search, Google Search, GitHub and Figshare was done to identify datasets directly. Datasets were included if they contained data about polyp detection, polyp characterization or quality of colonoscopy. To assess accessibility of datasets the following categories were defined: open access, open access with barriers and regulated access. To assess the potential usability of the included datasets, essential details of each dataset were extracted using a checklist derived from the CLAIM-checklist.
Results
We identified 22 datasets with open access, 3 datasets open access with barriers and 15 datasets with regulated access. The 22 open access databases containing 19,463 images and 952 videos. Nineteen of these databases focused on polyp detection, localization and/or segmentation, six on polyp characterization and three on quality of colonoscopy. Only half of these databases have been used by other researcher to develop, train or benchmark their AI-system. Although technical details were in general well-reported, important details such as polyp and patient demographics and the annotation process were underreported in almost all databases.
Conclusion
This review provides greater insight on public availability of colonoscopic imaging databases for AI-research. Incomplete reporting of important details limits the ability of researchers to assess the usability of the current databases.}
}
@article{EMAMI202249,
title = {A review of the critical elements and development of real-world connected vehicle testbeds around the world},
journal = {Transportation Letters},
volume = {14},
number = {1},
pages = {49-74},
year = {2022},
issn = {1942-7867},
doi = {https://doi.org/10.1080/19427867.2020.1759852},
url = {https://www.sciencedirect.com/science/article/pii/S1942786722004088},
author = {Azadeh Emami and Majid Sarvi and Saeed {Asadi Bagloee}},
keywords = {Connected Vehicle, Intelligent Transportation System (ITS), testbeds, multimodality, communication platform},
abstract = {ABSTRACT
Concerning the critical role of Intelligent Transportation System (ITS) in tackling the problem of traffic congestion, and enhancing the safety, mobility and sustainability of the transport network, this paper provides a comprehensive review of recent developments in Connected Vehicle (CV) technology, its features and terminology. The real-world implementation of the CV technologies can result in a better understanding of the practical and technical issues. Given the technical and conceptual challenges, as well as novelty factors associated with CVs, many CV pilot studies around the world are reviewed, and their findings are summarized. The paper contributes to the literature by reviewing the characteristics, communication platform, multimodality, size and type of study areas of the pilot CV testbeds across the world. This research also paves the way for the better development of CV technology by comparing and discussing the pros and cons of the existing CV pilot testbeds. Moreover, we have discussed the evaluation plans and the advantages and disadvantages of different testbeds. Besides, as a main component of the CV system, the traffic signal control algorithms, as well as transit signal priority in a CV ecosystem, are also reviewed. Based on our findings, the real-time data obtained from the CV system could result in a better adjustment of traffic signal parameters which consequently enhance the traffic regulation in the network (say up to 30% in terms of travel time in comparison with an actuated coordinated traffic signal). However, a major criticism of the existing traffic signal strategies in a CV system is that they do not utilize the maximum capability of the CV system (V2 V, V2I and I2I communications).}
}
@article{YOHANANDHAN2022107721,
title = {A holistic review on Cyber-Physical Power System (CPPS) testbeds for secure and sustainable electric power grid – Part – II: Classification, overview and assessment of CPPS testbeds},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {137},
pages = {107721},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107721},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521009479},
author = {Rajaa Vikhram Yohanandhan and Rajvikram Madurai Elavarasan and Rishi Pugazhendhi and Manoharan Premkumar and Lucian Mihet-Popa and Vladimir Terzija},
keywords = {Critical infrastructure protection, Cyber attack, Cyber-physical power system testbed, Cyber security, Real-time testbed, Smart grid, Sustainability},
abstract = {Cyber-physical power systems (CPPS) are interconnected architectures that interact with the physical power system environment by utilizing communication, control, and computing resources. Enterprise, industries, and critical infrastructure rely on CPPS. As a result of their critical importance, they are prime targets for cyberattacks aimed at disrupting their operations. CPPS are mission-critical, attacks on them can have disastrous consequences. CPPS security can be improved by utilizing testbed capabilities to replicate power system operations, discover threats, develop sustainable cybersecurity solutions, and evaluate grid operation in physical fault-induced or cyberattack scenarios. This Part-II paper reviews the CPPS testbeds in the view of the testbed type, targeted research area, CPPS domain, and communication infrastructure with the fusion of physical and cyber systems. Furthermore, this review gives an outline, framework, and application-based assessment of various industry and institutional testbeds. The design process of CPPS testbeds is reviewed first in this paper(Part-II), followed by description of the classification of CPPS testbeds for cyberattacks and sustainable cybersecurity analysis in CPPS. A brief overview of CPPS testbeds in various academic institutions, R&D laboratories, and industries are provided and each testbed is evaluated using the eleven proposed assessment criteria. Finally, the current issues and future research directions for CPPS testbeds to develop a secure and sustainable electric power grid are discussed. The Part-I paper reviewed the major research areas in CPPS, the importance of cyberattack testbeds, and long-term cybersecurity analysis in CPPS, as well as the NIST framework for CPS, CPPS domains and research areas.}
}
@article{OGIE2022102783,
title = {Social media use in disaster recovery: A systematic literature review},
journal = {International Journal of Disaster Risk Reduction},
volume = {70},
pages = {102783},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.102783},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922000024},
author = {R.I. Ogie and S. James and A. Moore and T. Dilworth and M. Amirghasemi and J. Whittaker},
keywords = {Disaster recovery, Social media, Mental health, Solidarity, Donations, Financial support},
abstract = {Studies on the role of social media in disaster management have so far focused mainly on early phases of the disaster response process. Published evidence regarding the scope and effectiveness of social media use in the recovery phase is limited but promising. There is currently no study that provides a comprehensive picture of the current research landscape that can inform different groups who need to capitalise on social media for disaster recovery. The present study aims to address this research gap by conducting a systematic literature review of social media use in disaster recovery. The review analyses the relevant studies to identify any temporal variations in research activity, the social media platforms most frequently used in disaster recovery, their patterns of use by type of disaster as well as the geographical locations where the studies have focused. Importantly, the paper identifies and summarises research findings relating to social media use in various aspects of disaster recovery, including (1) donations and financial support, (2) solidarity and social cohesion, (3) post-disaster reconstruction and infrastructure services, (4) socioeconomic and physical wellbeing, (5) information support, (6) mental health and emotional support, and (7) business & economic activities. We envisage that this comprehensive review will support the disaster risk reduction community with the requisite knowledge to better explore social media for disaster recovery. Similarly, future research may find the study helpful for understanding the state of knowledge and identifying research gaps around social media use for disaster recovery.}
}
@article{VANDERSLOOT2022105716,
title = {Deepfakes: regulatory challenges for the synthetic society},
journal = {Computer Law & Security Review},
volume = {46},
pages = {105716},
year = {2022},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2022.105716},
url = {https://www.sciencedirect.com/science/article/pii/S0267364922000632},
author = {Bart {van der Sloot} and Yvette Wagensveld},
keywords = {Deepfake, synethetic media, post-truth era, Privacy, freedom of expression, rule of law, democracy, social equality, fake news, non-consensual fake porn},
abstract = {With the rise of deepfakes and synthetic media, the question as to what is real and what is not will become increasingly important and politized. Deepfakes can be used to spread fake news, influence elections, introduce highly realistic fake evidence in courts and make fake porno movies. Each of these applications potentially has a big impact on society, social relationships, democracy and the rule of law. The question this article shall assess is whether the current regulatory regime suffices to address these potential harms and if not, which additional rules and principles should be adopted. It will discuss several potential amendments to the privacy and data protection regime, limitations to the freedom of expression and ex ante rules on the distribution of use of deepfake-technologies.}
}
@article{OLAWUMI2022103720,
title = {Automating the modular construction process: A review of digital technologies and future directions with blockchain technology},
journal = {Journal of Building Engineering},
volume = {46},
pages = {103720},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.103720},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221015783},
author = {Timothy O. Olawumi and Daniel W.M. Chan and Stephen Ojo and Michael C.H. Yam},
keywords = {Blockchain technology, Digital tools, Modular integrated construction, Prefabrication, Technologies},
abstract = {Modular integrated construction (MiC) method has come to limelight in recent years due to its enormous potentials. Although several digital tools and technologies (DTT) have been employed in MiC projects, no previous research study has critically reviewed and analysed their implementation in MiC projects. The current study addresses this gap using a three-tier research approach– data curation, science mapping, and systematic analysis to evaluate modular construction research studies. The findings revealed minimal application of DTT in the MiC prefab transportation phase and the potentiality of blockchain and other integrated DTT for use in MiC projects. Globally, Canada, China, and the USA are the leading countries that have applied DTT in MiC projects. Also, simulation, building information modelling (BIM), and optimization algorithms are the most frequently deployed DTT in modular construction. This study has provided valuable insights into the digital technologies adopted in MiC projects and potential areas for its future use in modular construction.}
}
@article{ZHANG2022133,
title = {A fault diagnosis method for wind turbines with limited labeled data based on balanced joint adaptive network},
journal = {Neurocomputing},
volume = {481},
pages = {133-153},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.01.067},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222000868},
author = {Guangyao Zhang and Yanting Li and Wenbo Jiang and Lianjie Shu},
keywords = {Wind turbine, Fault diagnosis, Transfer learning, Domain adaptation, SCADA, MMD, LSTM},
abstract = {Traditional machine learning or deep learning relies on a sufficient amount of labeled data for the training of fault diagnosis models. However, for new wind farms, insufficient data and limited labels hinder the establishment of such models. In order to cope with these two challenges, we proposed a new domain adaptive method for wind turbine fault diagnosis: balanced joint adaptive network (BJAN), which can transfer wind turbine data from other wind farms to the target new wind farm. In this method, we proposed a new pseudo-label prediction method that combines the sub-domain majority voting and overall iterations (SMV-I) to label the unlabeled data. In addition, BJAN uses long short-term memory model (LSTM) to replace common convolutional neural network (CNN) as the feature extraction module to improve diagnosis efficiency. Moreover, we also proposed a new distributed adaptive distance for BJAN: balanced joint maximum mean discrepancy (BJMMD), which can balance the data of different states during the distributed adaptive process to improve diagnostic accuracy. Numerical experiments with real wind turbine data in three wind farms not only show that the proposed SMV-I has excellent pseudo-label prediction performance, but also verify that the proposed fault diagnosis model BJAN has higher diagnostic accuracy and efficiency.}
}
@article{YANG2022103803,
title = {AutoDefect: Defect text classification in residential buildings using a multi-task channel attention network},
journal = {Sustainable Cities and Society},
volume = {80},
pages = {103803},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103803},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722001329},
author = {Donguk Yang and Byeol Kim and Sang Hyo Lee and Yong Han Ahn and Ha Young Kim},
keywords = {Sustainable building, Defect classification, Multi-task learning, Deep learning, Attention mechanism, Natural language processing},
abstract = {The sustainability of a building can be ensured through effective maintenance. Effective defect management, which is essential for maintaining the performance and longevity of buildings, requires regular defect inspections. Such inspections are expensive and time-consuming, traditionally taking the form of unstructured textual data. Classifying the collected data is complex, potentially leading to errors. A systematic classification system that considers a wide range of characteristics, including work type, defect location, defect element and defect type, is urgently needed. We propose a new automated defect text classification system (AutoDefect) based on a convolutional neural network (CNN) and natural language processing (NLP) using hierarchical two-stage encoders. A variant channel attention mechanism (the text squeeze-and-excitation block) is incorporated for one-dimensional CNN-based text modeling that extracts robust features for each encoder to improve classification performance. Testing the model on Korean textual defect data, AutoDefect outperformed three recent NLP models, BERT, ELECTRA and GPT-2, and was significantly more cost-effective, dramatically reducing the time required for defect management and minimizing human error.}
}
@article{ROBSON2022105118,
title = {Mining real-world high dimensional structured data in medicine and its use in decision support. Some different perspectives on unknowns, interdependency, and distinguishability},
journal = {Computers in Biology and Medicine},
volume = {141},
pages = {105118},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105118},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521009124},
author = {Barry Robson and S. Boray and J. Weisman},
keywords = {Real world data, Assumptions, Approximations, Unknowns, Interdependency, Distinguishability, Coherence, Inference net, Bayes' rule, Bayes net, Hyperbolic Dirac net, Clinical decision support},
abstract = {Synopsis
There are many difficulties in extracting and using knowledge for medical analytic and predictive purposes from Real-World Data, even when the data is already well structured in the manner of a large spreadsheet. Preparative curation and standardization or “normalization” of such data involves a variety of chores but underlying them is an interrelated set of fundamental problems that can in part be dealt with automatically during the datamining and inference processes. These fundamental problems are reviewed here and illustrated and investigated with examples. They concern the treatment of unknowns, the need to avoid independency assumptions, and the appearance of entries that may not be fully distinguished from each other. Unknowns include errors detected as implausible (e.g., out of range) values that are subsequently converted to unknowns. These problems are further impacted by high dimensionality and problems of sparse data that inevitably arise from high-dimensional datamining even if the data is extensive. All these considerations are different aspects of incomplete information, though they also relate to problems that arise if care is not taken to avoid or ameliorate consequences of including the same information twice or more, or if misleading or inconsistent information is combined. This paper addresses these aspects from a slightly different perspective using the Q-UEL language and inference methods based on it by borrowing some ideas from the mathematics of quantum mechanics and information theory. It takes the view that detection and correction of probabilistic elements of knowledge subsequently used in inference need only involve testing and correction so that they satisfy certain extended notions of coherence between probabilities. This is by no means the only possible view, and it is explored here and later compared with a related notion of consistency.}
}
@article{PENG2022336,
title = {Global estimates of 500 m daily aerodynamic roughness length from MODIS data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {183},
pages = {336-351},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621003130},
author = {Zhong Peng and Ronglin Tang and Yazhen Jiang and Meng Liu and Zhao-Liang Li},
keywords = {Aerodynamic roughness length, Machine learning, MODIS, Evapotranspiration},
abstract = {Aerodynamic roughness length (z0m) is a key parameter in the characterization of land surface turbulent heat fluxes and widely used in many surface and climate-related process models. The global products of time series of z0m at finer spatio-temporal resolution, however, have never been publicly available. Here we presented a practical method for global estimates of 500 m daily z0m with a combination of machine learning techniques, wind profile equation, observations from 273 sites and MODIS remote sensing data. Results showed that the random forest (RF) model outperformed the deep neural network (DNN) and convolutional neural network (CNN) models, and it could well reproduce the magnitude and temporal variability of daily z0m at almost all sites for all land cover types. In the validation of the RF-estimated daily z0m with the in-situ observations, the root mean square error (RMSE) varied between 0.02 m and 0.09 m, the mean absolute error (MAE) varied between 0.01 m and 0.05 m and the coefficient of determination (R2) was 1 for medium-to-high canopy shrublands, savannas and forests; for short-canopy croplands, grasslands and wetlands, the RMSE and MAE were 0.02 m and 0.01 m, respectively, and the R2 varied between 0.94 and 1. Compared to the Climate Forecast System Version 2 (CFSv2, 0.3°/monthly) and ECMWF Reanalysis v5 (ERA5, 0.25°/monthly) products in 2019, the RF-estimated z0m was found to have the similar global spatial pattern but significantly larger temporal variability, and it also showed a higher and lower global mean of z0m over forests and non-forests, respectively. The RF-estimated z0m displayed a higher temporal variability but a similar global spatial pattern of this variability compared to the CFSv2, whereas the ERA5 z0m product exhibited almost no temporal variability except for grasslands and croplands. This study is beneficial for improving the simulation of the momentum, water and energy transfer between land and atmosphere and helping boost the development of high-resolution land surface models and Earth system models.}
}
@article{DALIBOR2022111361,
title = {A Cross-Domain Systematic Mapping Study on Software Engineering for Digital Twins},
journal = {Journal of Systems and Software},
volume = {193},
pages = {111361},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111361},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000917},
author = {Manuela Dalibor and Nico Jansen and Bernhard Rumpe and David Schmalzing and Louis Wachtmeister and Manuel Wimmer and Andreas Wortmann},
keywords = {Software Engineering, Digital Twins, Manufacturing, Industry 4.0},
abstract = {Digital Twins are currently investigated as the technological backbone for providing an enhanced understanding and management of existing systems as well as for designing new systems in various domains, e.g., ranging from single manufacturing components such as sensors to large-scale systems such as smart cities. Given the diverse application domains of Digital Twins, it is not surprising that the characterization of the term Digital Twin, as well as the needs for developing and operating Digital Twins are multi-faceted. Providing a better understanding what the commonalities and differences of Digital Twins in different contexts are, may allow to build reusable support for developing, running, and managing Digital Twins by providing dedicated concepts, techniques, and tool support. In this paper, we aim to uncover the nature of Digital Twins based on a systematic mapping study which is not limited to a particular application domain or technological space. We systematically retrieved a set of 1471 unique publications of which 356 were selected for further investigation. In particular, we analyzed the types of research and contributions made for Digital Twins, the expected properties Digital Twins have to fulfill, how Digital Twins are realized and operated, as well as how Digital Twins are finally evaluated. Based on this analysis, we also contribute a novel feature model for Digital Twins from a software engineering perspective as well as several observations to further guide future software engineering research in this area.}
}
@article{YAHYA2022102071,
title = {Applied imagery pattern recognition for photovoltaic modules’ inspection: A review on methods, challenges and future development},
journal = {Sustainable Energy Technologies and Assessments},
volume = {52},
pages = {102071},
year = {2022},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2022.102071},
url = {https://www.sciencedirect.com/science/article/pii/S2213138822001230},
author = {Zefri Yahya and Sebari Imane and Hajji Hicham and Aniba Ghassane and El {Bouchini-Idrissi Safia}},
keywords = {Photovoltaics, Imagery, Digital image processing, Machine learning, Deep learning},
abstract = {We present a literature review of Applied Imagery Pattern Recognition (AIPR) for the inspection of photovoltaic (PV) modules under the main used spectra: (1) true-color RGB, (2) long-wave infrared (LWIR), and (3) electroluminescence-based short-wave infrared (SWIR). Three sequentially linked building blocks underpin this work. The first overviews reference guidelines of image acquisition and the main detectable defect patterns under each spectrum. It also provides key insights regarding the implementation of Unmanned Aerial Vehicles (UAVs) to acquire imagery, especially from a photogrammetric perspective. The second block presents various image pre-processing steps used to prepare inspection-ready datasets. These comprise radiometric correction, segmentation and edge extraction, geometric correction and cell clipping. The third surveys defect detection and classification through digital image processing and machine/deep learning techniques. We elaborate an in-depth topic discussion that, in parallel: highlights the main related challenges, provides core guidelines for AIPR-based PV inspection workflows, and suggests key research avenues for future studies. This review synthesizes the recent advances of the body knowledge. It also constitutes an insightful reference for professionals and academics within the PV operations and maintenance field who are considering the possibilities that digital imagery can offer.}
}