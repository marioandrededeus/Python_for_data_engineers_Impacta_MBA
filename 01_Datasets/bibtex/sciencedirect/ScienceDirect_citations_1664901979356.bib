@article{KIBRIA2022107672,
title = {The severity prediction of the binary and multi-class cardiovascular disease − A machine learning-based fusion approach},
journal = {Computational Biology and Chemistry},
volume = {98},
pages = {107672},
year = {2022},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2022.107672},
url = {https://www.sciencedirect.com/science/article/pii/S1476927122000524},
author = {Hafsa Binte Kibria and Abdul Matin},
keywords = {Artificial neural network, Random forest, Decision tree, Adaboost, Support vector machine, Logistic regression, Cardiovascular disease, Weighted score fusion},
abstract = {In today’s world, a massive amount of data is available in almost every sector. This data has become an asset as we can use this enormous amount of data to find information. Mainly health care industry contains many data consisting of patient and disease-related information. By using the machine learning technique, we can look for hidden data patterns to predict various diseases. Recently CVDs, or cardiovascular disease, have become a leading cause of death around the world. The number of death due to CVDs is frightening. That is why many researchers are trying their best to design a predictive model that can save many lives using the data mining model. In this research, some fusion models have been constructed to diagnose CVDs along with its severity. Machine learning(ML) algorithms like artificial neural network, SVM, logistic regression, decision tree, random forest, and AdaBoost have been applied to the heart disease dataset to predict disease. Randomoversampler only for multi-class classification to make the imbalanced dataset balanced. To improve the performance of classification, a weighted score fusion approach was taken. At first, the models were trained. After training, two algorithms’ decision was combined using a weighted sum rule. A total of three fusion models have been developed from the six ML algorithms. The results were promising in the performance parameter. The proposed approach has been experimented with different test training ratios for binary and multiclass classification problems, and for both of them, the fusion models performed well. The highest accuracy for multiclass classification was found as 75%, and it was 95% for binary.}
}
@article{JACOBS2022114552,
title = {Cultural reproduction of mental illness stigma and stereotypes},
journal = {Social Science & Medicine},
volume = {292},
pages = {114552},
year = {2022},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2021.114552},
url = {https://www.sciencedirect.com/science/article/pii/S0277953621008844},
author = {Susan Jacobs and Joseph Quinn},
keywords = {Stigma, Mental illness, Stereotypes, Cultural schema, Cultural transmission, Affect control theory},
abstract = {This study investigates how schemas and stereotypes about individuals with mental illness shape how information is transmitted between people. Mental illnesses are highly stigmatized identities, and prior work illustrates the persistence of mental illness stigma, despite public health efforts aimed at increasing awareness of the biological origins of mental illness (Pescosolido et al., 2010). Recent work has also demonstrated the utility of combining cultural cognition with social psychological theories of cultural meaning to investigate how stereotypes are transmitted through secondhand narratives (Hunzaker 2014, 2016). We connect this social psychological work with medical sociological literature on mental illness stigmas and propose that stereotypes function as cultural schemas that shape the way stories are remembered and retold about individuals with a mental illness. We then conduct a narrative transmission study to test this proposal, using schizophrenia as a case of interest. Consistent with prior work, we find that individuals who retell a story about a person with schizophrenia alter the narrative so that it becomes more consistent with stereotypes about individuals with schizophrenia. We also find that stereotype-inconsistent information is more likely to be transformed to align with culturally shared beliefs about schizophrenia. The findings extend prior work on how bias shapes the reproduction of mental illness stereotypes, and demonstrate how socially learned cultural beliefs can reinforce stereotypes, biases and stigma about mental illness.}
}
@article{WEI2022112775,
title = {Full-coverage mapping and spatiotemporal variations of ground-level ozone (O3) pollution from 2013 to 2020 across China},
journal = {Remote Sensing of Environment},
volume = {270},
pages = {112775},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112775},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721004958},
author = {Jing Wei and Zhanqing Li and Ke Li and Russell R. Dickerson and Rachel T. Pinker and Jun Wang and Xiong Liu and Lin Sun and Wenhao Xue and Maureen Cribb},
keywords = {Ozone, Air pollution, Ensemble learning, COVID-19, China},
abstract = {Ozone (O3) is an important trace and greenhouse gas in the atmosphere, posing a threat to the ecological environment and human health at the ground level. Large-scale and long-term studies of O3 pollution in China are few due to highly limited direct ground and satellite measurements. This study offers a new perspective to estimate ground-level O3 from solar radiation intensity and surface temperature by employing an extended ensemble learning of the space-time extremely randomized trees (STET) model, together with ground-based observations, remote sensing products, atmospheric reanalysis, and an emission inventory. A full-coverage (100%), high-resolution (10 km) and high-quality daily maximum 8-h average (MDA8) ground-level O3 dataset covering China (called ChinaHighO3) from 2013 to 2020 was generated. Our MDA8 O3 estimates (predictions) are reliable, with an average out-of-sample (out-of-station) coefficient of determination of 0.87 (0.80) and root-mean-square error of 17.10 (21.10) μg/m3 in China. The unique advantage of the full coverage of our dataset allowed us to accurately capture a short-term severe O3 pollution exposure event that took place from 23 April to 8 May in 2020. Also, a rapid increase and recovery of O3 concentrations associated with variations in anthropogenic emissions were seen during and after the COVID-19 lockdown, respectively. Trends in O3 concentration showed an average growth rate of 2.49 μg/m3/yr (p < 0.001) from 2013 to 2020, along with the continuous expansion of polluted areas exceeding the daily O3 standard (i.e., MDA8 O3 = 160 μg/m3). Summertime O3 concentrations and the probability of occurrence of daily O3 pollution have significantly increased since 2015, especially in the North China Plain and the main air pollution transmission belt (i.e., the “2 + 26” cities). However, a decline in both was seen in 2020, mainly due to the coordinated control of air pollution and ongoing COVID-19 effects. This carefully vetted and smoothed dataset is valuable for studies on air pollution and environmental health in China.}
}
@article{SYED2022330,
title = {High-Intensity Hospital Utilization Among Adults With Diabetic Foot Ulcers: A Population-based Study},
journal = {Canadian Journal of Diabetes},
volume = {46},
number = {4},
pages = {330-336.e7},
year = {2022},
issn = {1499-2671},
doi = {https://doi.org/10.1016/j.jcjd.2021.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1499267121004184},
author = {Muzammil H. Syed and Mohammed Al-Omran and Joel G. Ray and Muhammad Mamdani and Charles {de Mestral}},
keywords = {Canada, diabetic foot ulcers, epidemiology, health-care burden, population-based, Canada, ulcères du pied diabétique, épidémiologie, fardeau des soins de santé, populationnelle},
abstract = {Background
Diabetic foot ulcers (DFUs) are common and disabling, necessitating lengthy hospitalizations. In this study we sought to identify potentially modifiable determinants of high-intensity hospital care use among adults with DFUs.
Methods
Three related case–control studies were conducted using Canada-wide cohorts of adults hospitalized with a DFU from 2011 to 2015. In study 1, cases comprised the top 10% with the highest cumulative 1-year acute care hospital costs; controls were randomly selected from those below the top 10%. Study 2 comprised cases/controls within/below the top 10% for cumulative acute care hospital length of stay (LOS). Study 3 included cases/controls within/below the top 10% for cumulative number of acute care hospitalizations. Using generalized linear models, predictor variables were tested between cases and controls, while adjusting for age and sex.
Results
In study 1, mean acute care costs among 8,971 cases and 3,174 controls were $71,757 and $13,687, respectively. Sepsis conferred the greatest excess cost (mean, $38,790; 95% confidence interval [CI], $34,597 to $43,508), followed by chronic kidney disease (mean, $30,607; 95% CI, $28,389 to $32,825) and major lower limb amputation (mean, $30,884; 95% CI, $28,613 to $33,155). In study 2, mean LOS was higher among 8,477 cases (69 days) than 3,467 controls (12 days). Lower limb amputation conferred the greatest adjusted excess in mean LOS (mean, 28 days; 95% CI, 27 to 28 days). In study 3, there was a mean of 3 hospitalizations among 10,341 cases and 1 among 5,509 controls. Peripheral artery disease conferred the greatest excess number of hospitalizations (1.3 more hospitalizations; 1.2 to 1.4).
Conclusions
Early aggressive treatment of chronic kidney disease and peripheral artery disease, alongside guideline-based amputation prevention strategies, may reduce high-intensity hospital care use among adults with DFUs.
Résumé
Introduction
Les ulcères du pied diabétique (UPD) sont fréquents et handicapants, et nécessitent de longues hospitalisations. Dans la présente étude, nous avons cherché à cerner les facteurs déterminants potentiellement modifiables du recours considérable aux soins hospitaliers chez les adultes atteints d’UPD.
Méthodes
Trois études cas témoins connexes ont été menées auprès de cohortes d’adultes atteints d’UPD et hospitalisés dans l’ensemble du Canada de 2011 à 2015. Dans l’étude 1, les cas représentaient les coûts hospitaliers cumulatifs les plus élevés en soins de courte durée pendant 1 année dans les 10 % supérieurs; les témoins étaient sélectionnés de façon aléatoire parmi ceux en dessous des 10 % supérieurs. L’étude 2 était composée de cas et de témoins dont la durée de séjour (DS) cumulative à l’hôpital en soins de courte durée était dans ou en dessous des 10 % supérieures. L’étude 3 portait sur des cas et des témoins dont le nombre cumulatif d’hospitalisations en soins de courte durée était dans ou en dessous des 10 % supérieurs. À l’aide des modèles linéaires généralisés, nous avons vérifié les variables de prédiction entre les cas et les témoins, tout en les ajustant selon l’âge et le sexe.
Résultats
Dans l’étude 1, les coûts moyens en soins de courte durée des 8971 cas et des 3174 témoins étaient respectivement de 71 757 $ et 13 687 $. La sepsie générait les coûts excédentaires les plus importants (moyenne, 38 790 $; intervalle de confiance [IC] à 95 %, de 34 597 $ à 43 508 $), puis suivaient l’insuffisance rénale chronique (moyenne, 30 607 $; IC à 95 %, de 28 389 $ à 32 825 $) et l’amputation majeure d’un membre inférieur (moyenne, 30 884 $; IC à 95 %, de 28 613 $ à 33 155 $). Dans l’étude 2, la DS moyenne des 8477 cas (69 jours) était plus élevée que chez les 3467 témoins (12 jours). L’amputation d’un membre inférieur générait l’allongement de la DS moyenne ajustée le plus important (moyenne, 28 jours; IC à 95 %, de 27 à 28 jours). Dans l’étude 3, il y avait une moyenne de 3 hospitalisations chez les 10 341 cas et 1 chez les 5509 témoins. La maladie artérielle périphérique générait le nombre excédentaire d’hospitalisations le plus important (1,3 hospitalisation excédentaire; de 1,2 à 1,4).
Conclusions
Le traitement vigoureux précoce de l’insuffisance rénale chronique et de la maladie artérielle périphérique, et les stratégies de prévention de l’amputation fondées sur les lignes directrices peuvent faire diminuer le recours considérable aux soins hospitaliers chez les adultes atteints d’UPD.}
}
@article{FENG2022130816,
title = {The spatial spillover effects and impact paths of financial agglomeration on green development: Evidence from 285 prefecture-level cities in China},
journal = {Journal of Cleaner Production},
volume = {340},
pages = {130816},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.130816},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622004541},
author = {Yidai Feng and Longhui Zou and Huaxi Yuan and Lu Dai},
keywords = {Financial agglomeration, Green development, Spatial spillover effect, Heterogeneity analysis, Impact path},
abstract = {Financial agglomeration is a key way to promote the green transformation of the global economy and environmental governance. The existing literature mainly analyzed the impact of financial agglomeration on economic development, but rarely examines its comprehensive impact on economic growth and environmental governance considering spatial spillover effects. Based on the perspective of spatial spillover effects, this paper uses panel data of 285 cities above the prefecture-level in China to examine the impact and mechanism of financial agglomeration on green development. The results show that: (1) During the study period, financial agglomeration and green development in China are significantly different in directions of spatial distribution and expansion, but the spatial correlation between the two is relatively high. (2) Financial agglomeration can exert significant spatial spillover effects on green development. (3) Financial agglomeration has more obvious positive spatial spillover effects on green development of cities in the servitization stage or with high administrative level. (4) Industrial structure upgrading effect, labor upgrading effect and technological innovation effect are the main paths that financial agglomeration affects green development. The research results can provide a new perspective and approach to promote the green transformation of economy and sustainable development of the world.}
}
@article{ERDOS2022105639,
title = {The UK and the EU personal data framework after Brexit: A new trade and cooperation partnership grounded in Council of Europe Convention 108+?},
journal = {Computer Law & Security Review},
volume = {44},
pages = {105639},
year = {2022},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2021.105639},
url = {https://www.sciencedirect.com/science/article/pii/S0267364921001126},
author = {David Erdos},
keywords = {Adequacy, Brexit, Council of Europe, Data protection, Data Protection Convention 108+, GDPR, Law Enforcement Directive 2016/680, Transparency rules, Sensitive data},
abstract = {The EU-UK post-Brexit agreements provide for the UK to have the closest relationship on personal data with the EU outside of the European Economic Area (EEA) and Switzerland. In the area of justice and security, the Trade and Cooperation Agreement itself provides for very extensive data exchange including DNA and fingerprints and is complemented by the first ever mutual adequacy agreement within the area of law enforcement. In some contrast, the general area of data protection is underpinned only by mutual adequacy. Whilst mandating “essentially equivalent” (GDPR, recital 104) protection, significant flexibilities may be retained. Bona fide implementation of the Council of Europe's Data Protection Convention 108+ could provide a good lodestar for a more graduated regime which also seeks to clearly reconcile data protection with competing rights. The article tentatively examines what that might entail for the data protection's core substance including the proactive transparency rules, sensitive data regime, integrity provisions and specific restrictions. Any such reform would require great care and should not detract from the need for much more effective practical enforcement.}
}
@article{MOZAFFAR2022117485,
title = {Mechanistic artificial intelligence (mechanistic-AI) for modeling, design, and control of advanced manufacturing processes: Current state and perspectives},
journal = {Journal of Materials Processing Technology},
volume = {302},
pages = {117485},
year = {2022},
issn = {0924-0136},
doi = {https://doi.org/10.1016/j.jmatprotec.2021.117485},
url = {https://www.sciencedirect.com/science/article/pii/S0924013621004453},
author = {Mojtaba Mozaffar and Shuheng Liao and Xiaoyu Xie and Sourav Saha and Chanwook Park and Jian Cao and Wing Kam Liu and Zhengtao Gan},
keywords = {Scientific data science, Deep learning, Additive manufacturing, Physics-informed machine learning, Data-driven discovery, Data-driven design},
abstract = {Today's manufacturing processes are pushed to their limits to generate products with ever-increasing quality at low costs. A prominent hurdle on this path arises from the multiscale, multiphysics, dynamic, and stochastic nature of many manufacturing systems, which motivated many innovations at the intersection of artificial intelligence (AI), data analytics, and manufacturing sciences. This study reviews recent advances in Mechanistic-AI, defined as a methodology that combines the raw mathematical power of AI methods with mechanism-driven principles and engineering insights. Mechanistic-AI solutions are systematically analyzed for three aspects of manufacturing processes, i.e., modeling, design, and control, with a focus on approaches that can improve data requirements, generalizability, explainability, and capability to handle challenging and heterogeneous manufacturing data. Additionally, we introduce a corpus of cutting-edge Mechanistic-AI methods that have shown to be very promising in other scientific fields but yet to be applied in manufacturing. Finally, gaps in the knowledge and under-explored research directions are identified, such as lack of incorporating manufacturing constraints into AI methods, lack of uncertainty analysis, and limited reproducibility and established benchmarks. This paper shows the immense potential of the Mechanistic-AI to address new problems in manufacturing systems and is expected to drive further advancements in manufacturing and related fields.}
}
@article{LI2022110968,
title = {An adaptive prognostics method based on a new health index via data fusion and diffusion process},
journal = {Measurement},
volume = {193},
pages = {110968},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.110968},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122002433},
author = {Peng Li and Ahmed Maged and Aibo Zhang and Min Xie and Wei Dang and Congmin Lyu},
keywords = {Remaining useful life (RUL), Genetic algorithm, Adaptive extended Kalman filter (AEKF), Solid-state drives (SSDs)},
abstract = {Remaining useful life prediction (RUL) is critical in predictive maintenance for components or systems prone to deterioration. However, direct RUL prediction methods have difficulties tracking health trends and realizing online prognostics. To address this issue, this paper proposes a novel health index (HI) based adaptive prognostics method by leveraging the advantages of both data fusion to handle multi-dimensional data and the adaptive extended Kalman filter (AEKF) algorithm for parameter identification in the diffusion process. A fitness metric is proposed for feature selection, and then the composite HI sequence is constructed via data fusion using the genetic algorithm. Furthermore, a diffusion process model is built to characterize HI degradation while considering multi-source uncertainties. Model parameters are then updated using the fitting-based AEKF method. Finally, the proposed method is validated on a real-world dataset of solid-state drives in data centers, and prediction results and comparative studies verify its superiority.}
}
@article{ZHANG2022100510,
title = {Visual SLAM for underwater vehicles: A survey},
journal = {Computer Science Review},
volume = {46},
pages = {100510},
year = {2022},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2022.100510},
url = {https://www.sciencedirect.com/science/article/pii/S1574013722000442},
author = {Song Zhang and Shili Zhao and Dong An and Jincun Liu and He Wang and Yu Feng and Daoliang Li and Ran Zhao},
keywords = {Underwater visual SLAM, Autonomous underwater vehicles, Sensors, Visual odometry, State optimization, Loop closure detection},
abstract = {Underwater scene is highly unstructured, full of various noise interferences. Moreover, GPS information is not available in the underwater environment, which thus brings huge challenges to the navigation of autonomous underwater vehicle. As an autonomous navigation technology, Simultaneous Localization and Mapping (SLAM) can deliver reliable localization to vehicles in unknown environment and generate models about their surrounding environment. With the development and utilization of marine and other underwater resources, underwater SLAM has become a hot research topic. By focusing on underwater visual SLAM, this paper reviews the basic theories and research progress regarding underwater visual SLAM modules, such as sensors, visual odometry, state optimization and loop closure detection, discusses the challenges faced by underwater visual SLAM, and shares the prospects of underwater visual SLAM. It is found that the traditional underwater visual SLAM based on filtering methods is gradually developing towards optimization-based methods. Underwater visual SLAM presents a diversified trend, and various new methods have emerged. This paper aims to provide researchers and practitioners with a better understanding of the current status and development trend of underwater visual SLAM, while offering help for collecting underwater vehicles intelligence.}
}
@article{KATAL2022123817,
title = {Urban building energy and microclimate modeling – From 3D city generation to dynamic simulations},
journal = {Energy},
volume = {251},
pages = {123817},
year = {2022},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2022.123817},
url = {https://www.sciencedirect.com/science/article/pii/S0360544222007204},
author = {Ali Katal and Mohammad Mortezazadeh and Liangzhu (Leon) Wang and Haiyi Yu},
keywords = {UBEM, Microclimate, Digital city, GIS, Dynamic simulation, Archetype},
abstract = {Dynamic urban simulations often face three main challenges: 3D digital city generations, building archetype creations, and inclusions of urban microclimate impacts due to limited data and computing resources available. This study introduces a new approach for the 3D city generation by integrating publicly available data sets (OpenStreetMap and Microsoft footprints) and a free program (Google Earth). These data sets provide 2D building footprints, whereas Google Earth provides digital surface models of terrains and buildings. The building archetype library of non-geometrical properties was created based on building types and years of constructions in the form of shapefiles joined with the 3D city data through QGIS. The proposed workflow also includes the dynamic integration of urban microclimate (CityFFD) and building thermal/energy models (CityBEM). The dynamic simulations were achieved using weather station data as boundary conditions, including air temperature, solar radiation, and wind speed and direction, instead of typical meteorological year data. The transient microclimate results were validated using local weather station data, and dynamic energy simulation results were validated using measured power consumption data. The study provides a solution to dynamic urban building energy and microclimate modeling by publicly available data sets and tools.}
}
@article{KIM2022510,
title = {Human-guided auto-labeling for network traffic data: The GELM approach},
journal = {Neural Networks},
volume = {152},
pages = {510-526},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001794},
author = {Meejoung Kim and Inkyu Lee},
keywords = {Human-guided labeling, Auto-labeling process, Generalized extreme learning machine, Moore–Penrose generalized inverse, Network traffic, Attack prediction},
abstract = {Data labeling is crucial in various areas, including network security, and a prerequisite for applying statistical-based classification and supervised learning techniques. Therefore, developing labeling methods that ensure good performance is important. We propose a human-guided auto-labeling algorithm involving the self-supervised learning concept, with the purpose of labeling data quickly, accurately, and consistently. It consists of three processes: auto-labeling, validation, and update. A labeling scheme is proposed by considering weighted features in the auto-labeling, while the generalized extreme learning machine (GELM) enabling fast training is applied to validate assigned labels. Two different approaches are considered in the update to label new data to investigate labeling speed and accuracy. We experiment to verify the suitability and accuracy of the algorithm for network traffic, applying the algorithm to five traffic datasets, some including distributed denial of service (DDoS), DoS, BruteForce, and PortScan attacks. Numerical results show the algorithm labels unlabeled datasets quickly, accurately, and consistently and the GELM’s learning speed enables labeling data in real-time. It also shows that the performances between auto- and conventional labels are nearly identical on datasets containing only DDoS attacks, which implies the algorithm is quite suitable for such datasets. However, the performance differences between the two labels are not negligible on datasets, including various attacks. Several reasons that require further investigation can be considered, including the selected features and the reliability of conventional labels. Even with this limitation of the current study, the algorithm will provide a criterion for labeling data in real-time occurring in many areas.}
}
@article{KOVALCHUK2022104013,
title = {Three-stage intelligent support of clinical decision making for higher trust, validity, and explainability},
journal = {Journal of Biomedical Informatics},
volume = {127},
pages = {104013},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104013},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422000296},
author = {Sergey V. Kovalchuk and Georgy D. Kopanitsa and Ilia V. Derevitskii and Georgy A. Matveev and Daria A. Savitskaya},
keywords = {Clinical decision support, Predictive modeling, Interpretable machine learning, Personalized medicine, Machine learning, Diabetes mellitus},
abstract = {The paper presents a conceptual framework for building practically applicable clinical decision support systems (CDSSs) using data-driven (DD) predictive modelling. With the proposed framework we have tried to fill the gap between experimental CDSS implementations widely covered in the literature and solutions acceptable by physicians in daily practice. The framework is based on a three-stage approach where DD model definition is accomplished with practical norms referencing (scales, clinical recommendations, etc.) and explanation of the prediction results and recommendations. The approach is aimed at increasing the applicability of CDSSs based on DD models through better integration into decision context and higher explainability. The approach has been implemented in software solutions and tested within a case study in type 2 diabetes mellitus (T2DM) prediction, enabling us to improve known clinical scales (such as FINDRISK) while keeping the problem-specific reasoning interface similar to existing applications. A survey was performed to assess and investigate the acceptance level and provide insights on the influences of the introduced framework’s element on physicians’ behavior.}
}
@article{SUNDUS2022101088,
title = {Solving the multicollinearity problem to improve the stability of machine learning algorithms applied to a fully annotated breast cancer dataset},
journal = {Informatics in Medicine Unlocked},
volume = {33},
pages = {101088},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.101088},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822002246},
author = {Katrina I. Sundus and Bassam H. Hammo and Mohammad B. Al-Zoubi and Amal Al-Omari},
keywords = {Breast cancer, Recurrent breast cancer, Machine learning, Multicollinearity, Dimensionality reduction, Feature selection, Stacking classifier},
abstract = {Among the different types of cancer, breast cancer is the most common cancer affecting females in Jordan. Recurrent breast cancer after treatment is a significant concern for patients and oncologists. Developing countries like Jordan suffer from a lack of quality data on computational medicine (CM). This paper discusses the design, construction, and evaluation of an extensive, fully annotated breast cancer dataset extracted from the King Hussein Cancer Center's registry database (KHCC) in Amman, Jordan. The Jordan Breast Cancer dataset (JBRCA) has 20 attributes and 7562 instances of breast cancer patients. It can be considered a valuable resource to motivate future research in CM in the country. By illustration, the study describes the problems facing the compilation of the dataset. A thorough analysis of the dataset brought up many issues that required remedies before the dataset could be used in machine learning (ML) applications. These issues included missing values and outliers, unnormalized and imbalanced data, and the multicollinearity problem between the attributes. Multicollinearity occurs when two or more independent variables are highly correlated in a regression model, which might affect its stability. This is mainly a problem because we might not differentiate between the effects of the independent variables on the dependent variable. To handle these issues, we deleted missing values and outliers, applied the min-max normalization to control the attributes' different scales, and used SMOTE to solve the highly imbalanced problem. We also used the variance inflation factor (VIF) to solve the multicollinearity problem. Domain experts from KHCC help to identify the best subset of attributes to be removed from the dataset to enhance the stability and performance of the ML algorithms. We used classification models such as logistic regression, decision tree, k-nearest neighbors, Gaussian Naive Bayes, multilayer perceptron, and a stacking classifier combining all five classifiers to evaluate the compiled dataset. The stacking classifier outperformed the other base learners based on accuracy, sensitivity, and F1-score rates.}
}
@article{HEIDARI2022105141,
title = {The COVID-19 epidemic analysis and diagnosis using deep learning: A systematic literature review and future directions},
journal = {Computers in Biology and Medicine},
volume = {141},
pages = {105141},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105141},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521009355},
author = {Arash Heidari and Nima {Jafari Navimipour} and Mehmet Unal and Shiva Toumaj},
keywords = {Artificial intelligence, COVID-19, Deep learning, Neural networks, Pandemic},
abstract = {Since December 2019, the COVID-19 outbreak has resulted in countless deaths and has harmed all facets of human existence. COVID-19 has been designated an epidemic by the World Health Organization (WHO), which has placed a tremendous burden on nearly all countries, especially those with weak health systems. However, Deep Learning (DL) has been applied in several applications and many types of detection applications in the medical field, including thyroid diagnosis, lung nodule recognition, fetal localization, and detection of diabetic retinopathy. Furthermore, various clinical imaging sources, like Magnetic Resonance Imaging (MRI), X-ray, and Computed Tomography (CT), make DL a perfect technique to tackle the epidemic of COVID-19. Inspired by this fact, a considerable amount of research has been done. A Systematic Literature Review (SLR) has been used in this study to discover, assess, and integrate findings from relevant studies. DL techniques used in COVID-19 have also been categorized into seven main distinct categories as Long Short Term Memory Networks (LSTM), Self-Organizing Maps (SOMs), Conventional Neural Networks (CNNs), Generative Adversarial Networks (GANs), Recurrent Neural Networks (RNNs), Autoencoders, and hybrid approaches. Then, the state-of-the-art studies connected to DL techniques and applications for health problems with COVID-19 have been highlighted. Moreover, many issues and problems associated with DL implementation for COVID-19 have been addressed, which are anticipated to stimulate more investigations to control the prevalence and disaster control in the future. According to the findings, most papers are assessed using characteristics such as accuracy, delay, robustness, and scalability. Meanwhile, other features are underutilized, such as security and convergence time. Python is also the most commonly used language in papers, accounting for 75% of the time. According to the investigation, 37.83% of applications have identified chest CT/chest X-ray images for patients.}
}
@article{YANG2022103761,
title = {Innovation and sustainable: Can innovative city improve energy efficiency?},
journal = {Sustainable Cities and Society},
volume = {80},
pages = {103761},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103761},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722000920},
author = {Jingyi Yang and Guangqin Xiong and Daqian Shi},
keywords = {Innovative city, Policy effect, Energy efficiency, Propensity score matching–difference in differences, JEL Classification: O31 Q40 Q48 R58},
abstract = {This paper studies the impact of the construction of innovative cities on cities' energy efficiency. Using panel data of cities from 2005 to 2017, we take the implementation of the National Innovative Polit City Policy (NIPCP) in China as a quasi-natural experiment and identify its impact on improving cities' energy efficiency. Further, for the potential mechanism, we find that NIPCP not only enhances energy efficiency directly by establishing energy-related assessment indicators but also indirectly through the optimization of industrial structures and the promotion of urban innovation level, promoting the transformation to energy-saving cities. Considering the heterogeneity of cities, NIPCP has a greater effect on cities in the west, resource-based cities, provincial capitals, and small and medium-sized cities. Our empirical evidence strongly supports that NIPCP can realize a win-win situation for the energy and economy.}
}
@article{HO2022103858,
title = {OpenComm: Open community platform for data integration and privacy preserving for 311 calls},
journal = {Sustainable Cities and Society},
volume = {83},
pages = {103858},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103858},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722001858},
author = {Duy H. Ho and Yugyung Lee and Srichakradhar Nagireddy and Charan Thota and Brent Never and Ye Wang},
keywords = {311 calls, Data curation, Data privacy, Data integration, Categorization, Data visualization, Machine learning},
abstract = {Local governments are increasingly leveraging administrative data to drive performance. Likewise, cities are interested in improving responsiveness to citizens’ demands and cost savings through data analytics. However, city managers face many challenges when utilizing secondary data, such as 311 call records and the US Census. The challenge of interest to the current study is boundary issues as a result of data being collected at divergent geographic levels over different time horizons. Accordingly, an inductive analytical methodology was developed to create units of analysis that were both pragmatically and analytically appropriate for city managers and local policymakers. We created an open data analytics framework called OpenComm to harmonize administrative and secondary data using administrative data derived from Kansas City, Missouri. This framework produced robust inferences regarding the spatial and temporal aspects for the communities. Privacy-preserving technology, in particular, has been applied to public data to protect community privacy. The findings illustrate the power of inductive data aggregation, leading to empirical insights into hidden patterns of city service disparity over a decade-long time horizon. An application for the Open Data Platform is available at http://kc311.herokuapp.com/.}
}
@article{GRAY2022104550,
title = {Stakeholders’ insights on learning analytics: Perspectives of students and staff},
journal = {Computers & Education},
volume = {187},
pages = {104550},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104550},
url = {https://www.sciencedirect.com/science/article/pii/S036013152200121X},
author = {Geraldine Gray and Ana Elena Schalk and Gordon Cooke and Phelim Murnion and Pauline Rooney and K.C. O'Rourke},
keywords = {Data science applications in education, Evaluation methodologies, Improving classroom teaching, Information literacy, Teacher professional development},
abstract = {Learning analytics has drawn the attention of academics and administrators in recent years as a tool to better understand students' needs and to tailor appropriate and timely responses. While many value the potential of learning analytics, it is not without critics, especially with regards to ethical concerns surrounding the level and type of data gathered, and scepticism on data's ability to measure something useful and actionable. This paper gathers the thoughts of key stakeholders, including staff and students, and their expectations of learning analytics, their priorities for using student data, and how they should be supported to act on the data, with the aim of aiding institutions with their plans to implement learning analytics. For this analysis we explored stakeholder awareness, concerns, priorities and support needs with respect to effectively accessing, interpreting and utilising learning data through the use of surveys and focus groups. These were adapted from the previously published SHEILA framework protocols with additional topics added relating to awareness, uses of data, and support. The focus groups were used to capture prevalent themes, followed by surveys to gain perspectives on these themes from a wider stakeholder audience. Overall, results suggest there are significant differences in the perspectives of each of the stakeholders. There is also a strong need for both additional training and ongoing support to manage and realise stakeholder understanding and goals around learning analytics. Further research is necessary to explore the needs of a greater diversity of stakeholders.}
}
@article{HUANG2022,
title = {Priori-guided and data-driven hybrid model for wind power forecasting},
journal = {ISA Transactions},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0019057822003846},
author = {Yi Huang and Guo-Ping Liu and Wenshan Hu},
keywords = {Wind power forecasting, Priori-guided machine learning, Explainable representation, Ultra-short-term forecasting, Practical power curve},
abstract = {To overcome the high uncertainty and randomness of wind and enable the grid to optimize advance preparation, a priori-guided and data-driven hybrid method is proposed to provide accurate and reasonable wind power forecasting results. Fuzzy C-Means (FCM) clustering algorithm is used first to recognize the characteristics of the weather in different regions. Then, for the purpose of making full use of both priori information and collected measured data, a three-stage hierarchical framework is designed. First, via fuzzy inference and dimension reduction of Numerical Weather Prediction (NWP), more applicable wind speed information is obtained. Second, the accessible wind power generation patterns are served as a guide for mining the actual power curve. Third, the forecasted power is derived through the recorded data and the predictable wind conditions via data-driven model. This forecasting framework ingeniously introduces a gateway that can import priori knowledge to steer the iterative learning, thus possessing both adaptive learning ability and Volterra polynomial representation, and can present forecasted outcomes with robustness, accuracy and interpretability. Finally, a real-world dataset of a wind farm as well as an open source dataset are used to verify the performance of the proposed forecasting method. Results of the ablation analyses and comparative experiments demonstrate that the introduction of domain knowledge improves the forecasting performance.}
}
@article{CONLEY2022101752,
title = {Using a deep learning model to quantify trash accumulation for cleaner urban stormwater},
journal = {Computers, Environment and Urban Systems},
volume = {93},
pages = {101752},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101752},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521001599},
author = {Gary Conley and Stephanie Castle Zinn and Taylor Hanson and Krista McDonald and Nicole Beck and Howard Wen},
keywords = {Urban trash, Litter, Stormwater, Machine learning, Mask R-CNN},
abstract = {With growing understanding of trash impacts on aquatic habitats throughout the world, cities increasingly face regulatory requirements to reduce trash inputs to local waterways and the ocean, but they often rely upon insufficient monitoring data to prioritize and measure trash reduction effectiveness. We present an approach designed to make urban trash monitoring more cost-efficient and align the data collected with critical information needs of cities. We quantified urban trash accumulation along roadsides using vehicle mounted cameras and a deep convolutional neural network model to identify trash in the imagery captured. We compared the trash detection performance of three different models, with the best performing model (Mask R-CNN) achieving 91% recall, 83% precision, and 77% accuracy using data collected along 84 road segments in two California Cities. Trash detection model outputs were interpreted via a statistical model to relate the proportion of image pixels identified as trash to measured trash volumes. The resulting model estimates explained 67% of the variance in measured trash volumes collected on roadsides, which is more than double the variance explained by walking visual assessments. With vastly more efficient data collection compared to the visual assessments, deep learning-based monitoring approaches can provide a stronger basis for understanding urban trash sources, changes over time, and cost-effective compliance with stormwater regulatory requirements.}
}
@article{WU2022104108,
title = {Rule-based information extraction for mechanical-electrical-plumbing-specific semantic web},
journal = {Automation in Construction},
volume = {135},
pages = {104108},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104108},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005598},
author = {Lang-Tao Wu and Jia-Rui Lin and Shuo Leng and Jiu-Lin Li and Zhen-Zhong Hu},
keywords = {Information extraction, MEP, Rule match, Named entity recognition, Relation extraction, Natural language understanding, Semantic web},
abstract = {Information extraction (IE), which aims to retrieve meaningful information from plain text, has been widely studied in general and professional domains to support downstream applications. However, due to the lack of labeled data and the complexity of professional mechanical, electrical and plumbing (MEP) information, it is challenging to apply current common deep learning IE methods to the MEP domain. To solve this problem, this paper proposes a rule-based approach for MEP IE task, including a “snowball” strategy to collect large-scale MEP corpora, a suffix-based matching algorithm on text segments for named entity recognition (NER), and a dependency-path-based matching algorithm on dependency tree for relationship extraction (RE). 2 ideas called “meta linking” and “path filtering” for RE are proposed as well, to discover the out-of-pattern entities/relationships as many as possible. To verify the feasibility of the proposed approach, 65 MB MEP corpora have been collected as input of the proposed approach and an MEP semantic web which consists of 15,978 entities and 65,110 relationship triples established, with an accuracy of 81% to entities and 75% to relationship triples, respectively. A comparison experiment between classical deep learning models and the proposed rule-based approach was carried out, illustrating that the performance of our method is 37% and 49% better than the selected deep learning NER and RE models, respectively, in the aspect of extraction precision.}
}
@article{JETTER2022105907,
title = {Post-Cold War civil conflict and the role of history and religion: A stochastic search variable selection approach},
journal = {Economic Modelling},
volume = {114},
pages = {105907},
year = {2022},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2022.105907},
url = {https://www.sciencedirect.com/science/article/pii/S0264999322001535},
author = {Michael Jetter and Rafat Mahmood and Christopher F. Parmeter and Andrés Ramírez-Hassan},
keywords = {Civil conflict, Civil war, Stochastic search variable selection (), Greed versus grievances, Religion and conflict},
abstract = {Despite colossal economic and human losses caused by conflict and violence, designing effective policies to avoid conflict remains challenging. While the literature has proposed a voluminous set of candidate predictors, their robustness is questionable and model uncertainty masks the true drivers of conflicts and wars. Considering a comprehensive set of 34 potential determinants in 175 post-Cold-War countries, we employ stochastic search variable selection (SSVS) to sort through all 234 possible models to address model uncertainty. We find past conflict constitutes the most powerful predictor of current conflict: Path dependency matters. Also, larger shares of Jewish, Muslim, or Christian citizens are associated with increased conflict, while economic and political factors remain less relevant than colonial origin and religion. Our results help future researchers and policymakers by inching towards causality and providing a standard set of covariates that need to be accounted for in designing any relevant policies.}
}
@article{HUANG2022130401,
title = {A license plate recognition data to estimate and visualise the restriction policy for diesel vehicles on urban air quality: A case study of Shenzhen},
journal = {Journal of Cleaner Production},
volume = {338},
pages = {130401},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.130401},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622000476},
author = {Wenke Huang and Xiaoxiao Xu and Mingwei Hu and Wenwei Huang},
keywords = {Diesel vehicle, License plate recognition data, Environmental effect, Traffic policy},
abstract = {Diesel vehicles for road freight are primary contributors to PM2.5 and NOX emissions in numerous cities. Shenzhen, which is a megacity in China, has made efforts to promote the transition to green transport by implementing license plate restrictions. Nevertheless, it is still unclear whether the restrictions have greatly improved urban air quality. An effective framework for accurately estimating and visualising the effect of restriction policy on a large scale is still lacking. Therefore, this study aims to develop a novel method to visualise and evaluate the effect of license plate restriction policy by bridging diesel truck's license plate recognition data to emission inventories. The results reveal that the impact of the peak restriction on air quality was limited if it only affected nonlocal diesel vehicles. While the promotion of eco-friendly vehicles could reduce PM2.5 and NOX emissions. The findings could provide references for other cities or countries to estimate air pollution from diesel vehicles and recognise high emission zones at a large scale and thus create effective policies and initiatives.}
}
@article{WU2022109477,
title = {Generative Adversarial Networks in the built environment: A comprehensive review of the application of GANs across data types and scales},
journal = {Building and Environment},
volume = {223},
pages = {109477},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2022.109477},
url = {https://www.sciencedirect.com/science/article/pii/S0360132322007089},
author = {Abraham Noah Wu and Rudi Stouffs and Filip Biljecki},
keywords = {Machine learning, Generative design, Urban planning, GeoAI, Urban AI},
abstract = {Generative Adversarial Networks (GANs) are a type of deep neural network that have achieved many state-of-the-art results for generative tasks. GANs can be useful in the built environment, from processing large-scale urban mobility data and remote sensing images at the regional level, to performance analysis and design generation at the building level. We analyzed 100 articles to provide a comprehensive state-of-the-art review on how GANs are currently applied to solve challenging tasks in the built environment. Our results show that: (i) GANs are replacing older methods in some problems and setting state-of-the-art performances; (ii) GANs are opening new frontiers in previously overlooked problems, such as automatically generating spatially accurate floorplan layouts; (iii) GANs can be applied to different scales in the built environment, from entire cities to neighborhoods and buildings; and (iv) GANs are being used in a variety of problems and data types, from remote sensing data augmentation, vector data generation, spatio-temporal data privacy protection, to building design generation. In total, there are 26 unique application domains enabled by GANs; (v) however, one common challenge in this field currently is the lack of high-quality datasets curated specifically for problems in the built environment. With more data in the future, GANs could potentially produce even better results than today.}
}
@article{CHILDERS2022109778,
title = {Fracture diagnostic technologies with process workflow for implementation},
journal = {Journal of Petroleum Science and Engineering},
volume = {208},
pages = {109778},
year = {2022},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2021.109778},
url = {https://www.sciencedirect.com/science/article/pii/S0920410521013991},
author = {D. Childers and X. Wu},
keywords = {Hydraulic fracturing, Diagnosis, Unconventional reservoir, Fracture conductivity, Stimulated reservoir volume},
abstract = {Hydraulic Fracturing (HF) is a frequently used well stimulation technology to improve a well's productivity by increasing the contact area with the formation matrix. Hydraulic fractures are created by following a customized design based on imperfect knowledge of the subsurface formation and idealizations. Therefore, the resulting fracture system is often different from the original design, which calls for post-fracturing evaluations. Fracture diagnostics are utilized to understand fracture behavior during or after hydraulic fracturing. Understanding the geomechanics of how fractures form during fracturing has been studied in detail; however, predicting fracture genesis and propagation behavior has been a challenging endeavor because of reservoir heterogeneity. This paper will reveal the current fracture diagnostic technologies and assess their ability to detect HF extension and quantify the properties of hydraulic fractures in terms of conductivity and stimulated reservoir volumes. This paper is not an abridged version of the technical manual regarding how each method is conducted or used but focuses on insight into what they measure and their difference from others. With the critical reviews on current HF diagnostic technologies, we intend to (1) define key terminologies that are often used in HF evaluation to set up a common linguistic lexicon for comparison, (2) provide a brief discussion on their mechanisms; (3) stipulate a framework on how to choose proper HF diagnostic tools and analysis methods for different HF applications.}
}
@article{ZHA2022167481,
title = {Explaining and Predicting Allostery with Allosteric Database and Modern Analytical Techniques},
journal = {Journal of Molecular Biology},
volume = {434},
number = {17},
pages = {167481},
year = {2022},
note = {Allostery: From Mechanisms to Therapies},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2022.167481},
url = {https://www.sciencedirect.com/science/article/pii/S002228362200050X},
author = {Jinyin Zha and Mingyu Li and Ren Kong and Shaoyong Lu and Jian Zhang},
keywords = {allosteric site, allosteric drug, protein sequence, allosteric mechanism, machine learning},
abstract = {Allostery is a phenomenon that the protein activity is regulated when a non-functional site on it is bounded. This phenomenon is important in life process and disease therapy. However, it is difficult to study allostery due to the lack of knowledge. Facing this demand, we have created Allosteric Database (ASD) 10 years before to collect numerous kinds of allosteric data. In this review, we will introduce the 4 categories of data in ASD. For each category, we further reviewed how researchers applied ASD data to conduct studies. We focused on their research topics, analytical methods and conclusions. Several discoveries of new drug targets and allosteric modulators driven by ASD are also summarized. We hope this review could inspire researchers with new utilities of ASD data.}
}
@article{ZHANG2022118981,
title = {Retrieving soil heavy metals concentrations based on GaoFen-5 hyperspectral satellite image at an opencast coal mine, Inner Mongolia, China},
journal = {Environmental Pollution},
volume = {300},
pages = {118981},
year = {2022},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2022.118981},
url = {https://www.sciencedirect.com/science/article/pii/S0269749122001956},
author = {Bo Zhang and Bin Guo and Bin Zou and Wei Wei and Yongzhi Lei and Tianqi Li},
keywords = {Heavy metals, Hyperspectral image, Mining areas, Direct standardization algorithm, Random forest},
abstract = {Soil heavy metals pollution has been becoming one of the severely environmental issues globally. Previous studies reported laboratory-measured spectra could be used to infer soil heavy metals concentrations to some extent. However, using field-obtained spectra to estimate soil heavy metals concentrations is still a great challenge due to the low precision and weak efficiency at large scales. The present study collected 110 topsoil samples from an Opencast Coal Mine of Ordos, Inner Mongolia, China. Then, the spectra and soil heavy metals concentrations of samples were measured under laboratory conditions. The direct standardization (DS) algorithm was introduced to calibrate the Gaofen-5 (GF-5) hyperspectral image based on the measured spectra of samples. The spectral reflectance of the GF-5 hyperspectral image was reconstructed using continuous wavelet transform (CWT) at different scales. The characteristic bands of GF-5 for estimating heavy metals concentrations were selected by the Boruta algorithm. Finally, the random forest (RF), the extreme learning machine (ELM), the support vector machine (SVM), and the back-propagation neural network (BPNN) algorithms were used to predict the heavy metals concentrations. Some findings were achieved. First, CWT can effectively eliminate the noise of satellite hyperspectral data. The characteristic bands of Zn (480–677, 827–1029, 1241–1334, 1435–1797, and 1949–2500 nm), Ni (514–630, 835–985, 1258–1325, 1460–1578, and 1949–2319 nm), and Cu (822–831; 1029–1300, 1486–1595, and 1730–2294 nm) can be effectively retrieved via the Boruta algorithm. Second, the estimation accuracy was significantly improved by using the DS algorithm. For zinc (Zn), nickel (Ni), and copper (Cu), the determination coefficients of the validation dataset (Rv2) were 0.77 (RF), 0.62 (RF), and 0.56 (ELM), respectively. Third, the distribution trends of heavy metals were almost consistent with the results of actual ground measurements. This paper revealed that the GF-5 can be one of the reliable satellite hyperspectral imagery for mapping soil heavy metals.}
}
@article{EDMONDSON2022104097,
title = {Distributed Quasi-Poisson regression algorithm for modeling multi-site count outcomes in distributed data networks},
journal = {Journal of Biomedical Informatics},
volume = {131},
pages = {104097},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104097},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422001137},
author = {Mackenzie J. Edmondson and Chongliang Luo and Md. {Nazmul Islam} and Natalie E. Sheils and John Buresh and Zhaoyi Chen and Jiang Bian and Yong Chen},
keywords = {Distributed algorithm, Distributed data network, Electronic health records, Overdispersion, Poisson regression},
abstract = {Background
Observational studies incorporating real-world data from multiple institutions facilitate study of rare outcomes or exposures and improve generalizability of results. Due to privacy concerns surrounding patient-level data sharing across institutions, methods for performing regression analyses distributively are desirable. Meta-analysis of institution-specific estimates is commonly used, but has been shown to produce biased estimates in certain settings. While distributed regression methods are increasingly available, methods for analyzing count outcomes are currently limited. Count data in practice are commonly subject to overdispersion, exhibiting greater variability than expected under a given statistical model.
Objective
We propose a novel computational method, a one-shot distributed algorithm for quasi-Poisson regression (ODAP), to distributively model count outcomes while accounting for overdispersion.
Methods
ODAP incorporates a surrogate likelihood approach to perform distributed quasi-Poisson regression without requiring patient-level data sharing, only requiring sharing of aggregate data from each participating institution. ODAP requires at most three rounds of non-iterative communication among institutions to generate coefficient estimates and corresponding standard errors. In simulations, we evaluate ODAP under several data scenarios possible in multi-site analyses, comparing ODAP and meta-analysis estimates in terms of error relative to pooled regression estimates, considered the gold standard. In a proof-of-concept real-world data analysis, we similarly compare ODAP and meta-analysis in terms of relative error to pooled estimatation using data from the OneFlorida Clinical Research Consortium, modeling length of stay in COVID-19 patients as a function of various patient characteristics. In a second proof-of-concept analysis, using the same outcome and covariates, we incorporate data from the UnitedHealth Group Clinical Discovery Database together with the OneFlorida data in a distributed analysis to compare estimates produced by ODAP and meta-analysis.
Results
In simulations, ODAP exhibited negligible error relative to pooled regression estimates across all settings explored. Meta-analysis estimates, while largely unbiased, were increasingly variable as heterogeneity in the outcome increased across institutions. When baseline expected count was 0.2, relative error for meta-analysis was above 5% in 25% of iterations (250/1000), while the largest relative error for ODAP in any iteration was 3.59%. In our proof-of-concept analysis using only OneFlorida data, ODAP estimates were closer to pooled regression estimates than those produced by meta-analysis for all 15 covariates. In our distributed analysis incorporating data from both OneFlorida and the UnitedHealth Group Clinical Discovery Database, ODAP and meta-analysis estimates were largely similar, while some differences in estimates (as large as 13.8%) could be indicative of bias in meta-analytic estimates.
Conclusions
ODAP performs privacy-preserving, communication-efficient distributed quasi-Poisson regression to analyze count outcomes using data stored within multiple institutions. Our method produces estimates nearly matching pooled regression estimates and sometimes more accurate than meta-analysis estimates, most notably in settings with relatively low counts and high outcome heterogeneity across institutions.}
}
@article{MCDONNELL20221402,
title = {The impact of noise and missing fragmentation cleavages on de novo peptide identification algorithms},
journal = {Computational and Structural Biotechnology Journal},
volume = {20},
pages = {1402-1412},
year = {2022},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2022.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2001037022000836},
author = {Kevin McDonnell and Enda Howley and Florence Abram},
keywords = { peptide sequencing, Machine learning, Peptide identification, Noise, Fragmentation cleavage sites, Peptide fragmentation},
abstract = {Proteomics aims to characterise system-wide protein expression and typically relies on mass-spectrometry and peptide fragmentation, followed by a database search for protein identification. It has wide ranging applications from clinical to environmental settings and virtually impacts on every area of biology. In that context, de novo peptide sequencing is becoming increasingly popular. Historically its performance lagged behind database search methods but with the integration of machine learning, this field of research is gaining momentum. To enable de novo peptide sequencing to realise its full potential, it is critical to explore the mass spectrometry data underpinning peptide identification. In this research we investigate the characteristics of tandem mass spectra using 8 published datasets. We then evaluate two state of the art de novo peptide sequencing algorithms, Novor and DeepNovo, with a particular focus on their performance with regard to missing fragmentation cleavage sites and noise. DeepNovo was found to perform better than Novor overall. However, Novor recalled more correct amino acids when 6 or more cleavage sites were missing. Furthermore, less than 11% of each algorithms’ correct peptide predictions emanate from data with more than one missing cleavage site, highlighting the issues missing cleavages pose. We further investigate how the algorithms manage to correctly identify peptides with many of these missing fragmentation cleavages. We show how noise negatively impacts the performance of both algorithms, when high intensity peaks are considered. Finally, we provide recommendations regarding further algorithms’ improvements and offer potential avenues to overcome current inherent data limitations.}
}
@article{GAO2022283,
title = {FGFL: A blockchain-based fair incentive governor for Federated Learning},
journal = {Journal of Parallel and Distributed Computing},
volume = {163},
pages = {283-299},
year = {2022},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2022.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0743731522000259},
author = {Liang Gao and Li Li and Yingwen Chen and ChengZhong Xu and Ming Xu},
keywords = {Federated Learning, Incentive mechanism, Attack detection},
abstract = {Federated Learning is a framework that coordinates a large amount of workers to train a shared model in a distributed manner, in which the training data are located on the workers' sides in order to preserve data privacy. There are two challenges in the crowdsourcing of FL, the workers who participant in training need to consume computing and communication resources, so that they are reluctant to participate in the training process if they can not get reasonable rewards. Moreover, there may be attackers who send arbitrary updates to get undeserving compensation or even destroy the model, thus, effective prevention of malicious workers is also critical. An incentive mechanism is urgently required in order to encourage high-quality workers to participate in FL and to punish the attackers. In this paper, we propose FGFL, a blockchain-based incentive governor for Federated Learning. In FGFL, we assess the participants with reputation and contribution indicators. Then the task publisher rewards workers fairly to attract efficient ones while the malicious ones are punished and eliminated. In addition, we propose a blockchain-based incentive management system to manage the incentive mechanism. We evaluate the effectiveness and fairness of FGFL through theoretical analysis and comprehensive experiments. The evaluation results show that FGFL fairly rewards workers according to their corresponding behavior and quality. FGFL increases the system revenue by 0.2% to 3.4% in reliable federations compared with baselines. And in the unreliable scenario where contains attackers, the system revenue of FGFL outperforms the baselines by more than 46.7%.}
}
@article{BAI2022102741,
title = {A new data mining method for time series in visual analysis of regional economy},
journal = {Information Processing & Management},
volume = {59},
number = {1},
pages = {102741},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102741},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321002235},
author = {Yang Bai and Min Zhao and Rong Li and Peizhu Xin},
keywords = {Time series, Regional economy, Visualization},
abstract = {In order to improve the effect of visual analysis of regional economy, this paper uses machine learning algorithms to analyze time series data, uses various models and methods of intelligent data analysis to mine data laws from huge data, statistical data reports, and find problems in economic development. Moreover, this paper combines the time series algorithm to design and plan the functional structure of the system, and design a separate module structure from the actual situation of regional economic analysis, and build a model system from the overall structure. After constructing the system, this paper tests the system. From the results of the experimental research, we can see that the regional economic visualization system based on time series constructed in this paper has perfect system functions and can meet the needs of regional economic analysis.}
}
@article{HAKIM2022101945,
title = {A systematic review of rolling bearing fault diagnoses based on deep learning and transfer learning: Taxonomy, overview, application, open challenges, weaknesses and recommendations},
journal = {Ain Shams Engineering Journal},
pages = {101945},
year = {2022},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2022.101945},
url = {https://www.sciencedirect.com/science/article/pii/S2090447922002568},
author = {Mohammed Hakim and Abdoulhdi A. Borhana Omran and Ali Najah Ahmed and Muhannad Al-Waily and Abdallah Abdellatif},
keywords = {Rolling bearing, Deep learning, Transfer learning, Fault diagnosis, Systematic review},
abstract = {Rolling bearing fault detection is critical for improving production efficiency and lowering accident rates in complicated mechanical systems, as well as huge monitoring data, posing significant challenges to present fault diagnostic technology. Deep Learning is now an extraordinarily popular research topic in the field and a promising approach for detecting intelligent bearing faults. This paper aims to give a comprehensive overview of Deep Learning (DL) based on bearing fault diagnosis. The most widely used DL algorithms for detecting bearing faults include Convolutional Neural Network, Recurrent neural network, Autoencoder, and Generative Adversarial Network. It discusses a variety of transfer learning architectures and relevant theories while summarises, classifies, and explains several publications on the subject. The research area’s applications and problems are also addressed.}
}
@article{WUYUN2022150286,
title = {The spatiotemporal change of cropland and its impact on vegetation dynamics in the farming-pastoral ecotone of northern China},
journal = {Science of The Total Environment},
volume = {805},
pages = {150286},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.150286},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721053638},
author = {Deji Wuyun and Liang Sun and Zhongxin Chen and Anhong Hou and Luís Guilherme Teixeira Crusiol and Lifeng Yu and Ruiqing Chen and Zheng Sun},
keywords = {Land use classification, “Grain for Green” program, Land Use Change Trajectory, Vegetation index, Vegetation restoration},
abstract = {Due to the unfavorable soil conditions and water resources, the cropland use pattern in the farming-pastoral ecotone in northern China is complex. The program named “Grain for Green” has accelerated the cropland change. However, the complex cropland and retired cropland are challenging to monitor with remote sensing due to their spatially dispersed and easily confused with spectrally similar land use classes such as nature grasslands and non-cropped fields. Taking farming-pastoral ecotone in the northern foot of the Yinshan Mountains as a case study, we explored a classification approach for complex cropland and retired cropland, which was introduced as a specific land use class by using multi-temporal Landsat TM and OLI images with Google Earth Engine. During 1990–2000, cropland increased with a sharper growth and increased with a slower growth from 2001 to 2010, and then decreased significantly from 2011 to 2019, to lead the cropland area in 2019 was smaller than an area in 1990. We analyzed the spatiotemporal trajectories of retired cropland in 2019 using the Land Use Change Trajectory method to evaluate its source. In our finding, approximately 77% of retired cropland was labelled as cropland before 2019; albeit, not all retired cropland was converted from cropland. Moreover, we qualitatively assessed the vegetation dynamics in the study area by utilizing the long-term NDVI-mean value to reveal that vegetation coverage has shown a continuously increasing trend. It is related to the decline of cropland and the increase of retired cropland at the same rate. Our results highlighted that the “Grain for Green” program had led the vegetation restoration in the farming-pastoral ecotone. Our approach for monitoring cropland and retired cropland can improve the understanding of the driving factors and consequences of these critical land use change trajectories.}
}
@article{LIU2022624,
title = {Reproductive tissue-specific translatome of a rice thermo-sensitive genic male sterile line},
journal = {Journal of Genetics and Genomics},
volume = {49},
number = {7},
pages = {624-635},
year = {2022},
issn = {1673-8527},
doi = {https://doi.org/10.1016/j.jgg.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1673852722000066},
author = {Wei Liu and Jing Sun and Ji Li and Chunyan Liu and Fuyan Si and Bin Yan and Zhen Wang and Xianwei Song and Yuanzhu Yang and Yuxian Zhu and Xiaofeng Cao},
keywords = {TGMS rice, Translatome, MEL1, Reproductive tissue, Translating ribosome affinity purification (TRAP), Fertility alternation},
abstract = {Translational regulation, especially tissue- or cell type-specific gene regulation, plays essential roles in plant growth and development. Thermo-sensitive genic male sterile (TGMS) lines have been widely used for hybrid breeding in rice (Oryza sativa). However, little is known about translational regulation during reproductive stage in TGMS rice. Here, we use translating ribosome affinity purification (TRAP) combined with RNA sequencing to investigate the reproductive tissue-specific translatome of TGMS rice expressing FLAG-tagged ribosomal protein L18 (RPL18) from the germline-specific promoter MEIOSIS ARRESTED AT LEPTOTENE1 (MEL1). Differentially expressed genes at the transcriptional and translational levels are enriched in pollen and anther-related formation and development processes. These contain a number of genes reported to be involved in tapetum programmed cell death (PCD) and lipid metabolism during pollen development and anther dehiscence in rice, including several encoding transcription factors and key enzymes, as well as several long non-coding RNAs (lncRNAs) that potentially affect tapetum and pollen-related genes in male sterility. This study represents the comprehensive reproductive tissue-specific characterization of the translatome in TGMS rice. These results contribute to our understanding of the molecular basis of sterility in TGMS rice and will facilitate further genetic manipulation of TGMS rice in two-line breeding systems.}
}
@article{B2022103224,
title = {Fractional salp swarm algorithm: An association rule based privacy-preserving strategy for data sanitization},
journal = {Journal of Information Security and Applications},
volume = {68},
pages = {103224},
year = {2022},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2022.103224},
url = {https://www.sciencedirect.com/science/article/pii/S2214212622000989},
author = {Suma B and Shobha G},
keywords = {Privacy preservation, Data sanitization, Association rule, Tanimoto measure, Minkowski distance},
abstract = {Background
Data mining is the process of extracting hidden patterns from huge repositories. Privacy preservation at the time of data shared for mining is a demanding dilemma. Conventional techniques, such as access control and authentication have been used to handle data privacy. Various data sanitization techniques like perturbation, generalization, and sampling are utilized to preserve confidential information from disclosure.
Method
This paper develops a Fractional-Salp swarm algorithm (Fractional-SSA) for data sanitization using privacy preserved data. The Fractional-SSA is developed by integrating Fractional calculus (FC) and the Salp swarm algorithm (SSA). The proposed Fractional-SSA hides sensitive rules considering a large transactional database and recovers the original database against malicious attacks. Here, the random key generation of the sanitization process is performed using the proposed Fractional-SSA algorithm by arbitrarily initializing various keys. In addition, the sanitized database is obtained from sanitization that derives association rules considering certain factors that involve privacy success, information preservation, hiding success, database difference, privacy loss, information loss, hiding failure, and database difference. Finally, the key value gets updated to estimate the best solution. The fitness is obtained using success and failure scenarios.
Results
The proposed Fractional-SSA offered enhanced efficiency providing the highest privacy success of 0.933, information preservation of 0.487, minimal hiding failure of 0.054, and database difference of 0.008.}
}
@article{ROHAAN2022115925,
title = {Using supervised machine learning for B2B sales forecasting: A case study of spare parts sales forecasting at an after-sales service provider},
journal = {Expert Systems with Applications},
volume = {188},
pages = {115925},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115925},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421012793},
author = {D. Rohaan and E. Topan and C.G.M. Groothuis-Oudshoorn},
keywords = {Supervised machine learning, Natural Language Processing (NLP), B2B sales forecasting, Prioritization on sales potential, Information Extraction, Imbalanced data},
abstract = {In this paper, we present a method to use advance demand information (ADI), taking the form of request for quotation (RFQ) data, in B2B sales forecasting. We apply supervised machine learning and Natural Language Processing techniques to analyze and learn from RFQs. We apply and test our approach in a case study at a large after-sales service and maintenance provider. After evaluation we found that our approach identifies ∼ 70% of actual sales (recall) with a precision rate of ∼ 50%, which represents a performance improvement of slightly more than a factor 2.5 over the current labor-intensive manual process at the service and maintenance provider. Our research contributes to literature by giving step-by-step guidance on incorporating artificial intelligence in B2B sales forecasting and revealing potential pitfalls along the way. Furthermore, our research gives an indication of the performance improvement that can be expected when adopting supervised machine learning into B2B sales forecasting.}
}
@article{MONTINI2022661,
title = {An IIoT Platform For Human-Aware Factory Digital Twins},
journal = {Procedia CIRP},
volume = {107},
pages = {661-667},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.042},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122003262},
author = {Elias Montini and Vincenzo Cutrona and Niko Bonomi and Giuseppe Landolfi and Andrea Bettoni and Paolo Rocco and Emanuele Carpanzano},
keywords = {Human Digital Twin (HDT), Cyber Physical Systems (CPS), Industrial Internet of Things (IIoT), Reference Data Model, Industry 5.0},
abstract = {In the context of the Industry 4.0 approach, applications and solutions supporting monitoring, simulation, optimisation and decision-making in production systems are exponentially growing. These solutions are commonly built on digital twins, i.e., comprehensive, structured and effective digital representations of the production system and its entities, whose current status is constantly updated by the plugged data sources. The arising of the Industry 5.0 paradigm and the established key role of workers in manufacturing require new Digital Twins to represent also humans. In fact, as cognitive automation becomes more and more pervasive and its behaviour unintelligible to humans, it becomes essential for improving performance and well-being, at the same time, to model humans as data-driven agents and to represent their interaction with the factory systems. Currently, a standardised solution for creating Digital Twins is missing, forcing industrial solution architects to resort to ad-hoc implementations and models. These solutions lack re-usability, scalability and extensibility, preventing the introduction of a human digital representation in existent twins, so hindering the complete shift to the new Industry 5.0 paradigm. In this paper, such limitations are faced by introducing an extensible and flexible IIoT-industrial internet of things-based platform with a twofold benefit: on the one hand, to support the creation of customised data representations of production systems and their entities including humans; on the other hand, to provide a modular infrastructure, along with its interchangeable components, for easy digital twin instantiation and ramp-up. An implementation of the platform has been tested with different applications in a laboratory setting and released as a public resource. Finally, potential future applications of the proposed digital twin are discussed, highlighting its main benefits.}
}
@article{JAVAID202258,
title = {Significance of machine learning in healthcare: Features, pillars and applications},
journal = {International Journal of Intelligent Networks},
volume = {3},
pages = {58-73},
year = {2022},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2022.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666603022000069},
author = {Mohd Javaid and Abid Haleem and Ravi {Pratap Singh} and Rajiv Suman and Shanay Rab},
keywords = {Machine learning, Data, Healthcare, Patient outcome, Efficiency, Treatment},
abstract = {Machine Learning (ML) applications are making a considerable impact on healthcare. ML is a subtype of Artificial Intelligence (AI) technology that aims to improve the speed and accuracy of physicians' work. Countries are currently dealing with an overburdened healthcare system with a shortage of skilled physicians, where AI provides a big hope. The healthcare data can be used gainfully to identify the optimal trial sample, collect more data points, assess ongoing data from trial participants, and eliminate data-based errors. ML-based techniques assist in detecting early indicators of an epidemic or pandemic. This algorithm examines satellite data, news and social media reports, and even video sources to determine whether the sickness will become out of control. Using ML for healthcare can open up a world of possibilities in this field. It frees up healthcare providers' time to focus on patient care rather than searching or entering information. This paper studies ML and its need in healthcare, and then it discusses the associated features and appropriate pillars of ML for healthcare structure. Finally, it identified and discussed the significant applications of ML for healthcare. The applications of this technology in healthcare operations can be tremendously advantageous to the organisation. ML-based tools are used to provide various treatment alternatives and individualised treatments and improve the overall efficiency of hospitals and healthcare systems while lowering the cost of care. Shortly, ML will impact both physicians and hospitals. It will be crucial in developing clinical decision support, illness detection, and personalised treatment approaches to provide the best potential outcomes.}
}
@article{ZHANG2022106296,
title = {Industrial Development and Economic Impacts of Forest Biomass for Bioenergy: A Data-Driven Holistic Analysis Framework},
journal = {Resources, Conservation and Recycling},
volume = {182},
pages = {106296},
year = {2022},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2022.106296},
url = {https://www.sciencedirect.com/science/article/pii/S0921344922001446},
author = {Xufeng Zhang and Jingxin Wang and Michael P. Strager},
keywords = {Forest biomass, Bioenergy, Holistic framework, Machine learning, Suitability assessment, Economic impacts},
abstract = {A data-driven holistic analysis framework was developed to aid the industrial development of forest biomass for bioenergy to promote the regional bioeconomy. Leveraging the existing but fragmented multi-source data, four components of industrial bioenergy development were integrated into the framework including spatial statistical analysis of biomass feedstock and bioenergy production, machine learning-based suitability assessment, bioenergy plant sites identification and ranking, and socio-economic impacts assessment. A case study was conducted for forest biomass to pellet fuel in the U.S. Mid-Atlantic region. Our results indicate that the great potential of forest biomass with high variation at the county level is primarily clustered in western Pennsylvania and eastern North Carolina. Integrating the datasets of biomass feedstock, road conditions, employment status, income status, population, and current bioenergy production, the machine-learning model demonstrates good performance for bioenergy industry suitability assessment, with the high-suitable areas accounting for 19.76%, medium-suitable areas for 34.74%, and low-suitable areas for 54.49% in the region. Forest biomass availability and distance to major roads are the two top factors affecting bioenergy industry development. We identified 65 industrial sites within the suitable areas and their rankings were derived as a reference of the bioenergy development priority. The socio-economic impacts assessment indicates that the one-year construction of a medium-size pellet fuel facility (75,000 dry tons/year) could create 127 jobs, $8.78 million of labor income, while the operation could create 202 jobs, $10.52 million of labor income, $14.66 million of value-added, and $33.61 million of output in total per year for the state-level economy.}
}
@article{NIU2022107836,
title = {Green manufacturers’ power strategy in the smart grid era},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107836},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107836},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007403},
author = {Baozhuang Niu and Jian Dong and Fanzhuo Zeng},
keywords = {Wind power, Energy procurement, Green operations, Power stability, Dual sourcing},
abstract = {Conventional electricity generation from coal and natural gas is one of the largest greenhouse gas sources and using wind power is an effective way to achieve climate neutrality. Realizing this, green manufacturers such as SC Johnson and Silk decide to use 100% wind power for their manufacture. This enables the manufacturers to receive green certifications and hence, attract more customers. However, wind power can be unstable, so some green manufacturers like New Belgium Brewing purchase power from both the regular power supplier and the wind power supplier, resulting in a discount of market expansion. Modelling this complex system can be challenging that requires the use of meta-heuristic algorithms, so we build a game-theoretic model comprising of a wind power supplier, a regular power supplier and a green manufacturer to examine whether the green manufacturer is more benefited under all-wind power strategy. This helps clarify the strategic perdition about the firms’ equilibrium decisions. We find that the green manufacturer prefers all-wind power strategy when (a) the discount effect is significant and the market potential is greatly expanded; (b) both the discount effect and the market expansion are moderate. We further study the impact of the environmental effect, the improvement of wind power stability and the production cost uncertainty, finding that the main results are qualitatively unchanged.}
}
@article{WANG2022103159,
title = {You are what the permissions told me! Android malware detection based on hybrid tactics},
journal = {Journal of Information Security and Applications},
volume = {66},
pages = {103159},
year = {2022},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2022.103159},
url = {https://www.sciencedirect.com/science/article/pii/S2214212622000485},
author = {Huanran Wang and Weizhe Zhang and Hui He},
keywords = {Android malware detection, Deep learning, Permission sequence},
abstract = {Recent years have witnessed a significant increase in the use of Android devices in many aspects of our life. However, users can download Android apps from third-party channels, which provides numerous opportunities for malware. Attackers utilize unsolicited permissions to gain access to the sensitive private intelligence of users. Since signature-based antivirus solutions no longer meet practical needs, efficient and adaptable solutions are desperately needed, especially in new variants. As a remedy, we propose a hybrid Android malware detection approach that combines dynamic and static tactics. We firstly adopt static analysis inferring different permission usage patterns between malware and benign apps based on the machine-learning-based method. To classify the suspicious apps further, we extract the object reference relationships from the memory heap to construct a dynamic feature base. We then present an improved state-based algorithm based on DAMBA. Experimental results on a real-world dataset of 21,708 apps show that our approach outperforms the well-known detector with 97.5% F1-measure. Besides, our system is demonstrated to resist permission abuse behaviors and obfuscation techniques.}
}
@article{CHANG2022104746,
title = {Micro-fault diagnosis of electric vehicle batteries based on the evolution of battery consistency relative position},
journal = {Journal of Energy Storage},
volume = {52},
pages = {104746},
year = {2022},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2022.104746},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X22007575},
author = {Chun Chang and XiaPing Zhou and Jiuchun Jiang and Yang Gao and Yan Jiang and Tiezhou Wu},
keywords = {Battery pack, Micro-fault diagnosis, Charging cell voltage curve, Consistency, Relative fluctuation},
abstract = {Micro-faults in Li-ion batteries are a safety hazard for battery packs, and accurately identifying micro-faulted batteries is a complex problem to solve. In this paper, we propose a micro-fault diagnosis method based on the evolution of the consistent relative position of cells within multiple charging segments. The CCVC (Charging cell voltage curve) transformation is applied to match the charging voltage curve of each battery with the reference battery, and the particle swarm algorithm obtains the matching transform parameters reflecting the degree of battery consistency with adaptive inertia weights. The transformation parameters are normalized to obtain each battery's relative position Z-Score values in the consistency comparison of the transform parameters. Based on the constant consistency relative position hypothesis, the evolution of the consistency relative position of each cell is scored quantitatively by constructing consistency relative position fluctuation scores. The anomaly detection algorithm based on the 3 − σ criterion is used to identify and locate the micro faulted battery by comparing the scoring results of each battery. The method's effectiveness is verified using the collected actual breakdown vehicle data, and the influence of different reference cells on the technique is analyzed. The results show that the consistency relative position of healthy cells is almost stable over medium-term scales, while the consistency relative position of faulty cells falls. This method can accurately and effectively locate faulty cells even though the battery pack does not exhibit abnormal voltage fluctuations or significant inconsistencies.}
}
@article{TANTSCHER202235,
title = {Digital Retrofitting of legacy machines: A holistic procedure model for industrial companies},
journal = {CIRP Journal of Manufacturing Science and Technology},
volume = {36},
pages = {35-44},
year = {2022},
issn = {1755-5817},
doi = {https://doi.org/10.1016/j.cirpj.2021.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1755581721001760},
author = {Dominik Tantscher and Barbara Mayer},
keywords = {Digital Transformation, Digital Retrofitting, Industry 4.0, Procedure model},
abstract = {Digital Transformation is a demanding evolutional process for industrial companies that touches all important business areas. A central role for the development towards a more flexible and efficient manufacture play production data. However, most machines in use lack a digital interface, such that they are not capable to connect in a network. Thus, data cannot be utilized. One solution from the technical perspective is Digital Retrofitting focusing on the implementation of additional sensors and edge devices to digitally connect the machine and transforming it into a cyber-physical system. This approach is also economically promising for companies since investing in new machines is far more expensive than the retrofitting of legacy systems. Nevertheless, industrial practice shows that Digital Retrofitting projects often do not lead to sustainable solutions because they lack integration into the digital transformation process. This paper thus introduces a holistic procedure model for Digital Retrofitting that is the result of an analysis and clustering of existing process models. The framework incorporates the perspectives on digital strategy, interdisciplinarity, change and lean management and, therefore, provides a guideline for companies leading to a more effective and efficient implementation process with sustainable impact. Furthermore, a description of a successful validation of the procedure model is given on the example of a condition monitoring use case in the Smart Production Lab of FH JOANNEUM.}
}
@article{ZHANG2022121303,
title = {Operationalizing the telemedicine platforms through the social network knowledge: An MCDM model based on the CIPFOHW operator},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121303},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121303},
url = {https://www.sciencedirect.com/science/article/pii/S004016252100737X},
author = {Mengdan Zhang and Chonghui Zhang and Qiule Shi and Shouzhen Zeng and Tomas Balezentis},
keywords = {Telemedicine platform, Multi-criteria decision-making, SERVQUAL, Comprehensive assessment},
abstract = {Telemedicine is an effective way to address the excessive concentration of quality medical resources. Telemedicine platforms provide users with diversified high-quality medical and health services. These issues are topical in the context of the recent pandemic and the resulting socioeconomic transformations. In order to meet the multilevel and personalised health needs of users, optimise the management process of a telemedicine platform and rationally allocate medical resources, it is necessary to conduct scientific evaluations of telemedicine platforms. Therefore, this paper proposes a multi-criteria evaluation framework based on the interval value confidence induced Pythagorean fuzzy ordered hybrid weighted integration (CIPFOHW) operator and social network. To improve the fusion efficiency of user evaluation information and confidence level, the CIPFOHW operator is proposed. At the same time, since the trust relationship between users of the telemedicine platform influence the evaluation, the trust transfer network between users is given. In addition, based on SERVQUAL method, a five-dimension evaluation framework for telemedicine platforms is put forward. Finally, an applied case with five typical patients is used to verify the effectiveness of the method.}
}
@article{WANG2022103013,
title = {A Node Trust Evaluation Method of Vehicle-Road-Cloud Collaborative System Based on Federated Learning},
journal = {Ad Hoc Networks},
pages = {103013},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2022.103013},
url = {https://www.sciencedirect.com/science/article/pii/S1570870522001858},
author = {Denghui Wang and Yuping Yi and Shan Yan and Na Wan and Junhui Zhao},
keywords = {Federated learning, trust evaluation, vehicle-road-cloud collaboration system},
abstract = {As the vehicle-road-cloud collaboration system develops rapidly, it is accompanied by serious information security problems while solving the data transmission issues. For constructing secure transmission of data, trust is recommended as a relevant way to accomplish network security; that is, developing a trust model that can be used by sensor nodes to determine the reliability of another node is crucial. However, the heterogeneity of the network has different functional requirements for trust evaluation, and the openness of the network makes the nodes more vulnerable to attacks. Therefore, the research of trust evaluation model in the vehicle-road-cloud collaborative system is facing greater challenges than the traditional network. In this paper, a trust evaluation scheme of the vehicle-road-cloud collaborative system based on Federated Learning (FLT) is proposed. A hierarchical trust evaluation model is designed, and the complex model is simplified to an orderly hierarchical structure by using hierarchical analysis. The trust indexes of different layers are evaluated, and the influencing factors among different nodes are comprehensively considered. Combined with federated learning, it solves the problem of finding the most reliable route and realizes personalization at the level of equipment, data, and model. For the purpose of alleviating the heterogeneity and obtaining a high-quality personalized model for each device, trust values can be adaptively updated as changes in the topology of the network occur in real-time. The simulation findings demonstrate that, as compared to previous schemes, the energy consumption is lowered by 35%, and the accuracy is raised by 45% while maintaining trust stability.}
}
@article{PROUTSKOVA2022100735,
title = {The Jazz Ontology: A semantic model and large-scale RDF repositories for jazz},
journal = {Journal of Web Semantics},
volume = {74},
pages = {100735},
year = {2022},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2022.100735},
url = {https://www.sciencedirect.com/science/article/pii/S1570826822000245},
author = {Polina Proutskova and Daniel Wolff and György Fazekas and Klaus Frieler and Frank Höger and Olga Velichkina and Gabriel Solis and Tillman Weyde and Martin Pfleiderer and Hèlène Camille Crayencour and Geoffroy Peeters and Simon Dixon},
keywords = {Semantic modelling, Music, Metadata},
abstract = {Jazz is a musical tradition that is just over 100 years old; unlike in other Western musical traditions, improvisation plays a central role in jazz. Modelling the domain of jazz poses some ontological challenges due to specificities in musical content and performance practice, such as band lineup fluidity and importance of short melodic patterns for improvisation. This paper presents the Jazz Ontology – a semantic model that addresses these challenges. Additionally, the model also describes workflows for annotating recordings with melody transcriptions and for pattern search. The Jazz Ontology incorporates existing standards and ontologies such as FRBR and the Music Ontology. The ontology has been assessed by examining how well it supports describing and merging existing datasets and whether it facilitates novel discoveries in a music browsing application. The utility of the ontology is also demonstrated in a novel framework for managing jazz related music information. This involves the population of the Jazz Ontology with the metadata from large scale audio and bibliographic corpora (the Jazz Encyclopedia and the Jazz Discography). The resulting RDF datasets were merged and linked to existing Linked Open Data resources. These datasets are publicly available and are driving an online application that is being used by jazz researchers and music lovers for the systematic study of jazz.}
}
@article{XING2022127079,
title = {Traffic state estimation of urban road networks by multi-source data fusion: Review and new insights},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {595},
pages = {127079},
year = {2022},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2022.127079},
url = {https://www.sciencedirect.com/science/article/pii/S037843712200125X},
author = {Jiping Xing and Wei Wu and Qixiu Cheng and Ronghui Liu},
keywords = {Urban road network, Missing traffic state estimation, Data fusion, Multi-source data application, Systematic review},
abstract = {Accurate traffic state (i.e., flow, speed, density, etc.) on an urban road network is important information for urban traffic control and management strategies. However, due to the limitation of detector installation cost, it is difficult to obtain accurate traffic states through detectors in the whole urban road network with limited detector equipment. In this paper, we review the studies that focus on the missing traffic state estimation problem, especially for the traffic state estimation on the segments without detectors. We provide a way to summarize for readers who have an interest in the different modelling and application of missing traffic state estimation. We first divide the existing studies into three categories: estimation under different missing scenarios, estimation with multi-source data, estimation by fusing different detector types. Then, we summary some existing challenges by the different missing scenarios, data applications, and methodologies. Finally, this work also discusses some future research directions.}
}
@article{YAO2022107757,
title = {KfreqGAN: Unsupervised detection of sequence anomaly with adversarial learning and frequency domain information},
journal = {Knowledge-Based Systems},
volume = {236},
pages = {107757},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107757},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009837},
author = {Yueyue Yao and Jianghong Ma and Yunming Ye},
keywords = {Sequence anomaly detection, Prediction-based method, Adversarial learning, Frequency information},
abstract = {Sequence anomaly detection in time series is of critical importance to wide applications ranging from finance, healthcare to IT system monitoring. Most current researches use the reconstruction-based deep learning algorithms to solve the problem. In this article, we aim to use a prediction-based method to detect sequence anomalies in univariate time series, because the latter methods can detect anomalies using historical information revealing normal patterns in time series whereas the former methods simply consider current sequences. However, it is challenging because there exists both uncertainty in the future and performance deterioration under long detection horizon. To tackle the challenges, we propose an unsupervised algorithm called KfreqGAN, which is based on adversarially trained sequence predictor. The adversarial learning architecture helps the model make accurate predictions for future sequences. In addition, auxiliary information from frequency domain is used to help the model capture the characteristics of time series for achieving satisfactory predictions. We conduct extensive experiments on two public-available datasets, with results demonstrating the effectiveness of the proposed algorithm and its superiority to baseline algorithms.}
}
@article{HERRERASEMENETS2022107963,
title = {A fast instance reduction algorithm for intrusion detection scenarios},
journal = {Computers and Electrical Engineering},
volume = {101},
pages = {107963},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107963},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622002397},
author = {Vitali Herrera-Semenets and Raudel Hernández-León and Jan {van den Berg}},
keywords = {Instance selection, Data reduction, Intrusion detection, Data preprocessing, Data mining, Supervised classification},
abstract = {We live in a world that is being driven by data. This leads to challenges of extracting and analyzing knowledge from large volumes of data. An example of such a challenge is intrusion detection. Intrusion detection data sets are characterized by huge volumes, which affects the learning of the classifier. So there is a need to reduce the size of the training sets. Fortunately, inspection and analysis of available intrusion detection data sets showed that many instances are very similar and do not provide relevant information to the classification process. This prompted to look for possibilities to use a fast algorithm that, as much as possible, removes similar instances in intrusion detection data sets while enforcing the detection rate. In this work, a new fast instance reduction algorithm is presented. The proposed algorithm provides greater efficiency during the training stage, without significantly affecting the efficacy during the intrusion detection task.}
}
@article{SGUEGLIA2022170,
title = {A systematic literature review of IoT time series anomaly detection solutions},
journal = {Future Generation Computer Systems},
volume = {134},
pages = {170-186},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22001285},
author = {Arnaldo Sgueglia and Andrea {Di Sorbo} and Corrado Aaron Visaggio and Gerardo Canfora},
keywords = {IoT, Internet of Things, Anomaly detection, Time series},
abstract = {The rapid spread of the Internet of Things (IoT) devices has prompted many people and companies to adopt the IoT paradigm, as this paradigm allows the automation of several processes related to data collection and monitoring. In this context, the sensors (or other devices) generate huge amounts of data while monitoring physical spaces and objects. Therefore, the problem of managing and analyzing these huge amounts of data has stimulated researchers and practitioners to adopt anomaly detection techniques, which are automated solutions to enable the recognition of abnormal behaviors occurring in complex systems. In particular, in IoT environments, anomaly detection very often involves the analysis of time series data and this analysis should be accomplished under specific time or resource constraints. In this systematic literature review, we focus on the IoT time series anomaly detection problem by analyzing 62 articles written from 2014 to 2021. Specifically, we explore the methods and techniques adopted by researchers to deal with the issues related to dimensionality reduction, anomaly localization, and real-time monitoring, also discussing the datasets used, and the real-case scenarios tested. For each of these topics, we highlight potential limitations and open issues that need to be addressed in future work.}
}
@article{GUO2022127367,
title = {Construction of rapid early warning and comprehensive analysis models for urban waterlogging based on AutoML and comparison of the other three machine learning algorithms},
journal = {Journal of Hydrology},
volume = {605},
pages = {127367},
year = {2022},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2021.127367},
url = {https://www.sciencedirect.com/science/article/pii/S0022169421014177},
author = {Yuchen Guo and Lihong Quan and Lili Song and Hao Liang},
keywords = {Urban waterlogging, Automatic machine learning algorithm based on genetic algorithms, Rapid early warning, XGBoost, CatBoost, BPDNN, Comprehensive analysis},
abstract = {Urban waterlogging often causes urban disasters, and the rapid early warning and comprehensive analysis of the urban waterlogging can help disaster defenses. However, the warning of waterlogging through the monitoring data cannot give grid distribution and the forecast of hydrological models cannot ensure rapid early warning. To obtain a grid rapid early warning result for a region, like an urban area, a method needs to be proposed which can meet the above problems. In this research, AutoML (automatic machine learning based on genetic algorithm) was recommended to construct the rapid early warning and comprehensive analysis models for urban waterlogging by compared with the other three machine learning algorithms, CatBoost (Categorical Boosting), XGBoost (eXtreme Gradient Boosting), and BPDNN (Back Propagation Deep Learning Neural Network). In the models, the forecast and historical precipitation obtained from the Integrated Nowcasting through Comprehensive analysis system (INCA), the difference of elevation, and the urban waterlogging risk maps provided by Tianjin Meteorological Administration were employed as the input sources. The input precipitation duration was determined as 12 h based on the sensitivity analysis of the influence of various precipitation duration on waterlogging depths. Due to the non-digital (discrete dataset) features, the urban waterlogging risk maps were transformed to the weight of each corresponding risk level according to the area of each risk level and the number of samples falling in each risk level. The difference of elevation was characterized by the average elevations of various distances from the points of concern. The output waterlogging depths were compared with the waterlogging depths monitored in Tianjin, China, whose quality was controlled by eliminating the records of the waterlogging depths lasting for a long time after the end of rainfall. The comparison of the models constructed by different methods demonstrated that the AutoML performed better (NSE and R2 > 0.92, CC > 0.95, RMSE1.1–1.9 cm) than the other three models. The forecast waterlogging depths by AutoML was also coherent with the monitoring waterlogging depths (NSE and R2 ≥ 0.9, CC ≥ 0.95, RMSE 1.7–2.2 cm). For that local topography and waterlogging risk are considered, the AutoML models can be used in the area without the monitoring of water level, quickly predict waterlogging depths and give spatial grid results for rapidly early warning.}
}
@article{MA2022147,
title = {Data modeling and querying with fuzzy sets: A systematic survey},
journal = {Fuzzy Sets and Systems},
volume = {445},
pages = {147-183},
year = {2022},
note = {Logic and Databases},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2022.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0165011422000203},
author = {Zongmin Ma and Li Yan},
keywords = {Database models, XML, Fuzzy sets, Fuzzy data modeling, Querying},
abstract = {Uncertainty extensively exists in data and knowledge intensive applications, in which fuzzy information processing plays a crucial role. Fuzzy sets have been extensively used to enhance various database models for managing fuzzy data or flexibly querying crisp data. This has resulted in numerous contributions in this research area. This paper pays attention to three crucial issues in fuzzy techniques for data management: modeling fuzzy data, querying fuzzy data, and fuzzy queries over crisp data, and provides a full up-to-date survey on the current state of the art in fuzzy data modeling and querying. The paper identifies fuzzy conceptual data models, fuzzy (relational and object-oriented) database models and fuzzy XML model as well as the relationships among these fuzzy data models. For each type of fuzzy data models, the paper summarizes its query processing. The paper also reviews fuzzy querying over classical data models. In addition to providing a generic overview of the approaches for fuzzy data modeling and querying, this survey paper serves for identifying possible research opportunities in the area of fuzzy data processing.}
}
@article{WILSON2022101652,
title = {Public engagement and AI: A values analysis of national strategies},
journal = {Government Information Quarterly},
volume = {39},
number = {1},
pages = {101652},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101652},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000885},
author = {Christopher Wilson},
keywords = {Public engagement, Public values, Public value management, Artificial intelligence, Technology frames, Technology policy, Participation, Open government},
abstract = {Calls for public engagement and participation in AI governance align strongly with a public value management approach to public administration. Simultaneously, the prominence of commercial vendors and consultants in AI discourse emphasizes market value and efficiency in a way often associated with the private sector and New Public Management. To understand how this might influence the consolidation of AI governance regimes and decision-making by public administrators, 16 national strategies for AI are subjected to content analysis. References to the public's role and public engagement mechanisms are mapped across national strategies, as is the articulation of values related to professionalism, efficiency, service, engagement, and the private sector. Though engagement rhetoric is common, references to specific engagement mechanisms and activities are rare. Analysis of value relationships highlights congruence of engagement values with professionalism and private sector values, and raises concerns about neoliberal technology frames that normalize AI, obscuring policy complexity and trade-offs.}
}
@article{LIU2022106856,
title = {Context2Vector: Accelerating security event triage via context representation learning},
journal = {Information and Software Technology},
volume = {146},
pages = {106856},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106856},
url = {https://www.sciencedirect.com/science/article/pii/S095058492200026X},
author = {Jia Liu and Runzi Zhang and Wenmao Liu and Yinghua Zhang and Dujuan Gu and Mingkai Tong and Xingkai Wang and Jianxin Xue and Huanran Wang},
keywords = {Context modeling, Event triage, Topic model, Representation learning},
abstract = {Context:
Security teams are overwhelmed by thousands of alerts and events everyday, which are comprehensively collected for threat analysis in security operations center. Although methods based on rules, intelligence and data mining are utilized, the alert fatigue situation is still a challenging problem, slowing down the overall threat investigation process.
Objective:
‘Event polysemy’ phenomenon broadly exists in large-scale event dataset, which means that events of the same category can reveal different purposes in different contexts. This paper aims at exploring, revealing and evaluating the latent patterns embedding in the event contexts, to gain insight on context semantics and reduce manual intervention in event triage tasks.
Method:
A context representation learning based method, named Context2Vector, is proposed. Contexts are extracted from multiple behavioral views. Then, both dense event representations and sparse topic representations are learnt at the same time and in the same space. A human-in-the-loop topic annotation process is involved and finally, a context deviation detection based method is integrated to generate explainable and informative labels for automated context semantic decoding.
Results:
Various experiments are conducted on a enterprise-scale event dataset. The topic annotation, context related feature importance and top-N event ranking evaluation results show that Context2Vector outperforms traditional methods on the high-risk event identification problems, improving the attacker recall rate by up to 2.25 times within limited events to be investigated.
Conclusion:
It is concluded that event contexts imply practicable and abundant information in regard to behaviors and intents of real threat actors. More precise profiling of network entities can be extracted from contexts, compared to rules, intelligence, and anomaly detectors used in practice.}
}
@article{LIN2022103650,
title = {Cultivating proactive information security behavior and individual creativity: The role of human relations culture and IT use governance},
journal = {Information & Management},
volume = {59},
number = {6},
pages = {103650},
year = {2022},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2022.103650},
url = {https://www.sciencedirect.com/science/article/pii/S0378720622000623},
author = {Canchu Lin and Jenell L.S. Wittmer and Xin (Robert) Luo},
keywords = {Proactive information security behavior, Individual creativity, IT use governance, Human relations culture},
abstract = {This study developed the concept of proactive information security behavior and examined its connections with individual creativity and two organizational context factors: human relations culture (values and beliefs that promote participation and autonomy in decision-making) and IT use governance. Reliability and validity of this construct were tested with survey data. Findings of this study support its positive relationship with individual creativity, human relations culture, and IT use governance, and show partial mediation effects of individual creativity on the relationships between human relations culture and IT use governance, and proactive information security behavior. Theoretical and practice implications are discussed.}
}
@article{YIN2022107106,
title = {Impact of gamification elements on user satisfaction in health and fitness applications: A comprehensive approach based on the Kano model},
journal = {Computers in Human Behavior},
volume = {128},
pages = {107106},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107106},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221004295},
author = {Siqi Yin and Xianling Cai and Ziyang Wang and Yuning Zhang and Shenghui Luo and Jingdong Ma},
keywords = {Gamification, User satisfaction, Kano model, Health and fitness apps},
abstract = {As health and fitness applications (apps) take on larger markets, attracting and satisfying users has become a crucial task. Gamification, a popular ancillary design used in various fields, was gradually introduced into apps to make the products more attractive and practical. As previous studies mainly focused on the mechanism or efficiency merely on specific gamification elements (GE), heterogeneity was prominent, and scope was limited. Hence, this study comprehensively arranges GE into four dimensions. The main objective is to determine the correlation between gamification dimensions and user satisfaction. Natural language process and sentimental analysis were used in online reviews (N = 45,659) of a typical fitness app to build a hierarchical conception vocabulary of gamification words, elements, and dimensions, as well as calculate the degree of elements’ realization. Meanwhile, Kano model–based questionnaires (n = 110) quantitatively classified GE into different quality classifications. A user satisfaction score was provided at the end to quantitatively measure the correlation between GE and user satisfaction, demonstrating that different dimensions corresponded to a different level of contribution to user satisfaction (non-negative, stable positive, limitation, and uncertain). Furthermore, suggestions for designing strategy were given as an instructor for further improvement and design.}
}
@article{MERKERT2022100797,
title = {The impact of engine standardization on the cost efficiency of airlines},
journal = {Research in Transportation Business & Management},
pages = {100797},
year = {2022},
issn = {2210-5395},
doi = {https://doi.org/10.1016/j.rtbm.2022.100797},
url = {https://www.sciencedirect.com/science/article/pii/S2210539522000189},
author = {Rico Merkert},
keywords = {Fleet/engine standardization, Airline performance, DEA, Cost efficiency, Competitive advantage},
abstract = {Fleet standardization, which refers to the homogeneity and harmonization of the fleet in terms of the number of manufacturers and models, as a strategy has been deployed across many sectors, including airline operations. Given that engines are substantial aircraft components in terms of both capital and operating cost, representing nearly 50% of the aerospace aftermarket, we investigate whether – and to what extent – standardization strategies in the context of engines can improve cost efficiency of the airline industry. Using engine data of 12,305 aircraft and financial data of years with high (2013/14) and low (2016/17) fuel prices, we apply bootstrapped Data Envelopment Analysis (DEA) followed by random effects panel regression analysis to 84 airlines across the globe. Our quantitative findings are validated by qualitative stakeholder interviews. Our results suggest that both airframe and engine commonality impact on airline cost efficiency, but that engine cost effects are significantly larger in magnitude than standard airframe cost effects. In contrast to current management practices focusing exclusively on airframe commonality and tactical activities (such as renegotiating supplier and maintenance contracts), we demonstrate that an engine standardization strategy (through procurement, storage, retirement, maintenance and spare part optimization) improves the cost competitiveness and efficiency of airlines in an OEM servitized world.}
}
@article{ZHANG2022108745,
title = {Relationships between 3D urban form and ground-level fine particulate matter at street block level: Evidence from fifteen metropolises in China},
journal = {Building and Environment},
volume = {211},
pages = {108745},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108745},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321011343},
author = {Anqi Zhang and Chang Xia and Weifeng Li},
keywords = {3D urban form, Surface PM, Spatial metrics, Street block, Comparative analysis},
abstract = {Substantial efforts have been devoted to exploring the effects of urban form on fine particulate matter (PM2.5), but the complexity has been far away from being fully understood. The current remarkable inconsistencies with regards to measurements, ascertainment, and findings make the evidence across continents, regions, or cities be necessary to verify the robustness and generalizability of urban form effects. Besides, existing measurements of urban form are often unsystematic and limit analyses in both horizontal and vertical dimensions. In this paper, fifteen metropolises in China were selected to examine the relationships between three-dimensional (3D) urban form and PM2.5 concentrations at the street block level, using 3D spatial metrics and multivariate linear regression. Satellite-derived surface PM2.5 estimates of fine spatial resolution, building footprint, and multiple geographic open datasets were used. Our results demonstrated that urban form effects hold for the metropolises in China, and street accessibility, length of road segments, topography, urban vegetation, surrounding open and green spaces, and transportation facilities were found to be the influential factors of the concentrations of PM2.5. We also revealed the complicated and place-varying effects of urban form indicators, represented by the largely different or opposite effects of many urban form indicators in different cities. For example, building density, building height, and land use mixture have relatively limited and inconsistent effects in most cities. Results of this work suggest critical reflections on some of the current ideas that have been accepted to be vital for improving PM2.5.}
}
@article{YAGLI2022111909,
title = {Ensemble solar forecasting and post-processing using dropout neural network and information from neighboring satellite pixels},
journal = {Renewable and Sustainable Energy Reviews},
volume = {155},
pages = {111909},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111909},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121011734},
author = {Gokhan Mert Yagli and Dazhi Yang and Dipti Srinivasan},
keywords = {Dropout neural network, Ensemble solar forecasting, Machine learning, Monte Carlo sampling, Post-processing, Satellite-derived irradiance},
abstract = {Ensemble weather forecasts are often found to be under-dispersed and biased. Post-processing using spatio-temporal information is, therefore, required if one wishes to improve the quality of the raw forecasts. It is on this account that the present article generates and post-processes ensemble solar forecasts using satellite-derived irradiance not only from the focal pixel but also from the neighboring pixels. The ensemble forecasting model of choice is a dropout neural network with Monte Carlo sampling, eliminating the need for training multiple models and ensuring parameter diversity in ensemble forecasting. Subsequently, ensemble forecasts are post-processed using both parametric and nonparametric post-processing techniques, such as nonhomogenous regression, generalized additive model, linear quantile regression, or quantile random forests. The proposed forecasting framework is demonstrated and verified using four years of half-hourly data, at seven locations in the United States. Continuous ranked probability skill scores as high as 66% have been obtained when comparing the proposed method to a conditional climatology reference. The content of this article may be useful to a wide range of stakeholders in the power system, including but not limited to: independent system operators, who aim at efficiently maintaining the system’s reliability; utility- and distributed-scale PV plant owners, who wish to avoid penalties for power deviation between the scheduled and real-time delivery; and forecast retailers, who can benefit from selling solar forecasts of higher quality.}
}
@article{LI2022344,
title = {Spectral index-driven FCN model training for water extraction from multispectral imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {192},
pages = {344-360},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2022.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0924271622002283},
author = {Zhenshi Li and Xueliang Zhang and Pengfeng Xiao},
keywords = {Water delineation, Spectral index, Sentinel-2, Semantic labeling, Deep fully convolutional network},
abstract = {Terrestrial water is a fundamental component of the land surface. Accurate and robust water delineation of surface water is rather challenging due to the high intra-class variability and the spectral similarity with shadows and other dark surfaces. This study proposes a new method called the water index-driven deep fully convolutional neural network (WIDFCN) for high-accuracy water delineation with no need to collect samples manually. We formulate water delineation as a semantic labeling problem and solve it by training a deep fully convolutional network (FCN), whose capability of effectively extracting multilevel spatial and spectral features is exploited for discriminating water from complex surroundings. The main obstacle of using FCN, which requires a large volume of labeled training samples, is settled by utilizing the water recognition ability of the water spectral index (WI). Specifically, the training samples are automatically generated from WI by extracting a high-precision but incomplete water mask at first, which is then expanded to enhance the completeness. This strategy ensures the high quality of the automatically generated training samples and thus the water extraction performance of the trained FCN model. Twelve test sites from Sentinel-2 imagery with various water delineation challenges all over the world are used to assess the performance relative to that of supervised and unsupervised classification methods and water spectral index thresholding methods, in terms of Kappa coefficient, precision, recall, and F1-score. Overall, WIDFCN can achieve the highest precision and comparable recall, leading to the best water delineation accuracy with Kappa coefficient 0.9673 and F1-score 0.9696, as well as the lowest fluctuation in terms of various test sites. The results further demonstrate that WIDFCN can effectively deal with the scale and spectra variance of surface water, and has distinct robustness with respect to different kinds of shadows, including building, mountain, and cloud shadows. The findings in this study demonstrate a novel, robust, low-cost, and manual labor-free water delineation method that performs well in terms of both precision and completeness. Moreover, the core idea could provide a reference for extraction of geographic information by utilizing FCN models with no needs of manually labeling costs. Code and data will be available at https://github.com/LZhenShi/WIDFCN.}
}
@article{RANI2022118085,
title = {An efficient format-independent watermarking framework for large-scale data sets},
journal = {Expert Systems with Applications},
volume = {208},
pages = {118085},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118085},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422012829},
author = {Sapana Rani and Raju Halder},
keywords = {Digital watermarking, Large-scale data sets, MapReduce, Pig, Hive},
abstract = {In this paper, we propose an efficient distortion-free watermarking of large-scale data sets in various formats by exploiting the power of parallel and distributed computing environment. In particular, we adapt MapReduce, Pig and Hive paradigms for the data in CSV, XML and JSON formats by identifying key computational steps involved in the sequential watermarking algorithms. Following this, we design a middleware which allows watermark generation and verification (under any computing paradigm of user’s choice) of large-scale data sets (in any suitable format of user’s interest) and their conversion without affecting the watermark. The experimental evaluation on large-scale benchmark data sets shows a significant reduction of watermark generation and verification times. Interestingly, in case of XML and JSON formats, Pig and Hive outperform the MapReduce paradigm, whereas MapReduce shows better performance in case of CSV format. To the best of our knowledge, this is the first proposal towards large-scale data sets watermarking, considering popular distributed computing paradigms and data formats.}
}
@article{BESSEN2022104513,
title = {The role of data for AI startup growth},
journal = {Research Policy},
volume = {51},
number = {5},
pages = {104513},
year = {2022},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2022.104513},
url = {https://www.sciencedirect.com/science/article/pii/S0048733322000415},
author = {James Bessen and Stephen Michael Impink and Lydia Reichensperger and Robert Seamans},
keywords = {Artificial intelligence, Competition, Data, Algorithms, Venture capital},
abstract = {Artificial intelligence (AI)-enabled products are expected to drive economic growth. Training data are important for firms developing AI-enabled products; without training data, firms cannot develop or refine their algorithms. This is particularly the case for AI startups developing new algorithms and products. However, there is no consensus in the literature on which aspects of training data are most important. Using unique survey data of AI startups, we find a positive correlation between having proprietary training data and obtaining future venture capital funding. Moreover, this correlation is greater for startups in markets where data is a major advantage and for startups using more sophisticated algorithms, such as neural networks and ensemble learning.}
}
@article{WANG2022126099,
title = {The role of machine learning to boost the bioenergy and biofuels conversion},
journal = {Bioresource Technology},
volume = {343},
pages = {126099},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2021.126099},
url = {https://www.sciencedirect.com/science/article/pii/S0960852421014413},
author = {Zhengxin Wang and Xinggan Peng and Ao Xia and Akeel A. Shah and Yun Huang and Xianqing Zhu and Xun Zhu and Qiang Liao},
keywords = {Bioenergy, Biofuels, Machine learning, Lignocellulosic biomass, Algae},
abstract = {The development and application of bioenergy and biofuels conversion technology can play a significant role for the production of renewable and sustainable energy sources in the future. However, the complexity of bioenergy systems and the limitations of human understanding make it difficult to build models based on experience or theory for accurate predictions. Recent developments in data science and machine learning (ML), can provide new opportunities. Accordingly, this critical review provides a deep insight into the application of ML in the bioenergy context. The latest advances in ML assisted bioenergy technology, including energy utilization of lignocellulosic biomass, microalgae cultivation, biofuels conversion and application, are reviewed in detail. The strengths and limitations of ML in bioenergy systems are comprehensively analysed. Moreover, we highlight the capabilities and potential of advanced ML methods when encountering multifarious tasks in the future prospects to advance a new generation of bioenergy and biofuels conversion technologies.}
}
@article{EMARA2022310,
title = {Workflow for building interoperable food and nutrition security (FNS) data platforms},
journal = {Trends in Food Science & Technology},
volume = {123},
pages = {310-321},
year = {2022},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2022.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0924224422001133},
author = {Yasmine Emara and Barbara {Koroušić Seljak} and Eileen R. Gibney and Gorjan Popovski and Igor Pravst and Peter Fantke},
keywords = {Data integration, Interoperability criteria, FNS-Cloud, Ontology, Machine learning, Natural language processing, Branded food data},
abstract = {Background
In response to growing needs for the integration of heterogeneous data on food and nutrition security (FNS), and the current fragmentation of interoperability resources, the ‘FNS-Cloud project’ aims to develop a cross-domain, interoperable data platform that integrates diverse FNS data. Currently, there is insufficient guidance on how to develop such an FNS data platform and integrate a variety of FNS data types that differ in both their syntax and semantics.
Scope and approach
In the present study, we propose a generalizable workflow to guide data managers in building interoperable, cross-domain FNS data platforms, which centres around the definition of interoperability criteria that capture standardized data structures, terminologies and reporting formats for key variables across FNS data types. Information technology tools for automating different workflow steps are discussed. Finally, we include an illustrative case study, where we harmonize and link branded food datasets based on pre-defined interoperability criteria to answer an example research question.
Key findings and conclusions
Our work highlights the unique harmonization requirements within the FNS field. We provide two examples of how generic and domain-specific interoperability criteria addressing these requirements can be defined. Incoming FNS data must comply with defined criteria in order to enable their (semi-)automated integration into any data platform. Our case study reinforces the importance of semantic annotation of FNS data, and the need for clear mapping rules to be included into platform-internal semantic data models. The proposed workflow can be applied to any setting in which data managers strive towards harmonized and linked FNS data, and, thus, promotes an open-data and open-science environment.}
}
@article{YANG2022105366,
title = {IoT data analytics in dynamic environments: From an automated machine learning perspective},
journal = {Engineering Applications of Artificial Intelligence},
volume = {116},
pages = {105366},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105366},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622003803},
author = {Li Yang and Abdallah Shami},
keywords = {IoT data analytics, AutoML, Concept drift, Machine learning},
abstract = {With the wide spread of sensors and smart devices in recent years, the data generation speed of the Internet of Things (IoT) systems has increased dramatically. In IoT systems, massive volumes of data must be processed, transformed, and analyzed on a frequent basis to enable various IoT services and functionalities. Machine Learning (ML) approaches have shown their capacity for IoT data analytics. However, applying ML models to IoT data analytics tasks still faces many difficulties and challenges, specifically, effective model selection, design/tuning, and updating, which have brought massive demand for experienced data scientists. Additionally, the dynamic nature of IoT data may introduce concept drift issues, causing model performance degradation. To reduce human efforts, Automated Machine Learning (AutoML) has become a popular field that aims to automatically select, construct, tune, and update machine learning models to achieve the best performance on specified tasks. In this paper, we conduct a review of existing methods in the model selection, tuning, and updating procedures in the area of AutoML in order to identify and summarize the optimal solutions for every step of applying ML algorithms to IoT data analytics. To justify our findings and help industrial users and researchers better implement AutoML approaches, a case study of applying AutoML to IoT anomaly detection problems is conducted in this work. Lastly, we discuss and classify the challenges and research directions for this domain.}
}
@article{PIAO20222,
title = {An ultra low-input method for global RNA structure probing uncovers Regnase-1-mediated regulation in macrophages},
journal = {Fundamental Research},
volume = {2},
number = {1},
pages = {2-13},
year = {2022},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S2667325821003113},
author = {Meiling Piao and Pan Li and Xiaomin Zeng and Xi-Wen Wang and Lan Kang and Jinsong Zhang and Yifan Wei and Shaojun Zhang and Lei Tang and Jianghui Zhu and Chun Kit Kwok and Xiaoyu Hu and Qiangfeng Cliff Zhang},
keywords = {RNA structure probing method, Low-input, RNA structure element, Macrophage, RNA structure, RNA structurome},
abstract = {To enable diverse functions and precise regulation, an RNA sequence often folds into complex yet distinct structures in different cellular states. Probing RNA in its native environment is essential to uncovering RNA structures of biological contexts. However, current methods generally require large amounts of input RNA and are challenging for physiologically relevant use. Here, we report smartSHAPE, a new RNA structure probing method that requires very low amounts of RNA input due to the largely reduced artefact of probing signals and increased efficiency of library construction. Using smartSHAPE, we showcased the profiling of the RNA structure landscape of mouse intestinal macrophages upon inflammation, and provided evidence that RNA conformational changes regulate immune responses. These results demonstrate that smartSHAPE can greatly expand the scope of RNA structure-based investigations in practical biological systems, and also provide a research paradigm for the study of post-transcriptional regulation.}
}
@article{JIA2022233,
title = {A meteorologically adjusted ensemble Kalman filter approach for inversing daily emissions: A case study in the Pearl River Delta, China},
journal = {Journal of Environmental Sciences},
volume = {114},
pages = {233-248},
year = {2022},
note = {Atmospheric Chemistry in the Complex Air Pollution},
issn = {1001-0742},
doi = {https://doi.org/10.1016/j.jes.2021.08.048},
url = {https://www.sciencedirect.com/science/article/pii/S1001074221003521},
author = {Guanglin Jia and Zhijiong Huang and Xiao Tang and Jiamin Ou and Menghua Lu and Yuanqian Xu and Zhuangmin Zhong and Qing'e Sha and Huangjian Wu and Chuanzeng Zheng and Tao Deng and Duohong Chen and Min He and Junyu Zheng},
keywords = {Emission inversion, Daily emissions, Meteorological adjustment, Ensemble Kalman filter},
abstract = {The conventional Ensemble Kalman filter (EnKF), which is now widely used to calibrate emission inventories and to improve air quality simulations, is susceptible to simulation errors of meteorological inputs, making accurate updates of high temporal-resolution emission inventories challenging. In this study, we developed a novel meteorologically adjusted inversion method (MAEInv) based on the EnKF to improve daily emission estimations. The new method combines sensitivity analysis and bias correction to alleviate the inversion biases caused by errors of meteorological inputs. For demonstration, we used the MAEInv to inverse daily carbon monoxide (CO) emissions in the Pearl River Delta (PRD) region, China. In the case study, 60% of the total CO simulation biases were associated with sensitive meteorological inputs, which would lead to the overestimation of daily variations of posterior emissions. Using the new inversion method, daily variations of emissions shrank dramatically, with the percentage change decreased by 30%. Also, the total amount of posterior CO emissions estimated by the MAEInv decreased by 14%, indicating that posterior CO emissions might be overestimated using the conventional EnKF. Model evaluations using independent observations revealed that daily CO emissions estimated by MAEInv better reproduce the magnitude and temporal patterns of ambient CO concentration, with a higher correlation coefficient (R, +37.0%) and lower normalized mean bias (NMB, -17.9%). Since errors of meteorological inputs are major sources of simulation biases for both low-reactive and reactive pollutants, the MAEInv is also applicable to improve the daily emission inversions of reactive pollutants.}
}
@article{BOKHORST2022108599,
title = {Assessing to what extent smart manufacturing builds on lean principles},
journal = {International Journal of Production Economics},
volume = {253},
pages = {108599},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2022.108599},
url = {https://www.sciencedirect.com/science/article/pii/S0925527322001827},
author = {Jos A.C. Bokhorst and Wilfred Knol and Jannes Slomp and Thomas Bortolotti},
keywords = {Smart manufacturing, Industry 4.0, Lean principles, Operational performance, Necessary condition analysis},
abstract = {This study explores to what extent the adoption and performance of smart manufacturing technologies builds on the adoption of lean principles. Primary explorative survey data on the level of adoption of smart manufacturing technologies and lean principles and various operational performance outcomes were collected from a set of Dutch manufacturers and analysed using Cluster Analysis, ANOVA, and Necessary Condition Analysis (NCA). The Cluster Analysis shows that while lean is also applied without smart (“lean-only” companies), smart technologies are mostly applied in conjunction with lean (“lean and smart” companies), suggesting that the presence of lean principles is necessary for smart implementation. A third group of companies shows a low use of lean and smart (“non-adopters”). The NCAs further specify the extent of this necessity by showing that all individual smart manufacturing technologies used in our construct require presence of lean principles, with MES systems having the strongest dependency. Performance wise, lean-only and lean and smart companies have comparable superior performance compared to non-adopters when considering an aggregate operational performance measure using the dimensions of quality, delivery, flexibility and cost. When analysed separately, the aggregate level results remain true for quality and delivery performance. However, for flexibility, the superiority of lean-only companies is more apparent, while for cost, lean and smart companies are superior. This shows that implementing smart requires lean, but lean may suffice depending on the specific performance objectives strived for.}
}
@article{YAN2022112519,
title = {Uncovering wind power forecasting uncertainty sources and their propagation through the whole modelling chain},
journal = {Renewable and Sustainable Energy Reviews},
volume = {165},
pages = {112519},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112519},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122004221},
author = {Jie Yan and Corinna Möhrlen and Tuhfe Göçmen and Mark Kelly and Arne Wessel and Gregor Giebel},
keywords = {Wind power, Forecast uncertainty, Modelling chain},
abstract = {Wind power forecasting has supported operational decision-making for power system and electricity markets for 30 years. Efforts of improving the accuracy and/or certainty of deterministic or probabilistic wind power forecasts are continuously exerted by academics and industries. Forecast errors and associated uncertainties propagating through the whole forecasting chain, from weather provider to end user, cannot be eliminated completely. Therefore, understanding the uncertainty sources and how these uncertainties propagate throughout the modelling chain is significant to implement more rational and targeted uncertainty mitigation strategies and standardise the forecast and uncertainty validation. This paper presents a qualitative review on wind power forecasting uncertainty. First, the definition of uncertainty sources throughout the forecast modelling chain acts as a guiding line for checking and evaluating the uncertainty of a wind power forecast system/model. For each of the types of uncertainty sources, uncertainty mitigation strategies are provided, starting from the planning phase of wind farms, the establishment of a forecasting system through the operational phase and market phase. Our review finalises with a discussion on uncertainty validation with an example on ramp forecast validation. Highlights are a qualitative review and discussion including: (1) forecasting uncertainty exists and propagates everywhere throughout the entire modelling chain, from the planning phase to the market phase; (2) the mitigation efforts should be exerted in every modelling step; (3) standardised uncertainty validation practice, including why global data samples are required for forecasters to improve model performance and for forecast users to select and evaluate forecast model outputs.}
}
@article{CHENG2022201,
title = {OPTDP: Towards optimal personalized trajectory differential privacy for trajectory data publishing},
journal = {Neurocomputing},
volume = {472},
pages = {201-211},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.04.137},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016271},
author = {Wenqing Cheng and Ruxue Wen and Haojun Huang and Wang Miao and Chen Wang},
keywords = {Trajectory data publishing, Personalized differential privacy, Semantic similarity, Privacy level},
abstract = {With the development of location-based applications, more and more trajectory data are collected. Trajectory data often contains users’ sensitive information, and direct release it may pose a threat to users’ privacy. Differential privacy, as a privacy preserving method with solid mathematical foundation, has been widely used in trajectory data publishing. However, current trajectory data publishing methods based on differential privacy cannot fully realize the personalized privacy protection. In this paper, an optimal personalized trajectory differential privacy mechanism is proposed. Firstly, by establishing the probabilistic mobility model of trajectories, we cluster the locations to achieve semantic location matching between different trajectories. Based on the semantic similarity, we identify the templet trajectory, and propose a privacy level allocation method based on stay-points and frequent sub-trajectories. Then, according to the location matching results, we can automatically identify the privacy level of all locations. Combined with the optimal location differential privacy mechanism, we disturb the location points on the user’s trajectory before publishing, where different location privacy levels correspond to different privacy budgets. Experiment results on real-world datasets show that our mechanism provides a better tradeoff between privacy protection and data utility compared with traditional differential privacy methods.}
}
@article{QAVIDELFARD2022111771,
title = {Application of machine learning in thermal comfort studies: A review of methods, performance and challenges},
journal = {Energy and Buildings},
volume = {256},
pages = {111771},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111771},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821010550},
author = {Zahra {Qavidel Fard} and Zahra Sadat Zomorodian and Sepideh Sadat Korsavi},
keywords = {Thermal comfort, Machine learning, Group-based models, Personal comfort models, Performance, Prediction accuracy},
abstract = {This paper provides a systematic review on the application of Machine Learning (ML) in thermal comfort studies to highlight the latest methods and findings and provide an agenda for future studies. Reviewed studies were investigated to highlight ML applications, parameters, methods, performance and challenges. The results show that 62% of reviewed studies focused on developing group-based comfort models, while 35% focused on personal comfort models (PCMs) which account for individual differences and present high prediction accuracy. ML models could outperform PMV and adaptive models with up to 35.9% and 31% higher accuracy and PCMs could outperform PMV models with up to 74% higher accuracy. Applying ML-based control schemas reduced thermal comfort-related energy consumption in buildings up to 58.5%, while improving indoor quality up to 90% and reducing CO2 levels up to 24%. Using physiological parameters improved the prediction accuracy of PCMs up to 97%. Future studies are recommended to further investigate PCMs, determine the optimum sample size and consider both fitting and error metrics for model evaluation. This study introduces data collection, thermal comfort indices, time scale, sample size, feature selection, model selection, and real world application as the remaining challenges in the application of ML in thermal comfort studies.}
}
@article{GUNGOR2022103660,
title = {STEWART: STacking Ensemble for White-Box AdversaRial Attacks Towards more resilient data-driven predictive maintenance},
journal = {Computers in Industry},
volume = {140},
pages = {103660},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103660},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000574},
author = {Onat Gungor and Tajana Rosing and Baris Aksanli},
keywords = {Cybersecurity in Industrial IoT, Predictive maintenance, Adversarial machine learning, Ensemble learning},
abstract = {Industrial Internet of Things (I-IoT) is a network of devices that focus on monitoring industrial assets and continuously collecting data. This data can be utilized by Machine Learning (ML) methods to perform Predictive Maintenance (PDM) which identifies an optimal maintenance schedule for the industrial assets. The computational systems in the I-IoT are usually not designed with security in mind. Their limited computational power creates security vulnerabilities that attackers can exploit to prevent asset availability, sabotage communication, and corrupt system data. In this work, we first demonstrate that cyber-attacks can impact the performance of ML-based PDM methods significantly, leading up to 120 × prediction performance loss. Next, we develop a stacking ensemble learning-based framework that stays resilient against various white-box adversarial attacks. The results show that our framework performs well in the presence of cyber-attacks and has up to 60% higher resiliency compared to the most resilient individual ML method.}
}
@article{ZHANG2022101008,
title = {Machine learning-facilitated multiscale imaging for energy materials},
journal = {Cell Reports Physical Science},
volume = {3},
number = {9},
pages = {101008},
year = {2022},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2022.101008},
url = {https://www.sciencedirect.com/science/article/pii/S2666386422002995},
author = {Guo-Xu Zhang and Yajie Song and Wei Zhao and Hanwen An and Jiajun Wang},
keywords = {artificial intelligence, computed tomography, energy materials, image segmentation, machine learning, microscopy imaging},
abstract = {Summary
The relationship between the structure of a material and its properties, the so-called structure-property correlations, is at the center of materials science. The microstructure of a material is an essential feature for the optimization of physicochemical properties with improved performance. However, it remains a challenge to recognize and extract all relevant information from microscopic images. Machine learning (ML) has entered the field of multiscale characterization and visualization in energy materials. The aim of this review is to provide concise tutorials on multiscale imaging techniques and ML methods, showing how they can be incorporated for solving physical and chemical problems. With a particular focus on image segmentation, we discuss noteworthy applications of ML in X-ray and electron microscopy imaging for rechargeable batteries, solar cells, and fuel cells and discuss how ML can facilitate identifying microstructures, enhancing image quality, and tracking dynamic processes occurring both inside and at the materials interfaces.}
}
@article{ZHANG2022101204,
title = {The Situational Nature of Impulse Buying on Mobile Platforms: A Cross-Temporal Investigation},
journal = {Electronic Commerce Research and Applications},
pages = {101204},
year = {2022},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2022.101204},
url = {https://www.sciencedirect.com/science/article/pii/S1567422322000874},
author = {Lin Zhang and Zhen Shao and Jing Zhang and Xiaotong Li},
keywords = {digital marketing, impulse purchase, S-O-R framework, website quality, price attributes, situational stimulus},
abstract = {While online impulse buying has attracted increasing attentions from researchers, there is still limited research that investigates consumers’ impulse buying behavior across different situations. Categorizing external stimuli into three types (website, marketing and situational stimuli), our study examines their joint influences on consumers’ affective and cognitive reactions as well as their online impulse buying behavior. Our empirical findings indicate that the positive effects of website stimuli and marketing stimuli on consumers’ internal reactions exhibit significant variations based on a situational stimulus (i.e., a non-holiday season versus a holiday season). Specifically, consumers react more sensitively to perceived website quality to form both hedonic and utilitarian values during the non-holiday season, while they focus more on prices to judge utilitarian value rather than hedonic value during the holiday season. Furthermore, our results suggest that the cascading mediation effects of consumers’ internal responses vary greatly between the non-holiday season and the holiday season.}
}
@article{YULI20221159,
title = {Identify impacting factor for urban rail ridership from built environment spatial heterogeneity},
journal = {Case Studies on Transport Policy},
volume = {10},
number = {2},
pages = {1159-1171},
year = {2022},
issn = {2213-624X},
doi = {https://doi.org/10.1016/j.cstp.2022.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S2213624X22000785},
author = {Xiang {Yu Li} and Gobi {Krishna Sinniah} and Ruiwei Li},
keywords = {Built environment, Spatial heterogeneity, Urban rail system, GWR, Kuala Lumpur},
abstract = {The urban rail system is significant for the urban transport system due to its faster, dedicated lane and mass capacity feature. Many countries or cities devout build it to relieve urban traffic pressure. In an urban rail system, the station is one of the most vital elements because directly relative to station availability and user’s accessibility. This paper identifies the urban rail station spatial heterogeneity from the built environment for passenger flow under five variables that select Kuala Lumpur as a case study. Under this foundation, this paper measures and typologies the spatial heterogeneity based on the built environment by Geographic Weighting Regression (GWR). The result indicates that selecting indicator will impact the ridership but has an apparent spatial heterogeneity because the impacting situation is different in various station catchment areas even measuring variables are the same. According to this outcome, we could tangibly recognize the urban rail system station’s built environment and the impacting factor and the specific impacting ability distribution. That benefits improving or optimizing this system more efficiently from the micro-level, generating more ridership to enhance urban rail operating performance and relieve urban traffic stress.}
}
@article{ASLAM2022101120,
title = {The use of local climate zones in the urban environment: A systematic review of data sources, methods, and themes},
journal = {Urban Climate},
volume = {42},
pages = {101120},
year = {2022},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2022.101120},
url = {https://www.sciencedirect.com/science/article/pii/S2212095522000384},
author = {Ayman Aslam and Irfan Ahmad Rana},
keywords = {Climate change adaptation, Climate risk mapping, Sustainable development, Urban planning},
abstract = {The concept of local climate zones (LCZ) has emerged to identify the nature of urban climate, air quality, and temperature at local levels. Thus, this study reviews the literature on methodologies and data sources used in LCZs empirical research and identifies recurrent themes. A systematic review was conducted using bibliometric analysis and the PRISMA framework. Web of Science and Scopus databases were used to extract relevant datasets, and records were screened and extracted. Descriptive analyses reveal that most LCZ empirical research has been done on Chinese cities. Numerous data sources and analytical methods have been used, but Landsat and WUDAPT methodology is generally favored in the LCZ research due to its simplicity and freely available global datasets. Similarly, the review also shows that various software and methodologies are available to identify climate-sensitive areas of urban settlements with varying functionalities, accuracy, and visualizations. The thematic analysis indicates that the LCZ framework and its associated processes are being used in crosscutting phenomena such as thermal comfort, urban planning, climate change adaptation, and energy use. The review also suggests incorporating institutional and social aspects in local climate zones. LCZs can integrate the philosophies of climate change adaptation, urban resilience, and sustainability.}
}
@article{WAGAN2022,
title = {Internet of medical things and trending converged technologies: A comprehensive review on real-time applications},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822003263},
author = {Shiraz Ali Wagan and Jahwan Koo and Isma Farah Siddiqui and Muhammad Attique and Dong Ryeol Shin and Nawab Muhammad Faseeh Qureshi},
keywords = {Internet of medical things, Technology convergence, Real-time applications, Machine learning, Artificial intelligence, Cloud computing},
abstract = {The Internet of Medical Things (IoMT) facilitates patients with all-time-connected medical devices through cost-effective solutions and a feeling of comfort with round-the-clock hospital support. The patients who cannot visit hospitals for routine checkups prefer the usage of IoMT devices. The healthcare facilities also rely on the real-time statistics of IoMT machines and diagnose problems and their solutions within a small interval of time. This could only be possible when a robust convergence of technologies is used with IoMT devices. This review study discusses how we may apply the convergence of IoMT devices with trending technologies and focuses on delivering a new dimension of novel IoMT usage through broad multi-homing dense networks. It also discusses various applied machine learning algorithms available in the healthcare industry. It compares a variety of disease predictions and the accuracy of the equipment and decision recommendations. The review study also discusses various IoMT convergence open challenges and opportunities through the labor industry healthcare system.}
}
@article{JULIO20221299,
title = {Long term assessment of a successful e-bike-sharing system. Key drivers and impact on travel behaviour},
journal = {Case Studies on Transport Policy},
volume = {10},
number = {2},
pages = {1299-1313},
year = {2022},
issn = {2213-624X},
doi = {https://doi.org/10.1016/j.cstp.2022.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S2213624X22000943},
author = {Raky Julio and Andres Monzon},
keywords = {Bike-sharing, Travel patterns, Cycling behaviour, Electric bicycles, Cycling factors, System evolution},
abstract = {The many benefits of cycling, such as eco-friendliness, low cost, health benefits, and efficiency in congested areas, had encouraged governmental strategies to promote it, triggering a global growth of bike-sharing systems (BSS). In this line, it is important to avoid service termination by assessing the evolution, identifying drawbacks and success factors, that could be determinant on the system’s future. Nonetheless, in many cases, subjective and objective information regarding BSS was not collected nor compared. In this study, we analyse the evolution of Madrid’s pioneer electric system, by combining the subjective data of three surveys, conducted since 2014 to 2019, with objective data from the service operator. The insights extracted shed light on the key factors determining the system’s success, and its influence on travel behaviour. Results suggest that the user profile of the young early adopters evolved to middle-aged workers. Strong maintenance campaigns and network expansions improved bikes availably and user satisfaction. Slope of the streets is one of the lowest importance factors, whereas pedelec assistance the highest. It is likely to believe that there is a relationship between both, suggesting that electric assistance encourages cycling in a hilly city like Madrid. Transferable experiences to other cities evolving from traditional to e-BSS could be valuable, like the results suggesting that the introduction of an electric BSS is a potential trigger for bicycle adoption in dense urban environments. In addition, that subscribers tend to reduce the use of private car while increase cycling. This longitudinal analysis offers valuable policy implications, like those related with bike maintenance, network extension, and measures focused on keeping the new subscribers of the COVID-19 post-lockdown.}
}
@article{CAI2022101086,
title = {Flood forecasting in urban reservoir using hybrid recurrent neural network},
journal = {Urban Climate},
volume = {42},
pages = {101086},
year = {2022},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2022.101086},
url = {https://www.sciencedirect.com/science/article/pii/S2212095522000049},
author = {Bo Cai and Yaoxiang Yu},
keywords = {Reservoir flood, Machine learning, Hybrid learning model, Real-time forecasting, Forecast system},
abstract = {Flood forecasting can provide accurate inferences and early warnings for flood control work during the flood season. Due to the variability of local rainfall and the complexity of geographic conditions, existing prediction methods were unable to accurately predict the flooding process in a particular basin. Additionally, the water level sensor generates a significant amount of noise in the inbound flow data during period measurement. To address these issues, this article proposes a real-time flood forecasting model, which is used to accurately predict flood trends and peak times in the flood period. The model uses a convolution kernel function to smooth out local noise and neighborhood values, minimizing the impact of non-stationary series on the training process while retaining the true evolution of the flood in the original data. In our model, we develop a time series attention mechanism that is used to apply various weights to time series input vectors, such as outflow flow and rainfall from upstream reservoirs, this mechanism also improves the accuracy of short-term series prediction. To obtain additional information about the output of the recurrent neural network layer, we also include a multivariate autoregressive integrated moving average module. This method can add a linear component to the output, allowing the prediction result to adapt to the input period's scale shift. This article develops matching models for interval and full basin floods based on the geographical characteristics of China's urban Reservoir and the river basin, thresholds are established based on the outflow from upstream reservoirs, which enables the flood forecasting system to dynamically adjust model parameters in response to the threshold, it also circumvents the scaling problem inherent in flood time series at various scales. We trained and predicted using 25 different types of floods in Ankang Reservoir from 2010 to 2020. Three on-site real-time forecasts of catastrophic flooding at the Ankang Reservoir were conducted in September 2021 to validate the model's accuracy. The algorithm's efficiency in forecasting flood inflows is demonstrated through comparisons to traditional hydrological models and other machine learning networks, and our model consistently forecasts the peak time and total flood volume with the least amount of error in the comparison algorithm.}
}
@article{FRIEDERICH2022103586,
title = {A framework for data-driven digital twins of smart manufacturing systems},
journal = {Computers in Industry},
volume = {136},
pages = {103586},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103586},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521001937},
author = {Jonas Friederich and Deena P. Francis and Sanja Lazarova-Molnar and Nader Mohamed},
keywords = {Data-driven, Digital twin, Machine learning, Process mining, Reconfigurable manufacturing, Smart factory},
abstract = {Adoption of digital twins in smart factories, that model real statuses of manufacturing systems through simulation with real time actualization, are manifested in the form of increased productivity, as well as reduction in costs and energy consumption. The sharp increase in changing customer demands has resulted in factories transitioning rapidly and yielding shorter product life cycles. Traditional modeling and simulation approaches are not suited to handle such scenarios. As a possible solution, we propose a generic data-driven framework for automated generation of simulation models as basis for digital twins for smart factories. The novelty of our proposed framework is in the data-driven approach that exploits advancements in machine learning and process mining techniques, as well as continuous model improvement and validation. The goal of the framework is to minimize and fully define, or even eliminate, the need for expert knowledge in the extraction of the corresponding simulation models. We illustrate our framework through a case study.}
}
@article{ASKARI2022188,
title = {Intelligent systems using triboelectric, piezoelectric, and pyroelectric nanogenerators},
journal = {Materials Today},
volume = {52},
pages = {188-206},
year = {2022},
issn = {1369-7021},
doi = {https://doi.org/10.1016/j.mattod.2021.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S1369702121004326},
author = {Hassan Askari and Nan Xu and Bruno Henrique {Groenner Barbosa} and Yanjun Huang and Longping Chen and Amir Khajepour and Hong Chen and Zhong Lin Wang},
keywords = {Nanogenerators, Intelligent systems, Machine learning, Self-powered sensing, Artificial intelligence},
abstract = {Recent advances in artificial intelligence, computer science, communication, sensing and actuation technologies have resulted in the development of several novel intelligent systems. At the same time, the emergence of nanogenerators has opened a new research avenue with the overarching goal of developing self-powered sensing systems. The concepts of self-powered sensing, based on nanogenerators and intelligent systems can be fused together to open a new area of interdisciplinary research. In this article, we aim to show how these two emerging technologies have been combined to develop self-powered intelligent sensing systems. We first focus on the main keywords in the area of nanogenerators. Keyword co-occurrence network graphs are generated based on the most used keywords in the area of nanogenerators to select key concepts that are directly connected to the concept of intelligent systems. Thus, a detailed review is provided on different intelligent self-powered sensing systems based on nanogenerators. We also discuss the challenges presented by combining intelligent systems and self-powered sensing. As most of intelligent devices rely on machine learning techniques, a comprehensive section is allocated to this topic to focus on its applications in nanogenerator-based devices.}
}
@article{WEI2022694,
title = {Generating training images with different angles by GAN for improving grocery product image recognition},
journal = {Neurocomputing},
volume = {488},
pages = {694-705},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.11.080},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221017550},
author = {Yuchen Wei and Shuxiang Xu and Byeong Kang and Sabera Hoque},
keywords = {Grocery product recognition, Data augmentation, Generative adversarial network (GAN), Convolutional neural network (CNN)},
abstract = {Image recognition based on deep learning methods has gained remarkable achievements by feeding with abundant training data. Unfortunately, collecting a tremendous amount of annotated images is time-consuming and expensive, especially in grocery product recognition tasks. It is challenging to recognise grocery products accurately when the deep learning model is trained with insufficient data. This paper proposes multi-angle Generative Adversarial Networks (MAGAN), which can generate realistic training images with different angles for data augmentation. Mutual information is employed in the novel GAN to achieve the learning of angles in an unsupervised manner. This paper aims to create training images containing grocery products from different angles, thus improving grocery product recognition accuracy. We first enlarge the fruit dataset by using MAGAN and the state-of-the-art GAN variants. Then, we compare the top-1 accuracy results from CNN classifiers trained with different data augmentation methods. Finally, our experiments demonstrate that the MAGAN exceeds the existing GANs for grocery product recognition tasks, obtaining a significant increase in the accuracy.}
}
@article{WANG202269,
title = {FORSETI: A visual analysis environment enabling provenance awareness for the accountability of e-autopsy reports},
journal = {Visual Informatics},
volume = {6},
number = {3},
pages = {69-80},
year = {2022},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2022.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X22000407},
author = {Baoqing Wang and Noboru Adachi and Issei Fujishiro},
keywords = {Computational forensics, Legal medicine, Accountability, Provenance, Immersive analytics, Authority},
abstract = {Autopsy reports play a pivotal role in forensic science. Medical examiners (MEs) and diagnostic radiologists (DRs) cross-reference autopsy results in the form of autopsy reports, while judicial personnel derive legal documents from final autopsy reports. In our prior study, we presented a visual analysis system called the forensic autopsy system for e-court instruments (FORSETI) with an extended legal medicine markup language (x-LMML) that enables MEs and DRs to author and review e-autopsy reports. In this paper, we present our extended work to incorporate provenance infrastructure with authority management into FORSETI for forensic data accountability, which contains two features. The first is a novel provenance management mechanism that combines the forensic autopsy workflow management system (FAWfMS) and a version control system called lmmlgit for x-LMML files. This management mechanism allows much provenance data on e-autopsy reports and their documented autopsy processes to be individually parsed. The second is provenance-supported immersive analytics, which is intended to ensure that the DRs’ and MEs’ autopsy provenances can be viewed, listed, and analyzed so that a principal ME can author their own report through accountable autopsy referencing in an augmented reality setting. A fictitious case with a synthetic wounded body is used to demonstrate the effectiveness of the provenance-aware FORSETI system in terms of data accountability through the experience of experts in legal medicine.}
}
@article{CULICGAMBIROZA2022101842,
title = {Dynamic monitoring frequency for energy-efficient data collection in Internet of Things},
journal = {Journal of Computational Science},
volume = {64},
pages = {101842},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101842},
url = {https://www.sciencedirect.com/science/article/pii/S1877750322002010},
author = {Jelena {Čulić Gambiroža} and Toni Mastelić and Ivana {Nižetić Kosović} and Mario Čagalj},
keywords = {Dynamic monitoring frequency, Sensor data, Internet of Things, Energy efficiency},
abstract = {With growth of Internet of Things, number of connected sensors increases as well, along with data being collected by those sensors. Most sensors are battery powered and commonly collect data in short and equally spaced time periods resulting with large amount of redundant and often irrelevant data. In this paper, we propose a dynamic monitoring frequency (DMF) algorithm that aims at collecting data only when sensor readings change by more than a predefined value between consecutive readings. Thus, a sensor is turned on only when a change in monitored phenomenon value exceeds a predefined threshold. Two algorithms are analyzed, namely statistical and machine learning. DMF shows notable performance, resulting either with up to ∼70% less missed readings, or it collects up to ∼40% less data compared to the baseline algorithm that collects data with static monitoring frequency.}
}
@article{TAO2022100344,
title = {Proximal and remote sensing in plant phenomics: 20 years of progress, challenges, and perspectives},
journal = {Plant Communications},
pages = {100344},
year = {2022},
issn = {2590-3462},
doi = {https://doi.org/10.1016/j.xplc.2022.100344},
url = {https://www.sciencedirect.com/science/article/pii/S2590346222000992},
author = {Haiyu Tao and Shan Xu and Yongchao Tian and Zhaofeng Li and Yan Ge and Jiaoping Zhang and Yu Wang and Guodong Zhou and Xiong Deng and Ze Zhang and Yanfeng Ding and Dong Jiang and Qinghua Guo and Shichao Jin},
keywords = {plant phenomics, remote sensing, phenotyping, phenotypic traits, multi-omics, breeding, precision cultivation},
abstract = {Plant phenomics (PP) has been recognized as a bottleneck in studying the interactions of genomics and environment on plants, limiting the progress of smart breeding and precise cultivation. High-throughput plant phenotyping is challenging owing to the spatio-temporal dynamics of traits. Proximal and remote sensing (PRS) techniques are increasingly used for plant phenotyping because of their advantages in multi-dimensional data acquisition and analysis. Substantial progress of PRS applications in PP has been observed over the last two decades and is analyzed here from an interdisciplinary perspective based on 2972 publications. This progress covers most aspects of PRS application in PP, including patterns of global spatial distribution and temporal dynamics, specific PRS technologies, phenotypic research fields, working environments, species, and traits. Subsequently, we demonstrate how to link PRS to multi-omics studies, including how to achieve multi-dimensional PRS data acquisition and processing, how to systematically integrate all kinds of phenotypic information and derive phenotypic knowledge with biological significance, and how to link PP to multi-omics association analysis. Finally, we identify three future perspectives for PRS-based PP: (1) strengthening the spatial and temporal consistency of PRS data, (2) exploring novel phenotypic traits, and (3) facilitating multi-omics communication.}
}
@article{LNENICKA2022101745,
title = {Benchmarking open data efforts through indices and rankings: Assessing development and contexts of use},
journal = {Telematics and Informatics},
volume = {66},
pages = {101745},
year = {2022},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2021.101745},
url = {https://www.sciencedirect.com/science/article/pii/S0736585321001842},
author = {Martin Lnenicka and Mariusz Luterek and Anastasija Nikiforova},
keywords = {Open data, Benchmarking, Index, Ranking, Development, Indicator},
abstract = {This paper aims to provide a broad perspective on the development of benchmarking open data efforts through indices and rankings over the years, both at the level of countries and allowing for a cross-country comparison. The methodology follows a systematic search for the relevant resources, their classification and identification of six open data benchmarks to be further analyzed, the identification of their key components through decomposition, their description, and identifying the similarities and differences. Three major groups of indices and four periods that characterize the efforts to benchmark and measure the development of open data are identified, where the first measure the openness of the selected categories of data, the second focuses on different aspects of the open data ecosystem, using a large number of variables, and the third is a combination of both approaches. Recommendations as well as trends that can form the benchmarking frameworks in the future are also discussed. The findings are of a high importance for individual countries, which allow for correct and accurate interpretation of the results changes in the scope of a given index or rank, i.e., whether the difference in results is the result of national efforts or the subject of changes in the specific index, as well as how to combine and interpret the results of a number of indices for correct decision-making and for the definition of the future actions where the results vary significantly. In addition, the findings are also important for international organizations publishing benchmarking reports.}
}
@article{KIM2022103773,
title = {Does roadwork improve road speed? Evidence from urban freeways in California},
journal = {Regional Science and Urban Economics},
volume = {93},
pages = {103773},
year = {2022},
issn = {0166-0462},
doi = {https://doi.org/10.1016/j.regsciurbeco.2022.103773},
url = {https://www.sciencedirect.com/science/article/pii/S0166046222000047},
author = {Jinwon Kim},
keywords = {Traffic volume, Speed, Roadwork, Lane closure, Traffic congestion},
abstract = {This paper estimates the effects of roadwork on road speed and traffic volume using panel data from urban freeways in California. The empirical model is specified to identify the dynamic responses of road speed and traffic volume to a shift in the cost curve generated by roadwork. The estimates indicate that roadwork increases road speed shortly after the roadwork is completed, but this effect does not last longer than one year. Traffic volume does not immediately respond to roadwork but does increase after around one year. These empirical results support the “induced-demand hypothesis” of Downs (1962, 1992). This paper also quantifies the time-cost savings of roadwork to evaluate public spending on freeways. It is concluded that the congestion-relieving effect of roadwork alone is not enough to justify the state's large expenditures on roadwork.}
}
@article{LIU2022130960,
title = {DeepSniffer: A meta-learning-based chemiresistive odor sensor for recognition and classification of aroma oils},
journal = {Sensors and Actuators B: Chemical},
volume = {351},
pages = {130960},
year = {2022},
issn = {0925-4005},
doi = {https://doi.org/10.1016/j.snb.2021.130960},
url = {https://www.sciencedirect.com/science/article/pii/S0925400521015288},
author = {Chuanjun Liu and Hitoshi Miyauchi and Kenshi Hayashi},
keywords = {Chemiresistive sensor array, Meta learning, Deep metric learning, Siamese network, Aroma oil, Recognition and classification},
abstract = {A meta-learning algorithm, conventionally used for visual recognition, was applied to the recognition and classification of aroma oils. A printable chemiresistive sensor array was fabricated, based on composites of carbon black with various active materials. Standard aromatherapy kits with 30 types of essential oils were used as targets in an odor sensing experiment. Benefiting from the pattern recognition ability of the fabricated sensor array, a high-quality dataset was obtained with 30 aroma oil classes, in which each class had nine replicate samples. A deep metric learning model, based on a Siamese neural network and a multilayer perceptron, was used to perform the N-way k-shot meta-learning. A test accuracy of over 98.7% was obtained for 31-way 9-shot learning, on discriminating whether the input pair samples were taken from similar or dissimilar classes. The model was effective in extracting meta-features of the aroma oils; this was proved by the improved clustering effect of samples in the spaces of principal components analysis and t-distributed stochastic neighbor embedding. The 30 aroma oils were divided into two datasets according to 6-fold cross-validation: 25 aroma oil classes (plus one blank class) as seen classes for constructing 26-way 9-shot learning models and the remaining five aroma oils as unseen classes for prediction. Average accuracies of 93.5% and 93.9% were achieved for recognition of the unseen aroma oils from the seen classes and classification of the unseen aroma oils themselves, respectively, demonstrating the effectiveness of the developed sensor and model for odor recognition and classification.}
}
@article{LU2022106022,
title = {Using computer vision to recognize composition of construction waste mixtures: A semantic segmentation approach},
journal = {Resources, Conservation and Recycling},
volume = {178},
pages = {106022},
year = {2022},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2021.106022},
url = {https://www.sciencedirect.com/science/article/pii/S0921344921006303},
author = {Weisheng Lu and Junjie Chen and Fan Xue},
keywords = {Construction and demolition waste, Waste composition, Construction waste management, Artificial intelligence, Computer vision, Semantic segmentation},
abstract = {Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.}
}
@article{REIS2022117510,
title = {Predicting the lifetime of Lithium–Ion batteries: Integrated feature extraction and modeling through sequential Unsupervised-Supervised Projections (USP)},
journal = {Chemical Engineering Science},
volume = {252},
pages = {117510},
year = {2022},
issn = {0009-2509},
doi = {https://doi.org/10.1016/j.ces.2022.117510},
url = {https://www.sciencedirect.com/science/article/pii/S000925092200094X},
author = {Marco S. Reis and Benben Jiang},
keywords = {Lithium-ion batteries, Battery lifetime prediction, Battery degradation, Predictive analytics, Feature extraction, Latent variable modeling},
abstract = {Lithium-ion batteries are among the most used rechargeable batteries in the market, from portable electronics, and mobility solutions to process industry and aerospace. The ability to accurately predict battery lifetime and health status is of great interest for R&D activities, quality control & product release, predictive maintenance and recycling, among others. However, the complexity and multiplicity of degradation modes and usage/charging conditions raise considerable challenges to the construction of robust predictive models for battery lifecycle prediction. In this work, we propose an integrated methodology that is able to extract operational features and use them in the scope of a predictive model. Results demonstrate the superior feature extraction and accuracy of the proposed approach based only on the discharge information collected in the early usage periods (40–60 cycles), an aspect of practical interest. Data used regard commercial high-power LFP/graphite A123 cells, with nominal capacity of 1.1Ah and nominal voltage of 3.3 V.}
}
@article{MENG2022106207,
title = {Intelligent disassembly of electric-vehicle batteries: a forward-looking overview},
journal = {Resources, Conservation and Recycling},
volume = {182},
pages = {106207},
year = {2022},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2022.106207},
url = {https://www.sciencedirect.com/science/article/pii/S0921344922000556},
author = {Kai Meng and Guiyin Xu and Xianghui Peng and Kamal Youcef-Toumi and Ju Li},
keywords = {Electric vehicle battery, disassembly, recycling, artificial intelligence, machine learning, sustainability},
abstract = {Retired electric-vehicle lithium-ion battery (EV-LIB) packs pose severe environmental hazards. Efficient recovery of these spent batteries is a significant way to achieve closed-loop lifecycle management and a green circular economy. It is crucial for carbon neutralization, and for coping with the environmental and resource challenges associated with the energy transition. EV-LIB disassembly is recognized as a critical bottleneck for mass-scale recycling. Automated disassembly of EV-LIBs is extremely challenging due to the large variety and uncertainty of retired EV-LIBs. Recent advances in artificial intelligence (AI) machine learning (ML) provide new ways for addressing these problems. This study aims to provide a systematic review and forward-looking perspective on how AI/ML methodology can significantly boost EV-LIB intelligent disassembly for achieving sustainable recovery. This work examines the key advances and research opportunities of emerging intelligent technologies for EV-LIB disassembly, and recycling and reuse of industrial products in general. We show that AI could benefit the whole disassembly process, particularly addressing the uncertainty and safety issues. Currently, EV-LIB state prognostics, disassembly decision-making as well as target detection are indicated as promising areas to realize intelligence. The challenges still exist for extensive autonomy due to present AI's inherent limitations, mechanical and chemical complexities, and sustainable benefits concerns. This paper provides the practical map to direct how to implement EV-LIB intelligent disassembly as well as forward-looking perspectives for addressing these challenges.}
}
@article{CHALE2022117936,
title = {Generating realistic cyber data for training and evaluating machine learning classifiers for network intrusion detection systems},
journal = {Expert Systems with Applications},
volume = {207},
pages = {117936},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117936},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422011757},
author = {Marc Chalé and Nathaniel D. Bastian},
keywords = {Generative machine learning, Generative adversarial network, Variational autoencoder, Synthetic data generation, Network intrusion detection},
abstract = {Cyberspace operations, in conjunction with artificial intelligence and machine learning enhanced cyberspace infrastructure, make it possible to connect sensors directly to shooters independent of human control. These technologies serve as the pivot around which cyber data from the military’s Internet of Battlefield Things, for example, will be turned into actionable insight and knowledge and, ultimately, an information advantage for the military. As such, network intrusion detection systems must detect, evaluate, and respond to malicious cyber traffic at machine speed. Generative adversarial networks and variational autoencoders are fit as generative models with labeled cyber data from a real military enterprise network. These generative models are used to create realistic, synthetic cyber data. A combination of real and synthetic cyber data sets are then used to train several machine learning models for network intrusion detection. Purely synthetic data is shown to be statistically similar to the real data. There is no statistically significant difference in the performance of classifiers trained with real data versus a combination of real and synthetic data; however, classifiers trained with only synthetic data underperformed. To avoid a decrease in intrusion detection performance, classifiers must be trained with at least 15% real data.}
}
@article{YAN2022,
title = {Private owners’ propensity to engage in shared parking schemes under uncertainty: comparison of alternate hybrid expected utility-regret-rejoice choice models},
journal = {Transportation Letters},
year = {2022},
issn = {1942-7867},
doi = {https://doi.org/10.1080/19427867.2022.2088568},
url = {https://www.sciencedirect.com/science/article/pii/S1942786722005094},
author = {Qianqian Yan and Tao Feng and Harry Timmermans},
keywords = {Shared parking, owners, propensity, hybrid expected utility-regret-rejoice models, perception},
abstract = {ABSTRACT
To develop effective strategies for the supply of shared parking and study various theoretical choice models under uncertainty, this paper investigates private parking space owners’ propensity to engage in shared parking schemes using a stated choice experiment that involves an uncertain key attribute. A hybrid expected utility-regret model incorporating rejoice is specified to explore the participation behavior. Equivalent models considering the perception of attribute differences are also estimated. Results show that socio-demographic characteristics, social influence, government’s role, media attention, platform fee, and revenues are all important factors explaining private parking owners’ propensity to engage in shared parking schemes. Besides, the model incorporating all these components, including the emotions of regret and rejoice and the perception of attribute differences, yields the best results. These findings could help promote the policy development toward increasing people’s engagement in shared parking.}
}
@article{ZHOU2022103909,
title = {A comprehensive study of speed prediction in transportation system: From vehicle to traffic},
journal = {iScience},
volume = {25},
number = {3},
pages = {103909},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.103909},
url = {https://www.sciencedirect.com/science/article/pii/S2589004222001791},
author = {Zewei Zhou and Ziru Yang and Yuanjian Zhang and Yanjun Huang and Hong Chen and Zhuoping Yu},
keywords = {Algorithms, Engineering, Transportation engineering},
abstract = {Summary
In the intelligent transportation system (ITS), speed prediction plays a significant role in supporting vehicle routing and traffic guidance. Recently, a considerable amount of research has been devoted to a single-level (e.g., traffic or vehicle) prediction. However, a systematic review of speed prediction in and between different levels is still missing. In this article, existing research is comprehensively analyzed and divided into three levels, i.e. macro traffic, micro vehicles, and meso lane. In addition, this article summarizes the influencing factors and reviews the prediction methods based on how those methods utilize the available information to meet the challenges of the prediction at different levels. This is followed by a summary of evaluation metrics, public datasets, and open-source codes. Finally, future directions in this field are discussed to inspire and guide readers. This article aims to draw a complete picture of speed prediction and promote the development of ITS.}
}
@article{WANG2022123189,
title = {Energy consumption characteristics based driving conditions construction and prediction for hybrid electric buses energy management},
journal = {Energy},
volume = {245},
pages = {123189},
year = {2022},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2022.123189},
url = {https://www.sciencedirect.com/science/article/pii/S0360544222000925},
author = {Yue Wang and Keqiang Li and Xiaohua Zeng and Bolin Gao and Jichao Hong},
keywords = {Hybrid electric buses, Energy management, Energy consumption characteristics, Driving condition information},
abstract = {The energy consumption characteristics of driving condition is very important for hybrid electric buses energy management. In this paper, an energy consumption characteristics based driving conditions construction and prediction method was proposed. Under connected vehicular-cloud environment, missing data and noise data was processed by BP neural network method and wavelet transform method, respectively. According to the proposed the analysis method of energy consumption characteristics, the 7 characteristic parameters of the driving conditions related to energy consumption characteristics were extracted from 30 parameters. Based on the extracted characteristic parameters considering energy consumption, driving conditions construction and prediction were developed. In the driving cycle construction, it is found that the characteristic parameters error is less than 5% by comparing the original constructed cycles. Thus, the construction driving cycle can reflect the actual driving characteristics. In the driving cycle prediction, the prediction combining least squares support vector machine with BP neural network is proposed and compared with different topologies. The root mean square error of the proposed prediction model is 0.22 km/h, achieving the best prediction performance. Finally, energy management using the above driving condition information can significantly improve the energy economy.}
}
@article{CHEN2022107365,
title = {Short-term wind speed forecasting based on long short-term memory and improved BP neural network},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {134},
pages = {107365},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107365},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521006049},
author = {Gonggui Chen and Bangrui Tang and Xianjun Zeng and Ping Zhou and Peng Kang and Hongyu Long},
keywords = {Short-term Wind Speed Forecasting, Data Preprocessing, Fuzzy Entropy (FE), LSTM, Improved Sparrow Search Algorithm-BP (ISSA-BP)},
abstract = {Accurate and reasonable wind speed prediction system has a significant impact on the utilization of wind energy. A novel combination forecasting model based on Long Short-Term Memory (LSTM) network and BP neural network is designed in this paper. This model combines the principle of deep learning algorithm and the improved BP neural network to deal with nonlinear wind speed prediction. Before the prediction, singular spectrum analysis (ssa) and complete ensemble empirical model decomposition adaptive noise (CEEMDAN) are selected as the data pretreatment part to de-noise the original wind speed data and decompose it into multiple components. This part is conducive to improving the signal-to-noise ratio (SNR) of wind speed data and simplifying the characteristics of wind speed data. Then, in order to reduce the error accumulation and computation redundancy, fuzzy entropy (FE) is used to calculate the time complexity of each component, according to the Spearman correlation, the inherent mode function (IMF) components are recombined to form a new subsequence. Experimental results show that the error accumulation can be reduced by 48.65% for dataset 1 and 29.53% for dataset 2, and the operation time can be reduced by about 50% for two datasets. To avoid the limitation of a single model, introducing the LSTM and improved BPNN which improved by sparrow search algorithm (SSA) two different prediction models are used to predict the sub sequences with high complexity and the low complexity subsequences, respectively. Finally, the predicted values of the models are superimposed to get the final values. In order to verify the validity of the proposed model, the final predictions, compared with six different prediction models, show that this model can achieve the best performance and obtain higher prediction accuracy. Such as the performance evaluation indexes (RMSE = 0.051, MAPE = 0.929%) are smallest obtained from dataset1 by one-step prediction, and (RMSE = 0.086, MAPE = 0.966%) are smallest obtained from dataset2 by one-step prediction. In addition, the Pearson correlation between the predicted value and the true wind speed value obtained by the prediction model applied to the two data sets is the highest 99.17% and 98.73%, respectively.}
}
@article{KIM2022114868,
title = {Is walking or riding your bike when a tourist different? Applying VAB theory to better understand active transport behavior},
journal = {Journal of Environmental Management},
volume = {311},
pages = {114868},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.114868},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722004418},
author = {Myung Ja Kim and C. Michael Hall},
keywords = {Sustainability, Sustainable transport, Walking, Cycling, Value-attitude-behavior (VAB) theory, Sustainable tourism},
abstract = {Active transport (walking and biking) has significant environmental, health, and social benefits. Despite the importance of active transport, theoretically framed research has not sufficiently considered what makes consumers walk or bike based on activity types, particularly in an Asian context. This is an important topic as it helps provides a basis for better targeted marketing and promotion to encourage greater public engagement with active transport. To fill this knowledge gap, this work applied the value-attitude-behavior (VAB) theory to understand walkers and bikers’ behaviors in comparing tourism, leisure, and work activity. Results indicate that value on attitude has the greatest influence, followed by personal, and then social norm. Behavior for active transport is significantly influenced by personal norm, followed by attitude and social norm. Interestingly, from the three types of activities, the tourism group has the strongest relationship of value and attitude and the highest prediction for attitude and behavior.}
}
@article{WANG2022102093,
title = {Weakly supervised deep learning for prediction of treatment effectiveness on ovarian cancer from histopathology images},
journal = {Computerized Medical Imaging and Graphics},
volume = {99},
pages = {102093},
year = {2022},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2022.102093},
url = {https://www.sciencedirect.com/science/article/pii/S0895611122000660},
author = {Ching-Wei Wang and Cheng-Chang Chang and Yu-Ching Lee and Yi-Jia Lin and Shih-Chang Lo and Po-Chao Hsu and Yi-An Liou and Chih-Hung Wang and Tai-Kuang Chao},
keywords = {Epithelial ovarian cancer, Precision Oncology, Weakly supervised deep learningframework, Whole-slide image analysis, Histopathological Images},
abstract = {Despite the progress made during the last two decades in the surgery and chemotherapy of ovarian cancer, more than 70 % of advanced patients are with recurrent cancer and decease. Surgical debulking of tumors following chemotherapy is the conventional treatment for advanced carcinoma, but patients with such treatment remain at great risk for recurrence and developing drug resistance, and only about 30 % of the women affected will be cured. Bevacizumab is a humanized monoclonal antibody, which blocks VEGF signaling in cancer, inhibits angiogenesis and causes tumor shrinkage, and has been recently approved by FDA as a monotherapy for advanced ovarian cancer in combination with chemotherapy. Considering the cost, potential toxicity, and finding that only a portion of patients will benefit from these drugs, the identification of new predictive method for the treatment of ovarian cancer remains an urgent unmet medical need. In this study, we develop weakly supervised deep learning approaches to accurately predict therapeutic effect for bevacizumab of ovarian cancer patients from histopathological hematoxylin and eosin stained whole slide images, without any pathologist-provided locally annotated regions. To the authors’ best knowledge, this is the first model demonstrated to be effective for prediction of the therapeutic effect of patients with epithelial ovarian cancer to bevacizumab. Quantitative evaluation of a whole section dataset shows that the proposed method achieves high accuracy, 0.882 ± 0.06; precision, 0.921 ± 0.04, recall, 0.912 ± 0.03; F-measure, 0.917 ± 0.07 using 5-fold cross validation and outperforms two state-of-the art deep learning approaches Coudray et al. (2018), Campanella et al. (2019). For an independent TMA testing set, the three proposed methods obtain promising results with high recall (sensitivity) 0.946, 0.893 and 0.964, respectively. The results suggest that the proposed method could be useful for guiding treatment by assisting in filtering out patients without positive therapeutic response to suffer from further treatments while keeping patients with positive response in the treatment process. Furthermore, according to the statistical analysis of the Cox Proportional Hazards Model, patients who were predicted to be invalid by the proposed model had a very high risk of cancer recurrence (hazard ratio = 13.727) than patients predicted to be effective with statistical signifcance (p < 0.05).}
}
@article{PINTO2022104072,
title = {Ecosystem services and well-being dimensions related to urban green spaces – A systematic review},
journal = {Sustainable Cities and Society},
volume = {85},
pages = {104072},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.104072},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722003900},
author = {Luís Valença Pinto and Miguel Inácio and Carla Sofia Santos Ferreira and António Dinis Ferreira and Paulo Pereira},
keywords = {Urban green spaces, Ecosystem services, Wellbeing dimensions, Methods, Validation},
abstract = {Urban green spaces (UGS) supply several ecosystem services (ES) key to human wellbeing. In this article, we conducted a systematic review focused on identifying UGS's ES and wellbeing dimensions. From the 3626 articles screened, 218 were used in this review. Most studies were conducted in Europe, China, the United States of America (USA) and South Africa. Among all UGS, parks and gardens were the most investigated, with less of a focus on urban trees, forests, coastal mangroves, golf courses, roadside vegetation, and brownfields/unmanaged urban greenery. Cultural ES were the most studied, although it is well known that UGS also supply many provisioning and regulating ES. Health (mental and physical) and good social relations were the most investigated wellbeing dimensions, and food security received the least attention. Regarding the methodologies used to investigate the UGS contribution to human wellbeing, surveys, indicators, and surveys combined with statistical methods were the most common. Only a few works focusing on spatial modelling were validated, which is critical to ensure the reliability of the spatial models applied to UGS ES studies. Overall, this work identified the research gaps and future perspectives in ES and wellbeing dimensions provided by UGS, key to improving further research.}
}
@article{NASSEF2022108820,
title = {A survey: Distributed Machine Learning for 5G and beyond},
journal = {Computer Networks},
volume = {207},
pages = {108820},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.108820},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622000421},
author = {Omar Nassef and Wenting Sun and Hakimeh Purmehdi and Mallik Tatipamula and Toktam Mahmoodi},
keywords = {Machine Learning, Distributed machine learning, Distributed inference, Latency, 5G networks},
abstract = {5G is the fifth generation of cellular networks. It enables billions of connected devices to gather and share information in real time; a key facilitator in Industrial Internet of Things (IoT) applications. It has more capabilities in terms of bandwidth, latency/delay, processing powers and flexibility to utilize either edge or cloud resources. Furthermore, 6G is expected to be equipped with the new capability to converge ubiquitous communication, computation, sensing and controlling for a variety of sectors, which heightens the complexity in a more heterogeneous environment This increased complexity, combined with energy efficiency and Service Level Agreement (SLA) requirements makes application of Machine Learning (ML) and distributed ML necessary. A decentralized approach stemming from distributed learning is a very attractive option compared with a centralized architecture for model learning and inference. Distributed ML exploits recent Artificial Intelligence (AI) technology advancements to allow collaborated ML, whilst safeguarding private data, minimizing both communication and computation overhead along with addressing ultra-low latency requirements. In this paper, we review a number of distributed ML architectures and designs, that focus on optimizing communication, computation and resource distribution. Privacy, information security and compute frameworks, are also analyzed and compared with respect to different distributed ML approaches. We summarize the major contributions and trends in this area and highlight the potential of distributed ML to help researchers and practitioners make informed decisions on selecting the right ML approach for 5G and Beyond related AI applications. To enable distributed ML for 5G and Beyond, communication, security, and computing platform often counter balance each other, thus, consideration and optimization of these aspects at an overall system level is crucial to realize the full potential of AI for 5G and Beyond. These different aspects do not only pertain to 5G, but will also enable careful design of distributed machine learning architectures to circumvent the same hurdles that will inevitably burden 5G and Beyond network generations. This is the first survey paper that brings together all these aspects for distributed ML.}
}
@article{EKE2022600,
title = {International data governance for neuroscience},
journal = {Neuron},
volume = {110},
number = {4},
pages = {600-612},
year = {2022},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321009557},
author = {Damian O. Eke and Amy Bernard and Jan G. Bjaalie and Ricardo Chavarriaga and Takashi Hanakawa and Anthony J. Hannan and Sean L. Hill and Maryann E. Martone and Agnes McMahon and Oliver Ruebel and Sharon Crook and Edda Thiels and Franco Pestilli},
abstract = {Summary
As neuroscience projects increase in scale and cross international borders, different ethical principles, national and international laws, regulations, and policies for data sharing must be considered. These concerns are part of what is collectively called data governance. Whereas neuroscience data transcend borders, data governance is typically constrained within geopolitical boundaries. An international data governance framework and accompanying infrastructure can assist investigators, institutions, data repositories, and funders with navigating disparate policies. Here, we propose principles and operational considerations for how data governance in neuroscience can be navigated at an international scale and highlight gaps, challenges, and opportunities in a global brain data ecosystem. We consider how to approach data governance in a way that balances data protection requirements and the need for open science, so as to promote international collaboration through federated constructs such as the International Brain Initiative (IBI).}
}