@incollection{2012269,
editor = {Rick F. {van der Lans}},
booktitle = {Data Virtualization for Business Intelligence Systems},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {269-275},
year = {2012},
series = {MK Series on Business Intelligence},
isbn = {978-0-12-394425-2},
doi = {https://doi.org/10.1016/B978-0-12-394425-2.00027-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780123944252000277}
}
@article{STOOVE2014109,
title = {Making the most of a brave new world: Opportunities and considerations for using Twitter as a public health monitoring tool},
journal = {Preventive Medicine},
volume = {63},
pages = {109-111},
year = {2014},
issn = {0091-7435},
doi = {https://doi.org/10.1016/j.ypmed.2014.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0091743514001029},
author = {Mark A. Stoové and Alisa E. Pedrana},
keywords = {Epidemiology, Surveillance, Social media, Twitter, Prevention, HIV},
abstract = {This paper outlines a commentary response to an article published by Young and colleagues in Preventive Medicine that evaluated the feasibility of using Twitter as a surveillance and monitoring took for HIV. We draw upon the broader literature on disease surveillance and public health prevention using social media and broader considerations of epidemiological and surveillance methods to provide readers with necessary considerations for using social media in epidemiology and surveillance.}
}
@article{2014IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {43},
pages = {IFC},
year = {2014},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(14)00047-7},
url = {https://www.sciencedirect.com/science/article/pii/S0306437914000477}
}
@article{AKAZA201688,
title = {Asia prostate cancer study (A-CaP Study) launch symposium},
journal = {Prostate International},
volume = {4},
number = {3},
pages = {88-96},
year = {2016},
issn = {2287-8882},
doi = {https://doi.org/10.1016/j.prnil.2016.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2287888216300046},
author = {Hideyuki Akaza and Yoshihiko Hirao and Choung-Soo Kim and Mototsugu Oya and Seiichiro Ozono and Dingwei Ye and Matthew Cooperberg and Shiro Hinotsu and Ji Youl Lee and Gang Zhu and Mikio Namiki and Shigeo Horie and Byung Ha Chung and Chung-Hsin Chen and Ng Chi Fai and Lukman Hakim and Edmund Chiong and Jason Letran and Rainy Umbas and Kazuhiro Suzuki and Kazuo Nishimura and Teng Aik Ong and Bannakij Lojanapiwat and Tong-lin Wu and Wun-Jae Kim and Declan Murphy and Osamu Ogawa and Peter Carroll and Seiji Naito and Taiji Tsukamoto},
keywords = {Asian Cancer, Database, Prospective Study, Prostate Cancer},
abstract = {The Asian Prostate Cancer (A-CaP) Study is an Asia-wide initiative that has been developed over the course of 2 years. The A-CaP Study is scheduled to begin in 2016, when each participating country or region will begin registration of newly diagnosed prostate cancer patients and conduct prognosis investigations. From the data gathered, common research themes will be identified, such as comparisons among Asian countries of background factors in newly diagnosed prostate cancer patients. This is the first Asia-wide study of prostate cancer and has developed from single country research efforts in this field, including in Japan and Korea. The inaugural Board Meeting of A-CaP was held on December 11, 2015 at the Research Center for Advanced Science and Technology, The University of Tokyo, attended by representatives of all participating countries and regions, who signed a memorandum of understanding concerning registration for A-CaP. Following the Board Meeting an A-CaP Launch Symposium was held. The symposium was attended by representatives of countries and regions participating in A-CaP, who gave presentations. Presentations and a keynote address were also delivered by representatives of the University of California San Francisco, USA, and the Peter MacCallum Cancer Centre, Australia, who provided insight and experience on similar databases compiled in their respective countries.}
}
@article{BRAY2015202,
title = {Form and flow: the ‘karmic cycle’ of copper},
journal = {Journal of Archaeological Science},
volume = {56},
pages = {202-209},
year = {2015},
note = {Scoping the Future of Archaeological Science: Papers in Honour of Richard Klein},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2014.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0305440314004749},
author = {P. Bray and A. Cuénod and C. Gosden and P. Hommel and R. Liu and A.M. Pollard},
keywords = {Copper, Recycling, Provenance, Typology},
abstract = {The analysis and interpretation of the chemical composition of copper-alloys is one of the longest ongoing research projects within archaeological science. Beginning in the late 18th century these data have been consistently used to try and link objects with distinct metal sources. This paper argues the traditional provenance model for copper alloys is fatally flawed. Through pursuing a ‘pure’ source signal, chemical and isotopic datasets have been removed from their context and history. Social engagement with metal through processes such as reuse, recycling, and curation were rarely considered important by analysts. We offer an alternative model that unites the available legacy scientific datasets with process-metallurgy, archaeological and geographical context, and new conceptual approaches. Rather than provenance, we offer an empirical model of metal flow. Here objects are seen as snapshots of a wider metal stream; their final scientific characterisation including echoes of their previous forms and contexts. Through a series of case studies we highlight how the reinterpretation of existing datasets can disentangle the complex life histories of units of copper.}
}
@article{HAO2014112,
title = {Clustering clinical trials with similar eligibility criteria features},
journal = {Journal of Biomedical Informatics},
volume = {52},
pages = {112-120},
year = {2014},
note = {Special Section: Methods in Clinical Research Informatics},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2014.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1532046414000112},
author = {Tianyong Hao and Alexander Rusanov and Mary Regina Boland and Chunhua Weng},
keywords = {Medical informatics, Clinical trial, Cluster analysis},
abstract = {Objectives
To automatically identify and cluster clinical trials with similar eligibility features.
Methods
Using the public repository ClinicalTrials.gov as the data source, we extracted semantic features from the eligibility criteria text of all clinical trials and constructed a trial-feature matrix. We calculated the pairwise similarities for all clinical trials based on their eligibility features. For all trials, by selecting one trial as the center each time, we identified trials whose similarities to the central trial were greater than or equal to a predefined threshold and constructed center-based clusters. Then we identified unique trial sets with distinctive trial membership compositions from center-based clusters by disregarding their structural information.
Results
From the 145,745 clinical trials on ClinicalTrials.gov, we extracted 5,508,491 semantic features. Of these, 459,936 were unique and 160,951 were shared by at least one pair of trials. Crowdsourcing the cluster evaluation using Amazon Mechanical Turk (MTurk), we identified the optimal similarity threshold, 0.9. Using this threshold, we generated 8806 center-based clusters. Evaluation of a sample of the clusters by MTurk resulted in a mean score 4.331±0.796 on a scale of 1–5 (5 indicating “strongly agree that the trials in the cluster are similar”).
Conclusions
We contribute an automated approach to clustering clinical trials with similar eligibility features. This approach can be potentially useful for investigating knowledge reuse patterns in clinical trial eligibility criteria designs and for improving clinical trial recruitment. We also contribute an effective crowdsourcing method for evaluating informatics interventions.}
}
@incollection{SHEIKH20133,
title = {Chapter 1 - Defining Analytics},
editor = {Nauman Sheikh},
booktitle = {Implementing Analytics},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {3-20},
year = {2013},
series = {MK Series on Business Intelligence},
isbn = {978-0-12-401696-5},
doi = {https://doi.org/10.1016/B978-0-12-401696-5.00001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780124016965000013},
author = {Nauman Sheikh},
keywords = {analytics, data warehousing, business intelligence, descriptive analytics, forecasting, decision optimization, predictive analytics, regression, classification, decision trees, neural networks, linear programming, model versus algorithm, big data, business analytics},
abstract = {The chapter defines the terminology regarding analytics to simplify the concepts and put some boundaries around analytics, differentiating it from traditional reporting and business intelligence terminology. It uses a business perspective of definition and an implementation perspective by using explanations of several analytics techniques.}
}
@article{2015IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {49},
pages = {IFC},
year = {2015},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(15)00004-6},
url = {https://www.sciencedirect.com/science/article/pii/S0306437915000046}
}
@article{KILLICK2015242,
title = {The awkward adolescence of archaeological science},
journal = {Journal of Archaeological Science},
volume = {56},
pages = {242-247},
year = {2015},
note = {Scoping the Future of Archaeological Science: Papers in Honour of Richard Klein},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2015.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0305440315000230},
author = {David Killick},
keywords = {Archaeometry, Archaeological science, Quality control, Funding, Training, Employment},
abstract = {The rapid growth of archaeological science (and of the Journal of Archaeological Science) over the last 15 years has changed archaeology worldwide. New methods of analysis have allowed archaeologists to pose many new questions, and have made it possible to revisit many old ones. In spite of its many successes, archaeological science is not yet a mature field of science, for it has yet to attract adequate funding, has not solved the problem of how to reproduce itself (issues of training and employment), and still struggles with quality control. These are however all problems of archaeological science in rich nations. Looking beyond these, a particularly troubling issue is the growing inequality of access to archaeological science. Archaeologists in poorer nations are often aware of the growing importance of scientific techniques in archaeological research, but cannot obtain access to them. Archaeological scientists also need to be aware of potential political sensitivity of their work, and to work to build trust.}
}
@article{GERIKE201532,
title = {Workshop Synthesis: Improving Methods to Collect Data on Dynamic Behavior and Processes},
journal = {Transportation Research Procedia},
volume = {11},
pages = {32-42},
year = {2015},
note = {Transport Survey Methods: Embracing Behavioural and Technological Changes Selected contributions from the 10th International Conference on Transport Survey Methods 16-21 November 2014, Leura, Australia},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2015.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S2352146515002951},
author = {Regine Gerike and Martin Lee-Gosselin},
keywords = {Travel behavior, longitudinal, panel, survey, cross-sectional, repeated survey, continuous survey},
abstract = {This paper summarizes the findings from the workshop “Improving methods to collect data on dynamic behavior and processes”. This workshop focused on the scope, strengths and weaknesses of traditional and innovative survey methods used to capture dynamics in travel behaviour and on the identification of future research priorities. This paper gives an overview of the process followed by the workshop, presents the definitions of technical terms adopted to facilitate the spoken exchanges in the workshop, describes the current state of research on topics that were selected for discussion by the participants, and looks ahead to future research}
}
@article{ERFANI2016345,
title = {Context-awareness in the software domain—A semantic web enabled modeling approach},
journal = {Journal of Systems and Software},
volume = {121},
pages = {345-357},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216000558},
author = {Mostafa Erfani and Mohammadnaser Zandi and Juergen Rilling and Iman Keivanloo},
keywords = {Context-awareness, Meta-modeling, Semantic Web},
abstract = {Recent years have witnessed rapid advances in the use of contextual information in ubiquitous and ambient computing. Such information improves situated cognition and awareness as well as stakeholders’ usage experience. While domains such as Web 3.0 – the next generation of the web – have made context-awareness a main requirement of their solution space, the software engineering domain still lacks the same rate of adoption. In our research, we introduce an ontology based context-aware meta-model that takes advantage of Semantic Web technologies to capture and formalize context information. Providing such formal context representation allows us to make context information an integrated and reusable part of the software engineering domain. We present several case studies related to the software evolution domain to illustrate the benefit of sharing and reusing context for various software engineering tasks, such as mentor recommendation, code search, and result ranking.}
}
@article{PENG2015252,
title = {BigNeuron: Large-Scale 3D Neuron Reconstruction from Optical Microscopy Images},
journal = {Neuron},
volume = {87},
number = {2},
pages = {252-256},
year = {2015},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2015.06.036},
url = {https://www.sciencedirect.com/science/article/pii/S0896627315005991},
author = {Hanchuan Peng and Michael Hawrylycz and Jane Roskams and Sean Hill and Nelson Spruston and Erik Meijering and Giorgio A. Ascoli},
abstract = {Understanding the structure of single neurons is critical for understanding how they function within neural circuits. BigNeuron is a new community effort that combines modern bioimaging informatics, recent leaps in labeling and microscopy, and the widely recognized need for openness and standardization to provide a community resource for automated reconstruction of dendritic and axonal morphology of single neurons.}
}
@incollection{SHERMAN2015107,
title = {Chapter 6 - Data Architecture},
editor = {Rick Sherman},
booktitle = {Business Intelligence Guidebook},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {107-142},
year = {2015},
isbn = {978-0-12-411461-6},
doi = {https://doi.org/10.1016/B978-0-12-411461-6.00006-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012411461600006X},
author = {Rick Sherman},
keywords = {Analytical data architecture, Bill Inmon, Corporate information factory (CIF), Data architecture, Data integration, Data mart, Data schema, Hub and spoke, Hybrid dimensional-normalized model, Operational data store (ODS), Ralph Kimball, System of analytics (SOA), System of integration (SOI)},
abstract = {The data architecture defines the data along with the schemas, integration, transformations, storage, and workflow required to enable the analytical requirements of the information architecture. A solid data architecture is a blueprint that helps align your company's data with its business strategies. The data architecture guides how the data is collected, integrated, enhanced, stored, and delivered to business people who use it to do their jobs. It helps make data available, accurate, and complete so it can be used for business decision-making. The major choices are Enterprise Data Warehouse (EDW)-only, independent data marts, Ralph Kimball's enterprise data bus architecture, Bill Inmon's Corporate Information Factory (CIF), hub-and-spoke, analytical data architecture (ADA). The recommended approach is ADA with the hybrid dimensional-normalized model, which accommodates various data stores: hub-and-spoke, system of integration, and system of analytics. An architecture may include an operational data store, which is a database that enables non-traditional data warehousing functions such as real-time operational reporting or refining unstructured data.}
}
@article{HAWORTH2016189,
title = {Emergency management perspectives on volunteered geographic information: Opportunities, challenges and change},
journal = {Computers, Environment and Urban Systems},
volume = {57},
pages = {189-198},
year = {2016},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2016.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516300175},
author = {Billy Haworth},
keywords = {Volunteered geographic information, VGI, Disaster management, Emergency management, Geospatial data},
abstract = {Volunteered geographic information (VGI) refers to the widespread creation and sharing of geographic information by private citizens, often through platforms such as online mapping tools, social media, and smartphone applications. VGI has shifted the ways information is created, shared, used and experienced, with important implications for applications of geospatial data, including emergency management. Detailed interviews with 13 emergency management professionals from eight organisations across five Australian states provided insights into the impacts of VGI on official emergency management. Perceived opportunities presented by VGI included improved communication, acquisition of diverse local information, and increased community engagement in disaster management. Identified challenges included the digital divide, data management, misinformation, and liability concerns. Significantly, VGI disrupts the traditional top-down structure of emergency management and reflects a culture shift away from authoritative control of information. To capitalise on the opportunities of VGI, agencies need to share responsibility and be willing to remain flexible in supporting positive community practises, including VGI. Given the high accountability and inherently responsive nature of decision making in disaster management, it provides a useful lens through which to examine the impacts of VGI on official authoritative systems more broadly. This analysis of the perceptions of emergency management professionals suggests changes to traditional systems that involve decentralisation of power and increased empowerment of citizens, where value is increasingly recognised in both expert and citizen-produced information, initiatives and practises.}
}
@article{DIVITTORIO2013271,
title = {2013 North American Serials Interest Group (NASIG) 28th Annual Conference: Art of Information, Architecture of Knowledge},
journal = {Serials Review},
volume = {39},
number = {4},
pages = {271-277},
year = {2013},
issn = {0098-7913},
doi = {https://doi.org/10.1016/j.serrev.2013.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0098791313001433},
author = {Katy DiVittorio}
}
@article{AMBROSE2014800,
title = {Speaking of forgetting: Analysis of possible non-EU responses to the right to be forgotten and speech exception},
journal = {Telecommunications Policy},
volume = {38},
number = {8},
pages = {800-811},
year = {2014},
note = {Special issue on Moving Forward with Future Technologies: Opening a Platform for All Special issue on Papers from the 41st Research Conference on Communication, Information and Internet Policy (TPRC 2013)},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0308596114000731},
author = {Meg Leta Ambrose},
keywords = {International privacy law, Data protection, Right to be forgotten, Expression},
abstract = {The right to be forgotten is contentious partly because it highlights the difference between U.S. and E.U. prioritization of information privacy and freedom of expression. Recently, a moderate amount of research has been undertaken to explore the conceptual issues underlying the right to be forgotten and how the right conflicts with the U.S. first amendment, but little has been written about its impending implementation and interoperability issues. While this is an E.U. Data Protection Regulation proposing to grant rights only to E.U. citizens, the world has a stake in this right for a number of reasons. This article will analyze the options for non-E.U. countries and data controllers, namely the U.S., to react to the establishment of such a right, now called “The Right to Erasure”. These options are the following: (1) adopt the same right to erasure for themselves, (2) ignore right to erasure claims, (3) comply with erasure take down requests, or (4) seek to establish a modified version of the right to erasure. In assessing these options, the article will first address the reality of a right to erasure under U.S. law. Second, it will discuss compliance and jurisdictional issues if the right is ignored. Third, the article will look at the impact of full acceptance of the take-down regime, focusing on the potential chilling effects and abuse. Finally, it will propose that non-E.U. countries encourage a right to erasure that is less disruptive: a right to erasure that allows data subjects to directly request removal of data held privately by data controllers and a right to oblivion for publicly available information that is enforced similarly to defamation claims, requiring a court order.}
}
@article{KENNEDY20161069,
title = {The NITRC image repository},
journal = {NeuroImage},
volume = {124},
pages = {1069-1073},
year = {2016},
note = {Sharing the wealth: Brain Imaging Repositories in 2015},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.05.074},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915004644},
author = {David N. Kennedy and Christian Haselgrove and Jon Riehl and Nina Preuss and Robert Buccigrossi},
abstract = {The Neuroimaging Informatics Tools and Resources Clearinghouse (NITRC — www.nitrc.org) suite of services include a resources registry, image repository and a cloud computational environment to meet the needs of the neuroimaging researcher. NITRC provides image-sharing functionality through both the NITRC Resource Registry (NITRC-R), where bulk data files can be released through the file release system (FRS), and the NITRC Image Repository (NITRC-IR), a XNAT-based image data management system. Currently hosting 14 projects, 6845 subjects, and 8285 MRI imaging sessions, NITRC-IR provides a large array of structural, diffusion and resting state MRI data. Designed to be flexible about management of data access policy, NITRC provides a simple, free, NIH-funded service to support resource sharing in general, and image sharing in particular.}
}
@incollection{2016177,
title = {Index},
editor = {Tibor Koltay and Sonja Špiranec and László Z. Karvalics},
booktitle = {Research 2.0 and the Future of Information Literacy},
publisher = {Chandos Publishing},
pages = {177-180},
year = {2016},
isbn = {978-0-08-100075-5},
doi = {https://doi.org/10.1016/B978-0-08-100075-5.09989-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780081000755099892}
}
@article{DEHERT2016179,
title = {The new General Data Protection Regulation: Still a sound system for the protection of individuals?},
journal = {Computer Law & Security Review},
volume = {32},
number = {2},
pages = {179-194},
year = {2016},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2016.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0267364916300346},
author = {Paul {de Hert} and Vagelis Papakonstantinou},
keywords = {EU General Data Protection Regulation, Controller–processor relationship, Internet of things, Individual consent, DPIAs, The right to be forgotten, Data portability, Personal data breach notifications},
abstract = {The five-year wait is finally over; a few days before expiration of 2015 the “trilogue” that had started a few months earlier between the Commission, the Council and the Parliament suddenly bore fruit and the EU data protection reform package has finally been concluded. As planned since the beginning of this effort a Regulation, the General Data Protection Regulation is going to replace the 1995 Directive and a Directive, the Police and Criminal Justice Data Protection Directive, the 2008 Data Protection Framework Decision. In this way a long process that started as early as in 2009, peaked in early 2012, and required another three years to pass through the Parliament's and the Council's scrutiny is finished. Whether this reform package and its end-result is cause to celebrate or to lament depends on the perspective, the interests and the expectations of the beholder. Four years ago we published an article in this journal under the title “The proposed data protection Regulation replacing Directive 95/46/EC: A sound system for the protection of individuals”. This paper essentially constitutes a continuation of that article: now that the General Data Protection Regulation's final provisions are at hand it is possible to present differences with the first draft prepared by the Commission, to discuss the issues raised through its law-making passage over the past few years, and to attempt to assess the effectiveness of its final provisions in relation to their declared purposes.}
}
@article{KACPRZYK2015300,
title = {Fuzziness in database management systems: Half a century of developments and future prospects},
journal = {Fuzzy Sets and Systems},
volume = {281},
pages = {300-307},
year = {2015},
note = {Special Issue Celebrating the 50th Anniversary of Fuzzy Sets},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415003000},
author = {Janusz Kacprzyk and Sławomir Zadrożny and Guy {De Tré}},
keywords = {Database management systems, DBMS, Database querying, Fuzzy logic, Possibility theory, Bipolar queries},
abstract = {This comprehensive, bird's view research note combines the state of the art, a brief presentation of the history and some original solutions, and position like views of some prospective future developments of one of the most relevant and interesting areas related to the use of fuzzy logic in database management systems, notably in its querying component, and – to some extent – in a broader issue of data and information management. We briefly summarize the roots of those new applications of fuzzy logic, more relevant proposals and development in the context of fuzzification of the basic relational database model, and then some of its further generalizations. We particularly focus on fuzzy querying as a human consistent and friendly way of retrieving information due to real human intentions and preferences expressed in natural language represented via fuzzy logic and possibility theory. We mention some extensions, notably fuzzy queries with linguistic quantifiers, and point their close relation to linguistic summaries. As for newer, prospective developments, we mainly focus on bipolar queries that can accomodate the users' intentions and preferences involving some sort of a required and desired, mandatory and optional, etc. conditions. We show various ways of handling such queries. We conclude with some brief position statements of our view on relevant and promising directions, and challenges.}
}
@article{REDDICK2015129,
title = {Public opinion on National Security Agency surveillance programs: A multi-method approach},
journal = {Government Information Quarterly},
volume = {32},
number = {2},
pages = {129-141},
year = {2015},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2015.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X15000246},
author = {Christopher G. Reddick and Akemi Takeoka Chatfield and Patricia A. Jaramillo},
keywords = {Government surveillance, Citizen-centric e-governance, Twitter, E-government, Public opinion, Logistic regression analysis, Critical discourse analysis},
abstract = {This paper examines public opinion on National Security Agency (NSA) mass surveillance programs of Americans. A new theory, developed and tested in this paper, explicates the effect of political efficacy on creating greater citizen-centric e-governance. Its propositions state that the higher citizens' perceived self-efficacy in political knowledge and the higher citizens' perceived fairness of government procedures and outcomes, the more engaged citizens would be in using technology for better governance and the more vocal in their views on NSA surveillance programs. This paper adopts a multi-method research approach to examine citizens' approval/disapproval of NSA surveillance programs: (1) critical discourse analysis of tweets exchanged among citizens and interest groups in Twittersphere and (2) logistic regression analysis of survey data collected from a random sample public opinion poll of Americans. The findings of both analyses provide evidence that citizens hold strong views toward NSA surveillance programs. These findings indicate that government needs to be more efficacious in communicating about surveillance programs more transparently to garner greater citizens' approval for its surveillance programs. The findings also provide preliminary evidence for good explanatory power of the theory of citizen-centric e-governance. The theory explains effectively the relationship between government practicing greater political efficacious behavior and citizens engaging in more citizen-centric e-governance in governing government surveillance programs for a better balance between security and privacy.}
}
@article{RUSSELL2015182,
title = {Predictive analytics and child protection: Constraints and opportunities},
journal = {Child Abuse & Neglect},
volume = {46},
pages = {182-189},
year = {2015},
issn = {0145-2134},
doi = {https://doi.org/10.1016/j.chiabu.2015.05.022},
url = {https://www.sciencedirect.com/science/article/pii/S0145213415002197},
author = {Jesse Russell},
keywords = {Predictive analytics, Risk assessment, Child protection, Decision making},
abstract = {This paper considers how predictive analytics might inform, assist, and improve decision making in child protection. Predictive analytics represents recent increases in data quantity and data diversity, along with advances in computing technology. While the use of data and statistical modeling is not new to child protection decision making, its use in child protection is experiencing growth, and efforts to leverage predictive analytics for better decision-making in child protection are increasing. Past experiences, constraints and opportunities are reviewed. For predictive analytics to make the most impact on child protection practice and outcomes, it must embrace established criteria of validity, equity, reliability, and usefulness.}
}
@incollection{RIDGE2015149,
title = {Chapter 12 - Introduction to Testing},
editor = {Enda Ridge},
booktitle = {Guerrilla Analytics},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {149-158},
year = {2015},
isbn = {978-0-12-800218-6},
doi = {https://doi.org/10.1016/B978-0-12-800218-6.00012-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128002186000126},
author = {Enda Ridge},
keywords = {Testing, Expected Value, Test UID, Unique Identifiers},
abstract = {Summary
This chapter introduces testing in Guerrilla Analytics projects. It begins with describing where testing fits within the Guerrilla Analytics workflow. We will then discuss the fundamental concept of what it means to test something and why it is important. The areas of analytics testing will be introduced. You will also learn some tips on testing that can be applied across all these areas.}
}
@article{CHEN201531,
title = {Design and implementation of a Data Distribution System for Xiaoqushan Submarine Comprehensive Observation and Marine Equipment Test Platform},
journal = {Computers & Geosciences},
volume = {82},
pages = {31-37},
year = {2015},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2015.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0098300415001132},
author = {Hui Chen and Huiping Xu and Yang Yu and Rufu Qin and Changwei Xu},
keywords = {Seafloor observation system, Data distribution, Real-time interpretation, “Hot Swapping” interpretation},
abstract = {One of the major issues concerning undersea observation data is data distribution characterized by multi-disciplinary, multi-parameter and weather-independent continuous observations. It describes the data distribution system for Xiaoqushan Submarine Comprehensive Observation and Marine Equipment Test Platform (XSCOMETP). Based on the design of C/S architecture, the overall system establishes a communication link between the observation infrastructure and the data center using Socket technology. The Data Distribution System for XSCOMETP was developed by C# in the .NET framework, which enabled multi-source and heterogeneous data to be acquired, interpreted and stored in real time. The system can be divided into three functional modules including data acquisition and transmission, data interpretation and storage, and data display. Given the successful trial from August 11, 2013, the data distribution solution proposed in this paper could be a useful reference implementation to the East China Sea Seafloor Observation System.}
}
@article{SYLVIE201545,
title = {Data Science Approach for a Cross-disciplinary Understanding of Urban Phenomena: Application to Energy Efficiency of Buildings},
journal = {Procedia Engineering},
volume = {115},
pages = {45-52},
year = {2015},
note = {Toward integrated modelling of urban systems},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.07.353},
url = {https://www.sciencedirect.com/science/article/pii/S1877705815016367},
author = {Servigne Sylvie and Yann Gripay and Deleuil Jean-Michel and Nguyen Céline and Jay Jacques and Cavadenti Olivier and Mebrouk Radouane},
keywords = {Sensors, Data Model, Heterogenous Data, Multidimensional Data, Data Correlation, Data Exploration},
abstract = {Our goal is to develop theoretical and practical tools to model, explore and exploit heterogeneous data from various sources in order to understand a phenomenon. We focus on a generic model for data acquisition campaigns based on the concept of generic sensor. The concept of generic sensor is centered on acquired data and on their inherent multi-dimensional structure, to support complex domain-specific or field-oriented analysis processes. We consider that a methodological breakthrough, based on Data Science as a pivot for interdisciplinary dialog, may pave the way to deep understanding of voluminous and heterogeneous scientific data sets. Our use case concerns energy efficiency of buildings to understand the relationship between physical phenomena and user behaviors. This multidisciplinary project involves computer scientists, social and urban scientists, and thermal scientists. The aim of this paper is to give a synthetic presentation of our methodology, and an overview of our main results.}
}
@article{FISHER2014144,
title = {Section I: Integrating laboratory medicine with tissue specimens},
journal = {Current Problems in Cancer},
volume = {38},
number = {5},
pages = {144-158},
year = {2014},
note = {Molecular Genomics of Cancer: Linking Diagnostic Testing and Clinical Therapy},
issn = {0147-0272},
doi = {https://doi.org/10.1016/j.currproblcancer.2014.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0147027214000610},
author = {Kevin E. Fisher and Geoffrey H. Smith and Stewart G. Neill and Michael R. Rossi}
}
@article{BAER20165,
title = {DBStream: A holistic approach to large-scale network traffic monitoring and analysis},
journal = {Computer Networks},
volume = {107},
pages = {5-19},
year = {2016},
note = {Machine learning, data mining and Big Data frameworks for network monitoring and troubleshooting},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2016.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S1389128616301189},
author = {Arian Baer and Pedro Casas and Alessandro D’Alconzo and Pierdomenico Fiadino and Lukasz Golab and Marco Mellia and Erich Schikuta},
keywords = {Network monitoring, Data stream warehouse, Machine-to-machine traffic, On-line traffic classification, Machine learning, Cellular networks},
abstract = {In the last decade, many systems for the extraction of operational statistics from computer network interconnects have been designed and implemented. Those systems generate huge amounts of data of various formats and in various granularities, from packet level to statistics about whole flows. In addition, the complexity of Internet services has increased drastically with the introduction of cloud infrastructures, Content Delivery Networks (CDNs) and mobile Internet usage, and complexity will continue to increase in the future with the rise of Machine-to-Machine communication and ubiquitous wearable devices. Therefore, current and future network monitoring frameworks cannot rely only on information gathered at a single network interconnect, but must consolidate information from various vantage points distributed across the network. In this paper, we present DBStream, a holistic approach to large-scale network monitoring and analysis applications. After a precise system introduction, we show how its Continuous Execution Language (CEL) can be used to automate several data processing and analysis tasks typical for monitoring operational ISP networks. We discuss the performance of DBStream as compared to MapReduce processing engines and show how intelligent job scheduling can increase its performance even further. Furthermore, we show the versatility of DBStream by explaining how it has been integrated to import and process data from two passive network monitoring systems, namely METAWIN and Tstat. Finally, multiple examples of network monitoring applications are given, ranging from simple statistical analysis to more complex traffic classification tasks applying machine learning techniques using the Weka toolkit.}
}
@article{WIGGINS2013976,
journal = {International Journal of Information Management},
volume = {33},
number = {6},
pages = {976-977},
year = {2013},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2013.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0268401213001229},
author = {Bob Wiggins}
}
@incollection{MCKNIGHT20141,
title = {Chapter One - You’re in the Business of Information},
editor = {William McKnight},
booktitle = {Information Management},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {1-8},
year = {2014},
isbn = {978-0-12-408056-0},
doi = {https://doi.org/10.1016/B978-0-12-408056-0.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780124080560000011},
author = {William McKnight},
keywords = {business intelligence, data warehousing, information management, big data, information architecture, performance management, leadership},
abstract = {An introductory chapter stressing the importance of information to any business and how good decisions are made based on data.}
}
@article{2016IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {60},
pages = {IFC},
year = {2016},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(16)30216-2},
url = {https://www.sciencedirect.com/science/article/pii/S0306437916302162}
}
@article{ZHANG201629,
title = {Privacy-preserving QoI-aware participant coordination for mobile crowdsourcing},
journal = {Computer Networks},
volume = {101},
pages = {29-41},
year = {2016},
note = {Industrial Technologies and Applications for the Internet of Things},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2015.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S1389128616000074},
author = {Bo Zhang and Chi Harold Liu and Jianyu Lu and Zheng Song and Ziyu Ren and Jian Ma and Wendong Wang},
keywords = {Mobile crowdsourcing, Participant selection, Privacy protection, Internet of Things},
abstract = {Mobile crowdsourcing systems are important sources of information for the Internet of Things (IoT) such as gathering location related sensing data for various applications by employing ordinary citizens to participate in data collection. In order to improve the Quality of Information (QoI) of the collected data, the system server needs to coordinate participants with different data collection capabilities and various incentive requirements. However, existing participant coordination methods require the participants to reveal their trajectories to the system server which causes privacy leakage. But, with the improvement of ordinary citizens’ consciousness to protect their rights, the risk of privacy leakage may reduce their enthusiasm for data collection. In this paper, we propose a participant coordination framework, which allows the system server to provide optimal QoI for sensing tasks without knowing the trajectories of participants. The participants work cooperatively to coordinate their sensing tasks instead of relying on the traditional centralized server. A cooperative data aggregation, an incentive distribution method, and a punishment mechanism are further proposed to both protect participant privacy and ensure the QoI of the collected data. Simulation results show that our proposed method can efficiently select appropriate participants to achieve better QoI than other methods, and can protect each participant’s privacy effectively.}
}
@incollection{2014285,
title = {Index},
editor = {Alexander Borek and Ajith K. Parlikad and Jela Webb and Philip Woodall},
booktitle = {Total Information Risk Management},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {285-290},
year = {2014},
isbn = {978-0-12-405547-6},
doi = {https://doi.org/10.1016/B978-0-12-405547-6.18001-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780124055476180010}
}
@incollection{KOLTAY20161,
title = {Chapter 1 - Shifting Research Paradigms Toward Research 2.0},
editor = {Tibor Koltay and Sonja Špiranec and László Z. Karvalics},
booktitle = {Research 2.0 and the Future of Information Literacy},
publisher = {Chandos Publishing},
pages = {1-59},
year = {2016},
isbn = {978-0-08-100075-5},
doi = {https://doi.org/10.1016/B978-0-08-100075-5.00001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780081000755000018},
author = {Tibor Koltay and Sonja Špiranec and László Z. Karvalics},
keywords = {Research paradigms, Research 2.0, Researchers’ skills and abilities, Open science, Open access, The data-intensive paradigm of scientific research, Alternative metrics of scientific output},
abstract = {This chapter discusses how Research 2.0 came into existence and how it developed into a leading paradigm of our era. This requires an outline of the socio-technical changes brought about by the development and widespread use of information and communications technologies, based on computers and leading to the appearance of social media. There is no one who would deny that researchers are central figures in research, so their skills and abilities will be briefly examined. Research 2.0 is closely connected to the idea of open science that will be described, giving especial attention to its main constituent that is open access. Open science also comprises the data-intensive paradigm of scientific research, which we consider in detail. A wider uptake of Research 2.0 is inhibited by a number of the factors of scholarly communication, so we will enumerate them.}
}
@article{MILHAM2012214,
title = {Open Neuroscience Solutions for the Connectome-wide Association Era},
journal = {Neuron},
volume = {73},
number = {2},
pages = {214-218},
year = {2012},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2011.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0896627311010038},
author = {Michael Peter Milham},
abstract = {The neuroimaging community is at a crossroads. Long characterized by individualism, the data and computational and analytic needs of the connectome-wide association era necessitate cultural reform. Emerging initiatives have demonstrated the feasibility and utility of adopting an open neuroscience model to accelerate the pace and success of scientific discovery.}
}
@article{LAISKPODAR2016516,
title = {Ovarian Physiology and GWAS: Biobanks, Biology, and Beyond},
journal = {Trends in Endocrinology & Metabolism},
volume = {27},
number = {7},
pages = {516-528},
year = {2016},
issn = {1043-2760},
doi = {https://doi.org/10.1016/j.tem.2016.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1043276016300273},
author = {Triin Laisk-Podar and Cecilia M. Lindgren and Maire Peters and Juha S. Tapanainen and Cornelis B. Lambalk and Andres Salumets and Reedik Mägi},
keywords = {ovarian reserve, menopause, polycystic ovary syndrome, premature ovarian insufficiency},
abstract = {Ovarian function is central to female fertility, and several genome-wide association studies (GWAS) have been carried out to elucidate the genetic background of traits and disorders that reflect and affect ovarian physiology. While GWAS have been successful in reporting numerous genetic associations and highlighting involved pathways relevant to reproductive aging, for ovarian disorders, such as premature ovarian insufficiency and polycystic ovary syndrome, research has lagged behind due to insufficient study sample size. Novel approaches to study design and analysis methods that help to fit GWAS findings into biological context will improve our knowledge about genetics governing ovarian function in fertility and disease, and provide input for clinical tools and better patient management.}
}
@article{NGO2016498,
title = {A Data-based Approach for Quality Regulation},
journal = {Procedia CIRP},
volume = {57},
pages = {498-503},
year = {2016},
note = {Factories of the Future in the digital environment - Proceedings of the 49th CIRP Conference on Manufacturing Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2016.11.086},
url = {https://www.sciencedirect.com/science/article/pii/S2212827116312409},
author = {Quoc Hao Ngo and Robert H. Schmitt},
keywords = {quality management, quality control, quality regulation, zero-defect manufacturing, quality 4.0, data-driven production},
abstract = {In the customized production more complex processes are required. Companies are challenged by monitoring these complex processes which compared to mass production show a lower degree of standardization and are therefore characterized by higher instabilities. Quality management has developed various techniques to deal with instabilities such as error analysis and process monitoring, which are implemented successfully in mass production. These techniques are based on the principle of causality and are effective in identifying, monitoring and adjusting the main cause of error in isolated effect chains. Within the customized production the elimination of the main cause of error does not lead to a sustained improvement of production quality since causes of error differ due to varied products to be manufactured. Furthermore, processes in customized production increasingly imply immanent interdependencies. The emergence of quality along the value chain is thus getting more complex and can less be explained by an effect chain using the principle of causality. The data-based quality regulation is therefore developed in order to achieve high quality in complex production. This paper outlines the data-based quality regulation as well as its need for research. Afterwards, an approach based on a virtual production model to validate suitable data mining methods for the data-based quality regulation is provided.}
}
@article{VERDOODT2016599,
title = {Toying with children's emotions, the new game in town? The legality of advergames in the EU},
journal = {Computer Law & Security Review},
volume = {32},
number = {4},
pages = {599-614},
year = {2016},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2016.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0267364916300851},
author = {Valerie Verdoodt and Damian Clifford and Eva Lievens},
keywords = {Advergames, Children's rights, Data protection and privacy, Consumer protection, Advertising, Emotions},
abstract = {Marketing techniques such as advergames have proven to be an extremely useful marketing tool for advertisers and in particular when targeted towards children. Such techniques allow for the development of a positive product or brand association through the delivery of fun interactive content. As a result, children are no longer merely passive receivers of commercial communications. Instead, they become actively involved in the advertising process. Advergames have a potentially manipulative aspect. Children are often unable to distinguish between the commercial message and the non-commercial content. This has negative consequences when one considers the potentially persuasive nature of marketing techniques such as advergames which can further heighten this confusion. Moreover, as modern business models are based on data, advertisers are increasingly interested in the personal information of their young customers. Increased computing capabilities mean that commercial entities are now able to profile individual consumer behaviour online and assess how it differs from rational decision-making and to leverage this for economic gain. Such profiles facilitate the targeting of personalised advertisements thereby tailoring marketing campaigns based on children's behaviour. The capacity to collect and process information in addition to the technical ability to personalise consumer services online potentially allows for the triggering of consumer frailty. This has particular importance when one considers the effects of positive emotions, caused by advergames. The purpose of this paper is to examine the legal issues associated with advergames from an EU perspective and, in particular, this advertising technique's capacity to manipulate emotions.}
}
@incollection{2016xvii,
title = {Author Biographies},
editor = {Tiffany C. Vance and Nazila Merati and Chaowei Yang and May Yuan},
booktitle = {Cloud Computing in Ocean and Atmospheric Sciences},
publisher = {Academic Press},
pages = {xvii-xxix},
year = {2016},
isbn = {978-0-12-803192-6},
doi = {https://doi.org/10.1016/B978-0-12-803192-6.11001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128031926110011}
}
@incollection{DURRESI2016389,
title = {Chapter 14 - (Bio)Sensor Integration With ICT Tools for Supplying Chain Management and Traceability in Agriculture},
editor = {Viviana Scognamiglio and Giuseppina Rea and Fabiana Arduini and Giuseppe Palleschi},
series = {Comprehensive Analytical Chemistry},
publisher = {Elsevier},
volume = {74},
pages = {389-413},
year = {2016},
booktitle = {Biosensors for Sustainable Food - New Opportunities and Technical Challenges},
issn = {0166-526X},
doi = {https://doi.org/10.1016/bs.coac.2016.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166526X16300927},
author = {M. Durresi},
keywords = {Biosensors, Data mining, Data storage, Food supply chain, Smart sensors, Traceability, Wireless sensors network}
}
@article{YALEW20161,
title = {AgriSuit: A web-based GIS-MCDA framework for agricultural land suitability assessment},
journal = {Computers and Electronics in Agriculture},
volume = {128},
pages = {1-8},
year = {2016},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2016.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0168169916306056},
author = {S.G. Yalew and A. {van Griensven} and P. {van der Zaag}},
keywords = {Multi-criteria analysis, Land suitability, AHP, GIS, Remote sensing},
abstract = {A web-based framework (AgriSuit) that integrates various global data from different sources for multi-criteria based agricultural land suitability assessment based on the Google Earth Engine (GEE) platform is developed and presented. The platform enables online data gathering, training and classifying of land cover classes based on remote sensing and GIS techniques, as well as computation of suitability of land-use classes for agricultural activities. A demonstration of the framework on the Upper Blue Nile basin in Ethiopia is presented.}
}
@incollection{HOOD2013445,
title = {Chapter 23 - Systems Medicine and the Emergence of Proactive P4 Medicine: Predictive, Preventive, Personalized and Participatory},
editor = {A.J. Marian Walhout and Marc Vidal and Job Dekker},
booktitle = {Handbook of Systems Biology},
publisher = {Academic Press},
address = {San Diego},
pages = {445-467},
year = {2013},
isbn = {978-0-12-385944-0},
doi = {https://doi.org/10.1016/B978-0-12-385944-0.00023-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012385944000023X},
author = {Leroy Hood and Mauricio A. Flores and Kristin R. Brogaard and Nathan D. Price}
}
@article{BARON20142,
title = {The 2013 symposium on pathology data integration and clinical decision support and the current state of field},
journal = {Journal of Pathology Informatics},
volume = {5},
number = {1},
pages = {2},
year = {2014},
issn = {2153-3539},
doi = {https://doi.org/10.4103/2153-3539.126145},
url = {https://www.sciencedirect.com/science/article/pii/S2153353922002711},
author = {Jason M. Baron and Anand S. Dighe and Ramy Arnaout and Ulysses J. Balis and W. Stephen Black-Schaffer and Alexis B. Carter and Walter H. Henricks and John M. Higgins and Brian R. Jackson and JiYeon Kim and Veronica E. Klepeis and Long P. Le and David N. Louis and Diana Mandelker and Craig H. Mermel and James S. Michaelson and Rakesh Nagarajan and Mihae E. Platt and Andrew M. Quinn and Luigi Rao and Brian H. Shirts and John R. Gilbertson},
keywords = {Clinical decision support, genomics, interpretive reporting, machine learning, test utilization},
abstract = {Background: Pathologists and informaticians are becoming increasingly interested in electronic clinical decision support for pathology, laboratory medicine and clinical diagnosis. Improved decision support may optimize laboratory test selection, improve test result interpretation and permit the extraction of enhanced diagnostic information from existing laboratory data. Nonetheless, the field of pathology decision support is still developing. To facilitate the exchange of ideas and preliminary studies, we convened a symposium entitled: Pathology data integration and clinical decision support. Methods: The symposium was held at the Massachusetts General Hospital, on May 10, 2013. Participants were selected to represent diverse backgrounds and interests and were from nine different institutions in eight different states. Results: The day included 16 plenary talks and three panel discussions, together covering four broad areas. Summaries of each presentation are included in this manuscript. Conclusions: A number of recurrent themes emerged from the symposium. Among the most pervasive was the dichotomy between diagnostic data and diagnostic information, including the opportunities that laboratories may have to use electronic systems and algorithms to convert the data they generate into more useful information. Differences between human talents and computer abilities were described; well-designed symbioses between humans and computers may ultimately optimize diagnosis. Another key theme related to the unique needs and challenges in providing decision support for genomics and other emerging diagnostic modalities. Finally, many talks relayed how the barriers to bringing decision support toward reality are primarily personnel, political, infrastructural and administrative challenges rather than technological limitations.}
}
@article{2014IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {45},
pages = {IFC},
year = {2014},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(14)00078-7},
url = {https://www.sciencedirect.com/science/article/pii/S0306437914000787}
}
@article{HIRD2016900,
title = {Digital health revolution: perfect storm or perfect opportunity for pharmaceutical R&D?},
journal = {Drug Discovery Today},
volume = {21},
number = {6},
pages = {900-911},
year = {2016},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2016.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S1359644616000301},
author = {Nick Hird and Samik Ghosh and Hiroaki Kitano},
abstract = {The convergence of technology and medicine has pushed healthcare to the brink of a major disruption that pharma has, until recently, been slow to recognize. Tech players have pioneered the emerging field of digital wellness and health, and pharma is ideally placed to use its expertise in drug development and embrace these technologies to create digital applications that address major medical needs. This review describes digital innovation from a pharma R&D perspective, outlining principal drivers, digital components, opportunities and challenges as well as a sustainable new business model predicated on empowered patients and achieving therapeutic outcomes.}
}
@article{MORENCY20156,
title = {Embracing Technological and Behavioral Changes: A Synthesis},
journal = {Transportation Research Procedia},
volume = {11},
pages = {6-18},
year = {2015},
note = {Transport Survey Methods: Embracing Behavioural and Technological Changes Selected contributions from the 10th International Conference on Transport Survey Methods 16-21 November 2014, Leura, Australia},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2015.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352146515002938},
author = {Catherine Morency and Marcela Munizaga},
keywords = {survey methods, technology, behaviour},
abstract = {This document presents an introduction to the ISCTSC Special Issue of Transport Research Procedia. It synthesizes the discussions held at the 10th International Conference on Transport Survey Methods, and describes the contents of the selected contributions. This conference has been held in different countries from all over the world, involving an increasing group of enthusiastic and generous specialists, willing to share their knowledge. This 10th conference was an opportunity to discuss the state of the art on transport survey methods, but also to question the way transport surveys are conducted. We took the opportunity to identify the main challenges, and the most important questions.}
}
@article{MARKOWITZ2015730,
title = {Ten Years of Maintaining and Expanding a Microbial Genome and Metagenome Analysis System},
journal = {Trends in Microbiology},
volume = {23},
number = {11},
pages = {730-741},
year = {2015},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2015.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X15001754},
author = {Victor M. Markowitz and I-Min A. Chen and Ken Chu and Amrita Pati and Natalia N. Ivanova and Nikos C. Kyrpides},
keywords = {microbial genomics, metagenomics, comparative genome analysis},
abstract = {Launched in March 2005, the Integrated Microbial Genomes (IMG) system is a comprehensive data management system that supports multidimensional comparative analysis of genomic data. At the core of the IMG system is a data warehouse that contains genome and metagenome datasets sequenced at the Joint Genome Institute or provided by scientific users, as well as public genome datasets available at the National Center for Biotechnology Information Genbank sequence data archive. Genomes and metagenome datasets are processed using IMG's microbial genome and metagenome sequence data processing pipelines and are integrated into the data warehouse using IMG's data integration toolkits. Microbial genome and metagenome application specific data marts and user interfaces provide access to different subsets of IMG's data and analysis toolkits. This review article revisits IMG's original aims, highlights key milestones reached by the system during the past 10 years, and discusses the main challenges faced by a rapidly expanding system, in particular the complexity of maintaining such a system in an academic setting with limited budgets and computing and data management infrastructure.}
}
@article{2016IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {61},
pages = {IFC},
year = {2016},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(16)30242-3},
url = {https://www.sciencedirect.com/science/article/pii/S0306437916302423}
}
@incollection{LI2016137,
title = {Chapter 9 - A2CI: A Cloud-Based, Service-Oriented Geospatial Cyberinfrastructure to Support Atmospheric Research},
editor = {Tiffany C. Vance and Nazila Merati and Chaowei Yang and May Yuan},
booktitle = {Cloud Computing in Ocean and Atmospheric Sciences},
publisher = {Academic Press},
pages = {137-161},
year = {2016},
isbn = {978-0-12-803192-6},
doi = {https://doi.org/10.1016/B978-0-12-803192-6.00009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128031926000098},
author = {W. Li and H. Shao and S. Wang and X. Zhou and S. Wu},
keywords = {Crawler, Cyberinfrastructure, Interoperability, Service-oriented, Visualization},
abstract = {Big Earth science data offer the scientific community today great opportunities. Many more studies at large scale, long term, and high resolution can now be conducted using the rich information collected by remote sensing satellites, ground-based sensor networks, and even social media input. However, the hundreds of terabytes of information collected and compiled on an hourly basis by NASA and other government agencies present a significant challenge for atmospheric scientists seeking to improve the understanding of the Earth atmospheric system. These challenges include effective discovery, organization, analysis, and visualization of large amounts of data. This paper reports the outcomes of an NSF-funded project that developed a geospatial cyberinfrastructure—the A2CI (Atmospheric Analysis Cyberinfrastructure)—to support atmospheric research. We first introduce the service-oriented system framework, then describe in detail the implementation of the data discovery module, data management module, data integration module, data analysis and visualization modules following the cloud-computing principles—Data as a Service, Software as a Service, Platform as a Service, and Infrastructure as a Service. We demonstrate the graphic user interface by performing an analysis between Sea Surface Temperature and the intensity of tropical storms in the North Atlantic and Pacific Oceans. We expect this work to contribute to the technical advancement of cyberinfrastructure research as well as to the development of an online, collaborative scientific analysis system for atmospheric science.}
}
@article{2016iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {80},
pages = {iii-xi},
year = {2016},
note = {International Conference on Computational Science 2016, ICCS 2016, 6-8 June 2016, San Diego, California, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(16)31051-1},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916310511}
}
@article{2015IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {52},
pages = {IFC},
year = {2015},
note = {Special Issue on Selected Papers from SISAP 2013},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(15)00076-9},
url = {https://www.sciencedirect.com/science/article/pii/S0306437915000769}
}
@article{DIEZROUX2015980,
title = {Social and Behavioral Information in Electronic Health Records: New Opportunities for Medicine and Public Health},
journal = {American Journal of Preventive Medicine},
volume = {49},
number = {6},
pages = {980-983},
year = {2015},
issn = {0749-3797},
doi = {https://doi.org/10.1016/j.amepre.2015.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S0749379715005176},
author = {Ana V. {Diez Roux} and Mitchell Katz and Deidra C. Crews and David Ross and Nancy Adler}
}
@article{FENG2015199,
title = {Spectroscopic Measurements in Oil Sands Industry-From Laboratories to Real-time Applications},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {8},
pages = {199-204},
year = {2015},
note = {9th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2015},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.08.181},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315010484},
author = {Enbo Feng and Elom Domlan and Ramesh Kadali},
keywords = {Spectroscope, NIR, NMR, oil sands, measurement, chemometrics},
abstract = {This article presents an overview of the principle, engineering implementation and applications of spectroscopic measurements technology, such as NIR (near infrared), FTIR (Fourier transform infrared), Raman and NMR (nuclear magnetic resonance). The discussions are focused on oil sands industry in which the process majorly consists of the mining, slurry hydro-transport, extraction, froth treatment and upgrading plants.}
}
@article{KOHLI2015396,
title = {The Imaging 3.0 Informatics Scorecard},
journal = {Journal of the American College of Radiology},
volume = {12},
number = {4},
pages = {396-402},
year = {2015},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2014.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S154614401400787X},
author = {Marc Kohli and Keith J. Dreyer and J. Raymond Geis},
keywords = {Imaging 3.0, imaging informatics, radiology information technology, innovation, clinical decision support},
abstract = {Imaging 3.0 is a radiology community initiative to empower radiologists to create and demonstrate value for their patients, referring physicians, and health systems. In image-guided health care, radiologists contribute to the entire health care process, well before and after the actual examination, and out to the point at which they guide clinical decisions and affect patient outcome. Because imaging is so pervasive, radiologists who adopt Imaging 3.0 concepts in their practice can help their health care systems provide consistently high-quality care at reduced cost. By doing this, radiologists become more valuable in the new health care setting. The authors describe how informatics is critical to embracing Imaging 3.0 and present a scorecard that can be used to gauge a radiology group’s informatics resources and capabilities.}
}
@article{2015IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {50},
pages = {IFC},
year = {2015},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(15)00036-8},
url = {https://www.sciencedirect.com/science/article/pii/S0306437915000368}
}
@article{ZUO2014100,
title = {Test-retest reliabilities of resting-state FMRI measurements in human brain functional connectomics: A systems neuroscience perspective},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {45},
pages = {100-118},
year = {2014},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2014.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0149763414001262},
author = {Xi-Nian Zuo and Xiu-Xia Xing},
keywords = {Test-retest reliability, Reproducibility, Resting state fMRI, Brain connectome, Functional connectomics},
abstract = {Resting-state functional magnetic resonance imaging (RFMRI) enables researchers to monitor fluctuations in the spontaneous brain activities of thousands of regions in the human brain simultaneously, representing a popular tool for macro-scale functional connectomics to characterize normal brain function, mind-brain associations, and the various disorders. However, the test-retest reliability of RFMRI remains largely unknown. We review previously published papers on the test-retest reliability of voxel-wise metrics and conduct a meta-summary reliability analysis of seven common brain networks. This analysis revealed that the heteromodal associative (default, control, and attention) networks were mostly reliable across the seven networks. Regarding examined metrics, independent component analysis with dual regression, local functional homogeneity and functional homotopic connectivity were the three mostly reliable RFMRI metrics. These observations can guide the use of reliable metrics and further improvement of test-retest reliability for other metics in functional connectomics. We discuss the main issues with low reliability related to sub-optimal design and the choice of data processing options. Future research should use large-sample test-retest data to rectify both the within-subject and between-subject variability of RFMRI measurements and accelerate the application of functional connectomics.}
}
@incollection{LIN2015619,
title = {Citizen Mapping},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {619-624},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.72102-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868721027},
author = {Wen Lin},
keywords = {Cartography, Citizen mapping, Critical GIS, Geographic information systems, Geovisualization, Geoweb, Neogeography, Volunteered geographic information, Web 2.0},
abstract = {Since the mid-2000s, there have been significant shifts in geographic information production and dissemination, marked by the emergence of user-generated geographic information. This form of mapping and spatial data production, facilitated by an array of Web 2.0 technologies and location-aware mobile devices, has allowed ordinary citizens to carry out mapping practices without formal training in Geographic Information Systems or cartography. This article aims to provide an overview of the research on these mapping practices, known as citizen mapping; the focus is on three broad strands of work: spatial data in citizen mapping, citizen mapping as social process, and related methodological challenges and developments.}
}
@article{2016IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {62},
pages = {IFC},
year = {2016},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(16)30357-X},
url = {https://www.sciencedirect.com/science/article/pii/S030643791630357X}
}
@article{SUTHERLAND2016251,
title = {Electronic Health Record–Enabled Research in Children Using the Electronic Health Record for Clinical Discovery},
journal = {Pediatric Clinics of North America},
volume = {63},
number = {2},
pages = {251-268},
year = {2016},
note = {Quality of Care and Information Technology},
issn = {0031-3955},
doi = {https://doi.org/10.1016/j.pcl.2015.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0031395515002035},
author = {Scott M. Sutherland and David C. Kaelber and N. Lance Downing and Veena V. Goel and Christopher A. Longhurst},
keywords = {EHR, EMR, Electronic health record, Electronic medical record, Research, Clinical discovery, Children}
}
@article{KOLLIAKOU201615,
title = {Novel psychoactive substances: An investigation of temporal trends in social media and electronic health records},
journal = {European Psychiatry},
volume = {38},
pages = {15-21},
year = {2016},
issn = {0924-9338},
doi = {https://doi.org/10.1016/j.eurpsy.2016.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924933816300219},
author = {A. Kolliakou and M. Ball and L. Derczynski and D. Chandran and G. Gkotsis and P. Deluca and R. Jackson and H. Shetty and R. Stewart},
keywords = {Novel psychoactive substances, Mephedrone, Electronic health records, Social media, Public health monitoring},
abstract = {Background
Public health monitoring is commonly undertaken in social media but has never been combined with data analysis from electronic health records. This study aimed to investigate the relationship between the emergence of novel psychoactive substances (NPS) in social media and their appearance in a large mental health database.
Methods
Insufficient numbers of mentions of other NPS in case records meant that the study focused on mephedrone. Data were extracted on the number of mephedrone (i) references in the clinical record at the South London and Maudsley NHS Trust, London, UK, (ii) mentions in Twitter, (iii) related searches in Google and (iv) visits in Wikipedia. The characteristics of current mephedrone users in the clinical record were also established.
Results
Increased activity related to mephedrone searches in Google and visits in Wikipedia preceded a peak in mephedrone-related references in the clinical record followed by a spike in the other 3 data sources in early 2010, when mephedrone was assigned a ‘class B’ status. Features of current mephedrone users widely matched those from community studies.
Conclusions
Combined analysis of information from social media and data from mental health records may assist public health and clinical surveillance for certain substance-related events of interest. There exists potential for early warning systems for health-care practitioners.}
}
@article{WIEDER20151163,
title = {The Impact of Business Intelligence on the Quality of Decision Making – A Mediation Model},
journal = {Procedia Computer Science},
volume = {64},
pages = {1163-1171},
year = {2015},
note = {Conference on ENTERprise Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015 October 7-9, 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.599},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915027349},
author = {Bernhard Wieder and Maria-Luise Ossimitz},
keywords = {Business Intelligence, BI management, information quality, BI benefits, quality of decision making},
abstract = {Business Intelligence (BI) systems have been a top priority of CIOs for a decade, but little is known about how to successfully manage those systems beyond the implementation phase. This paper investigates the direct and indirect effects of BI management quality on the quality of managerial decision making using PLS analysis of survey responses of senior IT managers in Australia. The results confirm this overall relationship (total effect), but also reveal mediating effects of data/information quality and BI solution scope. The study contributes to both academia and industry by providing first time evidence of direct and indirect determinants of managerial decision support improvements related to BI solutions scope and active management of BI.}
}
@article{EKINS2013265,
title = {Four disruptive strategies for removing drug discovery bottlenecks},
journal = {Drug Discovery Today},
volume = {18},
number = {5},
pages = {265-271},
year = {2013},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2012.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1359644612003601},
author = {Sean Ekins and Chris L. Waller and Mary P. Bradley and Alex M. Clark and Antony J. Williams},
abstract = {Drug discovery is shifting focus from industry to outside partners and, in the process, creating new bottlenecks. Technologies like high throughput screening (HTS) have moved to a larger number of academic and institutional laboratories in the USA, with little coordination or consideration of the outputs and creating a translational gap. Although there have been collaborative public–private partnerships in Europe to share pharmaceutical data, the USA has seemingly lagged behind and this may hold it back. Sharing precompetitive data and models may accelerate discovery across the board, while finding the best collaborators, mining social media and mobile approaches to open drug discovery should be evaluated in our efforts to remove drug discovery bottlenecks. We describe four strategies to rectify the current unsustainable situation.}
}
@article{2015iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {64},
pages = {iii-viii},
year = {2015},
note = {Conference on ENTERprise Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015 October 7-9, 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(15)02827-6},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915028276}
}
@incollection{2014565,
title = {Subject Index},
editor = {Indra Neil Sarkar},
booktitle = {Methods in Biomedical Informatics},
publisher = {Academic Press},
address = {Oxford},
pages = {565-571},
year = {2014},
isbn = {978-0-12-401678-1},
doi = {https://doi.org/10.1016/B978-0-12-401678-1.00029-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124016781000294}
}
@incollection{2016393,
title = {Index},
editor = {Tiffany C. Vance and Nazila Merati and Chaowei Yang and May Yuan},
booktitle = {Cloud Computing in Ocean and Atmospheric Sciences},
publisher = {Academic Press},
pages = {393-415},
year = {2016},
isbn = {978-0-12-803192-6},
doi = {https://doi.org/10.1016/B978-0-12-803192-6.18001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128031926180016}
}
@incollection{LOSHIN2013189,
title = {Chapter 13 - Data Integration},
editor = {David Loshin},
booktitle = {Business Intelligence (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {189-210},
year = {2013},
series = {MK Series on Business Intelligence},
isbn = {978-0-12-385889-4},
doi = {https://doi.org/10.1016/B978-0-12-385889-4.00013-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780123858894000132},
author = {David Loshin}
}
@article{KJER201640,
title = {Advances using molecular data in insect systematics},
journal = {Current Opinion in Insect Science},
volume = {18},
pages = {40-47},
year = {2016},
note = {Neuroscience * Special Section on Insect phylogenetics},
issn = {2214-5745},
doi = {https://doi.org/10.1016/j.cois.2016.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2214574516301468},
author = {Karl Kjer and Marek L Borowiec and Paul B Frandsen and Jessica Ware and Brian M Wiegmann},
abstract = {The size of molecular datasets has been growing exponentially since the mid 1980s, and new technologies have now dramatically increased the slope of this increase. New datasets include genomes, transcriptomes, and hybrid capture data, producing hundreds or thousands of loci. With these datasets, we are approaching a consensus on the higher level insect phylogeny. Huge datasets can produce new challenges in interpreting branch support, and new opportunities in developing better models and more sophisticated partitioning schemes. Dating analyses are improving as we recognize the importance of careful fossil calibration selection. With thousands of genes now available, coalescent methods have come of age. Barcode libraries continue to expand, and new methods are being developed for incorporating them into phylogenies with tens of thousands of individuals.}
}
@article{GUETAT20151088,
title = {The Architecture Facet of Information Governance: The Case of Urbanized Information Systems},
journal = {Procedia Computer Science},
volume = {64},
pages = {1088-1098},
year = {2015},
note = {Conference on ENTERprise Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015 October 7-9, 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.564},
url = {https://www.sciencedirect.com/science/article/pii/S187705091502699X},
author = {Sana Bent Aboulkacem Guetat and Salem Ben Dhaou Dakhli},
keywords = {information, information governance, information architecture, information architectural dimension, urbanized information system, architecture rule},
abstract = {Nowadays, information is considered as one of the main intangible assets of modern organizations since it plays a critical role in their competitive advantage and survival. In particular, information underpins any decision within organizations at both the daily operational and the tactical and strategic decision levels. As a result, information quality, and security requirements are exacerbated, in order to maximize operational efficiency, and respect the constraints imposed by the ever-changing legal and regulatory environment. However, information is not yet managed with the same rigor or the same means as other organizations resources, including capital and human resources. Information governance has been proposed by many authors as a necessary prerequisite for the establishment of an information valorization process. Many information governance approaches and frameworks have been proposed by academics and practitioners. Nevertheless, outcomes of these solutions are below expectations. This paper has three objectives. First, it proposes a framework which considers information architecture as a driver of information governance. Second, it describes the architecture facet of information governance by presenting an information architecture model. Third, it demonstrates how urbanized information systems take into account the architecture facet of information governance.}
}
@article{CHUA2016295,
title = {Mapping Cilento: Using geotagged social media data to characterize tourist flows in southern Italy},
journal = {Tourism Management},
volume = {57},
pages = {295-310},
year = {2016},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2016.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0261517716301005},
author = {Alvin Chua and Loris Servillo and Ernesto Marcheggiani and Andrew Vande Moere},
keywords = {Data mining, Visual analytics, Flow analysis, Geotagged social media data},
abstract = {New sources of geotagged information derived from social media like Twitter show great promise for geographic research in tourism. This paper describes an approach to analyze geotagged social media data from Twitter to characterize spatial, temporal and demographic features of tourist flows in Cilento - a regional tourist attraction in southern Italy. It demonstrates how the analysis of geotagged social media data yields more detailed spatial, temporal and demographic information of tourist movements, in comparison to the current understanding of tourist flows in the region. The insights obtained from our case study illustrate the potential of the proposed methodology yet attention should be paid to biases in the data as well as methodological limitations when drawing conclusions from analytical results.}
}
@incollection{2015xix,
title = {How to Use This Book},
editor = {Rick Sherman},
booktitle = {Business Intelligence Guidebook},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {xix-xxi},
year = {2015},
isbn = {978-0-12-411461-6},
doi = {https://doi.org/10.1016/B978-0-12-411461-6.05001-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780124114616050012}
}
@article{BARUCH2016923,
title = {The motivations, enablers and barriers for voluntary participation in an online crowdsourcing platform},
journal = {Computers in Human Behavior},
volume = {64},
pages = {923-931},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.07.039},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305295},
author = {Avinoam Baruch and Andrew May and Dapeng Yu},
keywords = {Crowdsourcing, Volunteering, Participation, Motivations, Enablers, Barriers},
abstract = {This paper examines the phenomena of online crowdsourcing from the perspectives of both volunteers and the campaign coordinator of Tomnod – an online mapping project that uses crowdsourcing to identify objects and places in satellite images. A mixed-methods approach was used to study the enablers and barriers to participation, taking into consideration the whole spectrum of volunteers. The results show broad diversity in online volunteers, both in their demographics and the factors affecting their voluntary participation. The majority are older than 50 years and many – particularly the most active volunteers – have disabilities or long term health problems. The personal circumstances of participants are highlighted as a major factor affecting involvement in campaigns. Like many other platforms, altruism is a key motivator, yet many participants are more interested in the quality of their data and the impact it has on the ground. For many participants of online crowdsourcing campaigns, their involvement is strongly linked to the level of contact they have with campaign coordinators, both in the design of the platform and in providing feedback on the impact of their contributions.}
}
@article{MORELLO201417,
title = {Quality Control (QC) procedures for Australia’s National Reference Station’s sensor data—Comparing semi-autonomous systems to an expert oceanographer},
journal = {Methods in Oceanography},
volume = {9},
pages = {17-33},
year = {2014},
issn = {2211-1220},
doi = {https://doi.org/10.1016/j.mio.2014.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211122014000425},
author = {Elisabetta B. Morello and Guillaume Galibert and Daniel Smith and Ken R. Ridgway and Ben Howell and Dirk Slawinski and Greg P. Timms and Karen Evans and Timothy P. Lynch},
keywords = {Sustained observing, Coastal oceanography, Climatology, Quality control, Fuzzy logic, IMOS},
abstract = {The National Reference Station (NRS) network, part of Australia’s Integrated Marine Observing System (IMOS), is designed to provide the baseline multi-decadal time series required to understand how large-scale, long-term change and variability in the global ocean are affecting Australia’s coastal ocean ecosystems. High temporal resolution observations of oceanographic variables are taken continuously across the network’s nine moored stations using a Water Quality Monitor (WQM) multi-sensor. The data collected are made freely available and thus need to be assessed to ensure their consistency and fitness-for-use prior to release. Here, we describe a hybrid quality control system comprising a series of tests to provide QC flags for these data and an experimental ‘fuzzy logic’ approach to assessing data. This approach extends the qualitative pass/fail approach of the QC flags to a quantitative system that provides estimates of uncertainty around each data point. We compared the results obtained from running these two assessment schemes on a common dataset to those produced by an independent manual QC undertaken by an expert oceanographer. The qualitative flag and quantitative fuzzy logic QC assessments were shown to be highly correlated and capable of flagging samples that were clearly erroneous. In general, however, the quality assessments of the two QC schemes did not accurately match those of the oceanographer, with the semi-automated QC schemes being far more conservative in flagging samples as ‘bad’. The conservative nature of the semi-automated systems does, however, provide a solution for QC with a known risk. Our software systems should thus be seen as robust low-pass filters of the data with subsequent expert review of data flagged as ‘bad’ to be recommended.}
}
@article{HUSNJAK2015816,
title = {Telematics System in Usage Based Motor Insurance},
journal = {Procedia Engineering},
volume = {100},
pages = {816-825},
year = {2015},
note = {25th DAAAM International Symposium on Intelligent Manufacturing and Automation, 2014},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.01.436},
url = {https://www.sciencedirect.com/science/article/pii/S1877705815004634},
author = {Siniša Husnjak and Dragan Peraković and Ivan Forenbacher and Marijan Mumdziev},
keywords = {Usage Based Insurance, Pay How You Drive, Pay As You Drive, Insurance Telematics, Motor Insurance Billing},
abstract = {For the premium calculation and billing process in the motor insurance, current billing models are very general and not optimally tailored for the end users. Important parameters such as mileage, driving behavior and types of roads driven are not considered for the premium calculation. Development of advanced information and communication systems, significant drop in the technology cost of ownership, as well as the necessity for market differentiation in the insurance industry, facilitated the appearance of new billing models in the motor insurance industry. The purpose of this paper is to demonstrate underlying principles of the technology facilitating new billing models in the motor insurance industry. This paper gives an overview of the system architecture of one of the telematics systems offered and used on the market, as well as the data model used in the billing process. The potential of such a system is demonstrated through the real case project implemented in Eastern Europe.}
}
@article{GARCIA2015153,
title = {Supply chain design and optimization: Challenges and opportunities},
journal = {Computers & Chemical Engineering},
volume = {81},
pages = {153-170},
year = {2015},
note = {Special Issue: Selected papers from the 8th International Symposium on the Foundations of Computer-Aided Process Design (FOCAPD 2014), July 13-17, 2014, Cle Elum, Washington, USA},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2015.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0098135415000861},
author = {Daniel J. Garcia and Fengqi You},
keywords = {Supply chains, EWO, Energy and sustainability, Multi-scale modeling and optimization, Life cycle optimization},
abstract = {Optimal supply chain design is vital to the success of industrial concerns now more than ever before. This paper reviews some principal research opportunities and challenges in the field of supply chain design. The growing area of enterprise-wide optimization and the increasing importance of energy and sustainability issues provide plentiful opportunities for supply chain design research. However, modeling, algorithmic, and computational challenges arise from these research opportunities. There are three major technical challenge areas where knowledge gaps can be addressed in supply chain design, namely multi-scale challenges, multi-objective and sustainability challenges, and multi-player challenges. This paper provides an overview of opportunity areas, a description of relevant technical challenges, and a perspective on how these challenges might be addressed in supply chain design. Illustrative examples are presented to illuminate avenues for future research.}
}
@article{BABIN20163133,
title = {Heresies and sacred cows in scholarly marketing publications},
journal = {Journal of Business Research},
volume = {69},
number = {8},
pages = {3133-3138},
year = {2016},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2015.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0148296315006268},
author = {Barry J. Babin and Mitch Griffin and Joseph F. Hair},
keywords = {Heresy, Knowledge, Journals, Method, Marketing Research},
abstract = {Merriam-Webster defines heresies as “dissent or deviation from a dominant theory, opinion, or practice.” This Journal of Business Research special issue and the editorial examine heresies and sacred cows in marketing research. Seven papers investigate different aspects of typical academic business journal presentations. Each manuscript critically analyzes generally accepted practices for the pursuit of publication in academic journals and reveals ways these practices may do more harm than good, hindering the goal of presenting true growth of knowledge through publication. The editorial provides an integrative schema for the manuscripts in the special issue. Providing a series of broader topics to tie the papers together, this special issue illustrates how the findings of each study can help improve our pursuit of knowledge. In addition, the editorial discusses heresies and sacred cows not covered by manuscripts in the current issue. The editorial concludes with recommendations for both authors and reviewers that may enhance the approach to research, methodologies employed, and reporting of scholarly research.}
}
@article{BHATT20152230,
title = {ACC/AHA/STS Statement on the Future of Registries and the Performance Measurement Enterprise: A Report of the American College of Cardiology/American Heart Association Task Force on Performance Measures and The Society of Thoracic Surgeons},
journal = {Journal of the American College of Cardiology},
volume = {66},
number = {20},
pages = {2230-2245},
year = {2015},
issn = {0735-1097},
doi = {https://doi.org/10.1016/j.jacc.2015.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S073510971504379X},
author = {Deepak L. Bhatt and Joseph P. Drozda and David M. Shahian and Paul S. Chan and Gregg C. Fonarow and Paul A. Heidenreich and Jeffrey P. Jacobs and Frederick A. Masoudi and Eric D. Peterson and Karl F. Welke},
keywords = {ACC/AHA Performance Measures, health policy and outcome research, quality indicators, registries}
}
@article{HAUSMANN201442,
title = {Enterprise Information Management Readiness: A Survey of Current Issues, Challenges and Strategy},
journal = {Procedia Technology},
volume = {16},
pages = {42-51},
year = {2014},
note = {CENTERIS 2014 - Conference on ENTERprise Information Systems / ProjMAN 2014 - International Conference on Project MANagement / HCIST 2014 - International Conference on Health and Social Care Information Systems and Technologies},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.10.066},
url = {https://www.sciencedirect.com/science/article/pii/S221201731400293X},
author = {Verena Hausmann and Susan P. Williams and Catherine A. Hardy and Petra Schubert},
keywords = {Enterprise Information Management (EIM), strategy, challenges, drivers, information capability;},
abstract = {In recent years organisations have witnessed considerable change in their information environment including the increasing volume of new (and mostly unstructured) information types. The imperative to manage this information across its entire lifecycle presents considerable challenges. This paper outlines the findings of an in-depth survey of information professionals addressing drivers, issues and challenges of Enterprise Information Management (EIM). The current status of EIM strategy and its benefits and challenges are addressed. The survey reveals that the drivers for EIM are diverse ranging from obtaining business value to meeting regulatory compliance. The study also shows that EIM drivers cannot be simply reduced to a series of technical or organisational needs but reveals EIM as a complex sociotechnical phenomenon. Few organisations have enterprise-wide EIM strategies in place; those who have them are better able to keep track of and achieve performance objectives. The survey sets the basis for further research investigations in supporting organisation in their EIM initiatives.}
}
@article{2016IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {59},
pages = {IFC},
year = {2016},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(16)30182-X},
url = {https://www.sciencedirect.com/science/article/pii/S030643791630182X}
}
@article{2015IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {51},
pages = {IFC},
year = {2015},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(15)00050-2},
url = {https://www.sciencedirect.com/science/article/pii/S0306437915000502}
}
@article{THOMPSON2015874,
title = {Known knowns, known unknowns, and unknown unknowns: can systems medicine provide a new approach to sepsis?},
journal = {British Journal of Anaesthesia},
volume = {114},
number = {6},
pages = {874-877},
year = {2015},
issn = {0007-0912},
doi = {https://doi.org/10.1093/bja/aev097},
url = {https://www.sciencedirect.com/science/article/pii/S0007091217314708},
author = {J.P. Thompson and T.J. Coats and M.R. Sims}
}
@article{CORTEREAL2014172,
title = {The Diffusion Stages of Business Intelligence & Analytics (BI&A): A Systematic Mapping Study},
journal = {Procedia Technology},
volume = {16},
pages = {172-179},
year = {2014},
note = {CENTERIS 2014 - Conference on ENTERprise Information Systems / ProjMAN 2014 - International Conference on Project MANagement / HCIST 2014 - International Conference on Health and Social Care Information Systems and Technologies},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.10.080},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314003077},
author = {Nadine Côrte-Real and Pedro Ruivo and Tiago Oliveira},
keywords = {BI&A, business intelligence & analytics, implementation, adoption, use, impacts, benefits, systematic mapping study},
abstract = {Business intelligence & analytics (BI&A) has evolved to become a foundational cornerstone of enterprise decision support. Since the way BI&A is implemented and assimilated is quite different among organizations is important to approach BI&A literature by four selected diffusion stages (adoption, implementation, use and impacts of use). The diffusion stages assume a crucial importance to track the BI&A evolution in organizations and justify the investment made. The main focus of this paper is to evidence BI&A research on its several diffusion stages. It provides an updated bibliography of BI&A articles published in the IS journal and conferences during the period of 2000 and 2013. A total of 30 articles from 11 journals and 8 conferences are reviewed. This study contributes to the BI&A research in three ways. This is the first systematic mapping study focused on BI&A diffusion stages. It contributes to see how BI&A stages have been analyzed (theories used, data collection methods, analysis methods and publication source). Finally, it observes that little attention has been given to BI&A post-adoption stages and proposes future research line on this area.}
}
@article{2014IFC,
title = {Aims and Scope},
journal = {Information Systems},
volume = {44},
pages = {IFC},
year = {2014},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(14)00060-X},
url = {https://www.sciencedirect.com/science/article/pii/S030643791400060X}
}
@incollection{WISE2012175,
title = {Chapter 16 - Required skillsets},
editor = {Lyndsay Wise},
booktitle = {Using Open Source Platforms for Business Intelligence},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {175-184},
year = {2012},
series = {MK Series on Business Intelligence},
isbn = {978-0-12-415811-5},
doi = {https://doi.org/10.1016/B978-0-12-415811-5.00016-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780124158115000160},
author = {Lyndsay Wise}
}
@article{CORVOL201615,
title = {Translational research on cognitive and behavioural disorders in neurological and psychiatric diseases},
journal = {Therapies},
volume = {71},
number = {1},
pages = {15-26},
year = {2016},
note = {XXXIes Rencontres Nationales de Pharmacologie et de Recherche Clinique, pour l'Innovation Thérapeutique et l'Evaluation des Technologies de Santé - Tables rondes Giens, 4 au 5 octobre 2015},
issn = {0040-5957},
doi = {https://doi.org/10.1016/j.therap.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0040595716000032},
author = {Jean-Christophe Corvol and Sylvia Goni and Régis Bordet and Carole Azuar and Olivier Blin and Frédéric Checler and Denis J. David and Franck Durif and Pierre-Olivier Fernagut and Julien Dupouey and Lisa Otten and Raphaël Gaillard and Marie-Louise Kemel and Joëlle Micallef and Marie-Christine Perault-Pochat and Anne-Lise Pitel and Philippe Truffinet},
keywords = {Neurology, Psychiatrics, Cognition, Behaviour, Pharmacology, Medications, Medical devices},
abstract = {Summary
The important medical and social burden of nervous system diseases contrasts with the currently limited therapeutic armamentarium and with the difficulty encountered in developing new therapeutic options. These failures can be explained by the conjunction of various phenomena related to the limitations of animal models, the narrow focus of research on precise pathophysiological mechanisms, and methodological issues in clinical trials. It is perhaps the paradigm itself of the way research is conducted that may be the real reason for our incapacity to find effective strategies. The purpose of this workshop was to define overall lines of research that could lead to the development of effective novel therapeutic solutions. Research has long focused on diseases per se rather than on cognitive and behavioural dimensions common to several diseases. Their expression is often partial and variable, but can today be well-characterised using neurophysiological or imaging methods. This dimensional or syndromic vision should enable a new insight to the question, taking a transnosographic approach to re-position research and to propose: translational models exploring the same functions in animal models and in humans; identification of homogeneous groups of patients defined according to the clinical, anatomico-functional and molecular characteristics; and preclinical and clinical developments enriched by the use of cognitive-behavioural, biological neurological, and imaging biomarkers. For this mutation to be successful, it must be accompanied by synchronised action from the public authorities and by ad hoc measures from the regulatory agencies.}
}
@incollection{GUZAN2014153,
title = {Chapter 7 - A Nanomaterial Registry},
editor = {Matthew S. Hull and Diana M. Bowman},
booktitle = {Nanotechnology Environmental Health and Safety (Second Edition)},
publisher = {William Andrew Publishing},
edition = {Second Edition},
address = {Oxford},
pages = {153-172},
year = {2014},
series = {Micro and Nano Technologies},
isbn = {978-1-4557-3188-6},
doi = {https://doi.org/10.1016/B978-1-4557-3188-6.00007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9781455731886000074},
author = {Kimberly A. Guzan and Vijay Gupta and Karmann C. Mills and Michele L. Ostraat},
keywords = {Compliance level rating, Nanoparticle Ontology, NKI, NIST, MIANs},
abstract = {The use of nanotechnology in consumer goods continues to grow at a rapid pace. According to the Woodrow Wilson International Center for Scholars Project on Emerging Nanotechnologies, the nanotechnology-enabled consumer products inventory contained 1317 self-identified products as of March 2011 (with potentially more going unreported), which is a growth of 521% since its initial release in March 2006. Stakeholders from the entire product life cycle are vested in understanding the potential effects that these nanomaterials may have on human health and safety and the fate and transport of these materials in the environment. Some examples of these stakeholders include research laboratories, manufacturers, consumers of nano-enabled products, and regulators involved in overseeing the safe use and disposal of these products. As a result, extensive research is being undertaken to relate the toxicity of nanomaterials to their structure and properties. A vast amount of data is being generated in the process.}
}
@incollection{WINTERSMINER2015975,
title = {Chapter 17 - The Predictive Potential of Connected Digital Health},
editor = {Linda A. Winters-Miner and Pat S. Bolding and Joseph M. Hilbe and Mitchell Goldstein and Thomas Hill and Robert Nisbet and Nephi Walton and Gary D. Miner},
booktitle = {Practical Predictive Analytics and Decisioning Systems for Medicine},
publisher = {Academic Press},
pages = {975-988},
year = {2015},
isbn = {978-0-12-411643-6},
doi = {https://doi.org/10.1016/B978-0-12-411643-6.00045-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124116436000454},
author = {Linda A. Winters-Miner and Pat Bolding and Thomas Hill and Bob Nisbet and Mitchell Goldstein and Joseph M. Hilbe and Nephi Walton and Gary Miner and Christopher L. Wasden},
keywords = {Mobile Health Technology, Digital Consumer Connections, liabilities, precision and probabilistic medicine, privacy and security},
abstract = {With the development of a healthcare-centered democracy, we have seen an explosion in the volume and velocity of patient-generated data. This development has become a driving force in the connection of digital health records to each other and to diagnosis and treatment practitioners. The volume of patient-generated data and their digital format provide hints that point to the promise and potential of what predictive analytics will be able to do if we can harness this torrent of bits and bytes. Mobile connected health devices and applications are proving to be one of the most disruptive forces within health care – but this disruption is moving health care in new, exciting directions. These “bring your own device” technologies are generally smaller, faster, better, and cheaper than many traditional products.}
}
@incollection{2013219,
editor = {Douglas K. Barry and David Dick},
booktitle = {Web Services, Service-Oriented Architectures, and Cloud Computing (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {219-226},
year = {2013},
series = {The Savvy Manager's Guides},
isbn = {978-0-12-398357-2},
doi = {https://doi.org/10.1016/B978-0-12-398357-2.00023-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780123983572000233}
}
@article{LARBURU2015451,
title = {Quality-of-Data Management for Telemedicine Systems},
journal = {Procedia Computer Science},
volume = {63},
pages = {451-458},
year = {2015},
note = {The 6th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2015)/ The 5th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2015)/ Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.367},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915025028},
author = {Nekane Larburu and Richard Bults and Marten {van Sinderen} and Hermie Hermens},
keywords = {Quality-of-data dimensions, information and communication technology, clinical-decision-support-systems},
abstract = {This paper describes techniques to manage the quality-of-data (QoD), particularly in telemedicine systems. Hence, clinical data users, such as clinical decision support systems that support ‘real-time’ guidance of ambulatory patients, can process the data together with QoD in order to make the ‘best’ treatment decisions. Current information and communication technology (ICT) applied in telemedicine systems enables remote clinical data collection and delivery to the point of decision, thereby giving opportunities to develop new, pervasive, healthcare applications. However, the QoD in such distributed and decentralized environments is not always guaranteed. We propose QoD management techniques that take into account the multidimensionality of QoD and its ‘fitness for use’. Additionally, we present a technique that handles the quality of ‘real-time’ streaming data. We developed a telemedicine system prototype to investigate the applicability and the usefulness of the proposed techniques.}
}
@article{BUNGE201636,
title = {Mood management effects of brief unsupported internet interventions},
journal = {Internet Interventions},
volume = {5},
pages = {36-43},
year = {2016},
issn = {2214-7829},
doi = {https://doi.org/10.1016/j.invent.2016.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2214782916300094},
author = {Eduardo L. Bunge and Rachel E. Williamson and Monique Cano and Yan Leykin and Ricardo F. Muñoz},
keywords = {Depression, Anxiety, Mood, Confidence, Motivation, Internet intervention},
abstract = {ABSTRACT
Background
Most users of unsupported Internet interventions visit that site only once, therefore there is a need to create interventions that can be offered as a single brief interaction with the user.
Objective
The main goal of this study was to compare the effect of a one-session unsupported Internet intervention on participants' clinical symptoms (depressive and anxiety symptoms) and related variables (mood, confidence and motivation).
Method
A total of 765 adults residing in the United States took part in a randomized controlled trial. Participants were randomly assigned to one of five brief plain text interventions lasting 5–10min. The interventions designed to address depressive symptoms were: thoughts (increasing helpful thoughts), activities (increasing activity level), sleep hygiene, assertiveness (increasing assertiveness awareness), Own Methods (utilizing methods that were previously successful). They were followed-up one week after consenting.
Results
A main effect of time was observed for both depression (F(1, 563)=234.70, p<0.001) and anxiety (F(1, 551)=170.27, p<0.001). In all cases, regardless of assigned condition and Major Depressive Episode status, mean scores on both positive outcomes (mood, confidence and motivation) and negative outcome scores (depression and anxiety) improved over time.
Conclusions
Brief unsupported Internet interventions can improve depressive symptoms at one-week follow-up. Further outcome data and research implications will be discussed.}
}
@article{LANE20151659,
title = {New linked data on research investments: Scientific workforce, productivity, and public value},
journal = {Research Policy},
volume = {44},
number = {9},
pages = {1659-1671},
year = {2015},
note = {The New Data Frontier},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2014.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0048733315000025},
author = {Julia I. Lane and Jason Owen-Smith and Rebecca F. Rosen and Bruce A. Weinberg},
keywords = {IRIS, UMETRICS, STAR METRICS, Science of science policy, Linked data, Scientific workforce, Scientific networks, Occupation classification},
abstract = {Longitudinal micro-data derived from transaction level information about wage and vendor payments made by Federal grants on multiple US campuses are being developed in a partnership involving researchers, university administrators, representatives of Federal agencies, and others. This paper describes the UMETRICS data initiative that has been implemented under the auspices of the Committee on Institutional Cooperation. The resulting data set reflects an emerging conceptual framework for analyzing the process, products, and impact of research. It grows from and engages the work of a diverse and vibrant community. This paper situates the UMETRICS effort in the context of research evaluation and ongoing data infrastructure efforts in order to highlight its novel and valuable features. Refocusing data construction in this field around individuals, networks, and teams offers dramatic possibilities for data linkage, the evaluation of research investments, and the development of rigorous conceptual and empirical models. Two preliminary analyses of the scientific workforce and network approaches to characterizing scientific teams ground a discussion of future directions and a call for increased community engagement.}
}
@incollection{MCKNIGHT201452,
title = {Chapter Six - Data Warehouses and Appliances},
editor = {William McKnight},
booktitle = {Information Management},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {52-66},
year = {2014},
isbn = {978-0-12-408056-0},
doi = {https://doi.org/10.1016/B978-0-12-408056-0.00006-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780124080560000060},
author = {William McKnight},
keywords = {business intelligence, data warehouse, data warehouse appliance, analytic appliance},
abstract = {Prebuilt analytical machines, up and running quickly, can siphon off analytic workloads such as the data warehouse. The data warehouse is the heart of the information-centric organization and remains a fixture in the environment for reasons discussed in this chapter. Practices for implementing a data warehouse are discussed as well. Select data warehouse appliances, and data appliances, are discussed to further convey their distinction and place in the ecosystem.}
}
@article{2015IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {47},
pages = {IFC},
year = {2015},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(14)00139-2},
url = {https://www.sciencedirect.com/science/article/pii/S0306437914001392}
}
@article{GRANA20131567,
title = {Special issue on “Innovative knowledge based techniques in pattern recognition”},
journal = {Pattern Recognition Letters},
volume = {34},
number = {14},
pages = {1567-1568},
year = {2013},
note = {Innovative Knowledge Based Techniques in Pattern Recognition},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2013.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167865513002390},
author = {Manuel Graña and Michal Wozniak and Nima Hatami}
}
@article{PIMM2015685,
title = {Emerging Technologies to Conserve Biodiversity},
journal = {Trends in Ecology & Evolution},
volume = {30},
number = {11},
pages = {685-696},
year = {2015},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2015.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0169534715002128},
author = {Stuart L. Pimm and Sky Alibhai and Richard Bergl and Alex Dehgan and Chandra Giri and Zoë Jewell and Lucas Joppa and Roland Kays and Scott Loarie},
keywords = {technology, conservation, crowdsourcing, remote-sensing, traditional knowledge, innovation},
abstract = {Technologies to identify individual animals, follow their movements, identify and locate animal and plant species, and assess the status of their habitats remotely have become better, faster, and cheaper as threats to the survival of species are increasing. New technologies alone do not save species, and new data create new problems. For example, improving technologies alone cannot prevent poaching: solutions require providing appropriate tools to the right people. Habitat loss is another driver: the challenge here is to connect existing sophisticated remote sensing with species occurrence data to predict where species remain. Other challenges include assembling a wider public to crowdsource data, managing the massive quantities of data generated, and developing solutions to rapidly emerging threats.}
}
@article{2016527,
title = {Subject Index},
journal = {Procedia Computer Science},
volume = {95},
pages = {527-531},
year = {2016},
note = {Complex Adaptive Systems Los Angeles, CA November 2-4, 2016},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.09.336},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916325091}
}
@article{2014IFC,
title = {IFC EDBD/Aims and Scope},
journal = {Information Systems},
volume = {46},
pages = {IFC},
year = {2014},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(14)00098-2},
url = {https://www.sciencedirect.com/science/article/pii/S0306437914000982}
}
@article{DEMARTINI20155,
title = {Hybrid human–machine information systems: Challenges and opportunities},
journal = {Computer Networks},
volume = {90},
pages = {5-13},
year = {2015},
note = {Crowdsourcing},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2015.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S1389128615002194},
author = {Gianluca Demartini},
keywords = {Human computation, Crowdsourcing, Database, Semantic web, Information retrieval},
abstract = {Micro-task Crowdsourcing has been used for different purposes: creating training data for machine learning algorithms, relevance judgments for evaluation of information systems, sentiment analysis, language translation, etc. In this paper we focus on the use of crowdsourcing as core component of data-driven systems. The creation of hybrid human–machine systems is a highly promising direction as it allows leveraging both the scalability of machines over large amounts of data as well as keeping the quality of human intelligence in the loop to finally obtain both efficiency and effectiveness in data processing applications. Such a hybrid approach is a great opportunity to develop systems that are more powerful than purely machine-based ones. For example, it is possible to build systems that can understand sarcasm in text at scale. However, when designing such systems it is critical to take into account a number of dimensions related to human behavior as humans become a component of the overall process. In this paper, we overview existing hybrid human–machine systems presenting commonalities in the approaches taken by different research communities. We summarize the key challenges that one has to face in developing such systems as well the opportunities and the open research directions to make such approaches the best way to process data in the future.}
}
@incollection{DOAN2012453,
title = {19 - The Future of Data Integration},
editor = {AnHai Doan and Alon Halevy and Zachary Ives},
booktitle = {Principles of Data Integration},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {453-457},
year = {2012},
isbn = {978-0-12-416044-6},
doi = {https://doi.org/10.1016/B978-0-12-416044-6.00019-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780124160446000193},
author = {AnHai Doan and Alon Halevy and Zachary Ives}
}
@article{VERTESY20158,
title = {Nondestructive characterization of flake graphite cast iron by magnetic adaptive testing},
journal = {NDT & E International},
volume = {74},
pages = {8-14},
year = {2015},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2015.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0963869515000419},
author = {Gábor Vértesy and Tetsuya Uchimoto and Toshiyuki Takagi and Ivan Tomáš and Hidehiko Kage},
keywords = {Cast iron, Magnetic hysteresis, Magnetic adaptive testing, Nondestructive testing},
abstract = {Three series of flake graphite cast iron samples having different chemical compositions and different heat treatments within each series were investigated by the method of magnetic adaptive testing. The flat samples were magnetized by an attached yoke, and sensitive descriptors were obtained from the proper evaluation, based on the measurements of series of magnetic minor hysteresis loops, without magnetic saturation of the samples. Results of the non-destructive magnetic tests were compared with the destructive mechanical measurements of Brinell hardness and linear correlation was found between them in all cases, where the influence of chemical composition and influence of heat treatment were considered.}
}
@article{QIN2016137,
title = {When things matter: A survey on data-centric internet of things},
journal = {Journal of Network and Computer Applications},
volume = {64},
pages = {137-153},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516000606},
author = {Yongrui Qin and Quan Z. Sheng and Nickolas J.G. Falkner and Schahram Dustdar and Hua Wang and Athanasios V. Vasilakos},
keywords = {Internet of Things, Data management, RFID systems, Wireless sensor networks},
abstract = {With the recent advances in radio-frequency identification (RFID), low-cost wireless sensor devices, and Web technologies, the Internet of Things (IoT) approach has gained momentum in connecting everyday objects to the Internet and facilitating machine-to-human and machine-to-machine communication with the physical world. IoT offers the capability to connect and integrate both digital and physical entities, enabling a whole new class of applications and services, but several significant challenges need to be addressed before these applications and services can be fully realized. A fundamental challenge centers around managing IoT data, typically produced in dynamic and volatile environments, which is not only extremely large in scale and volume, but also noisy and continuous. This paper reviews the main techniques and state-of-the-art research efforts in IoT from data-centric perspectives, including data stream processing, data storage models, complex event processing, and searching in IoT. Open research issues for IoT data management are also discussed.}
}
@article{KATARYA2016182,
title = {Recent developments in affective recommender systems},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {461},
pages = {182-190},
year = {2016},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2016.05.046},
url = {https://www.sciencedirect.com/science/article/pii/S037843711630231X},
author = {Rahul Katarya and Om Prakash Verma},
keywords = {Recommender systems, Affective, Human factors, Review, Emotions},
abstract = {Recommender systems (RSs) are playing a significant role since 1990s as they provide relevant, personalized information to the users over the internet. Lots of work have been done in information filtering, utilization, and application related to RS. However, an important area recently draws our attention which is affective recommender system. Affective recommender system (ARS) is latest trending area of research, as publication in this domain are few and recently published. ARS is associated with human behaviour, human factors, mood, senses, emotions, facial expressions, body gesture and physiological with human–computer interaction (HCI). Due to this assortment and various interests, more explanation is required, as it is in premature phase and growing as compared to other fields. So we have done literature review (LR) in the affective recommender systems by doing classification, incorporate reputed articles published from the year 2003 to February 2016. We include articles which highlight, analyse, and perform a study on affective recommender systems. This article categorizes, synthesizes, and discusses the research and development in ARS. We have classified and managed ARS papers according to different perspectives: research gaps, nature, algorithm or method adopted, datasets, the platform on executed, types of information and evaluation techniques applied. The researchers and professionals will positively support this survey article for understanding the current position, research in affective recommender systems and will guide future trends, opportunity and research focus in ARS.}
}